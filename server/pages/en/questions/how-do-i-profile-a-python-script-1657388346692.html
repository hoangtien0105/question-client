<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="@solutionschecker.com"/><meta name="twitter:creator" content="@solutionschecker.com"/><meta property="og:url" content="https://solutionschecker.com"/><meta property="og:type" content="website"/><meta property="og:image" content="https://solutionschecker.com/solutions-checker-banner.png"/><meta property="og:image:alt" content="Find the solution to any question. We focus on finding the fastest possible solution for users. Main topics like coding, learning. - solutionschecker.com"/><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"/><link rel="manifest" href="/site.webmanifest"/><script type="application/ld+json">{"@context":"https://schema.org","@type":"Organization","logo":"/logo.svg","url":"https://solutionschecker.com"}</script><link name="keywords" content="solutions checker, solution checker, how to, solution for, check for solution, resolve question, what is, what solution for, find solution"/><script type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"https://solutionschecker.com","name":"Home"}},{"@type":"ListItem","position":2,"item":{"@id":"https://solutionschecker.com/questions","name":"Questions"}},{"@type":"ListItem","position":3,"item":{"@id":"https://solutionschecker.com/questions/how-do-i-profile-a-python-script-1657388346692","name":"Questions"}}]}</script><title>How do I profile a Python script? | Solution Checker</title><meta name="robots" content="index,follow"/><meta name="description" content="Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs. With Python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.

What is a good way to profile how long a Python program takes to run?
    "/><meta property="og:title" content="How do I profile a Python script? | Solution Checker"/><meta property="og:description" content="Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs. With Python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.

What is a good way to profile how long a Python program takes to run?
    "/><script type="application/ld+json">{"@context":"https://schema.org","@type":"QAPage","mainEntity":{"name":"How do I profile a Python script?","text":"Project Euler and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs. With Python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to __main__.\n\nWhat is a good way to profile how long a Python program takes to run?\n    ","answerCount":30,"upVoteCount":500,"suggestedAnswer":[{"text":"Python includes a profiler called cProfile. It not only gives the total running time, but also times each function separately, and tells you how many times each function was called, making it easy to determine where you should make optimizations.\n\nYou can call it from within your code, or from the interpreter, like this:\n\nimport cProfile\ncProfile.run(&apos;foo()&apos;)\n\n\nEven more usefully, you can invoke the cProfile when running a script:\n\npython -m cProfile myscript.py\n\n\nTo make it even easier, I made a little batch file called &apos;profile.bat&apos;:\n\npython -m cProfile %1\n\n\nSo all I have to do is run:\n\nprofile euler048.py\n\n\nAnd I get this:\n\n1007 function calls in 0.061 CPU seconds\n\nOrdered by: standard name\nncalls  tottime  percall  cumtime  percall filename:lineno(function)\n    1    0.000    0.000    0.061    0.061 &lt;string&gt;:1(&lt;module&gt;)\n 1000    0.051    0.000    0.051    0.000 euler048.py:2(&lt;lambda&gt;)\n    1    0.005    0.005    0.061    0.061 euler048.py:2(&lt;module&gt;)\n    1    0.000    0.000    0.061    0.061 {execfile}\n    1    0.002    0.002    0.053    0.053 {map}\n    1    0.000    0.000    0.000    0.000 {method &apos;disable&apos; of &apos;_lsprof.Profiler objects}\n    1    0.000    0.000    0.000    0.000 {range}\n    1    0.003    0.003    0.003    0.003 {sum}\n\n\nEDIT: Updated link to a good video resource from PyCon 2013 titled \nPython Profiling\nAlso via YouTube.\n    ","url":"/questions/[slug]#solution1","@type":"Answer","upvoteCount":0},{"text":"A while ago I made pycallgraph which generates a visualisation from your Python code. Edit: I&apos;ve updated the example to work with 3.3, the latest release as of this writing.\n\nAfter a pip install pycallgraph and installing GraphViz you can run it from the command line:\n\npycallgraph graphviz -- ./mypythonscript.py\n\n\nOr, you can profile particular parts of your code:\n\nfrom pycallgraph import PyCallGraph\nfrom pycallgraph.output import GraphvizOutput\n\nwith PyCallGraph(output=GraphvizOutput()):\n    code_to_profile()\n\n\nEither of these will generate a pycallgraph.png file similar to the image below:\n\n\n    ","url":"/questions/[slug]#solution2","@type":"Answer","upvoteCount":0},{"text":"It&apos;s worth pointing out that using the profiler only works (by default) on the main thread, and you won&apos;t get any information from other threads if you use them.  This can be a bit of a gotcha as it is completely unmentioned in the profiler documentation.\n\nIf you also want to profile threads, you&apos;ll want to look at the threading.setprofile() function in the docs.\n\nYou could also create your own threading.Thread subclass to do it:\n\nclass ProfiledThread(threading.Thread):\n    # Overrides threading.Thread.run()\n    def run(self):\n        profiler = cProfile.Profile()\n        try:\n            return profiler.runcall(threading.Thread.run, self)\n        finally:\n            profiler.dump_stats(&apos;myprofile-%d.profile&apos; % (self.ident,))\n\n\nand use that ProfiledThread class instead of the standard one.  It might give you more flexibility, but I&apos;m not sure it&apos;s worth it, especially if you are using third-party code which wouldn&apos;t use your class.\n    ","url":"/questions/[slug]#solution3","@type":"Answer","upvoteCount":0},{"text":"The python wiki is a great page for profiling resources:\nhttp://wiki.python.org/moin/PythonSpeed/PerformanceTips#Profiling_Code\n\nas is the python docs:\nhttp://docs.python.org/library/profile.html\n\nas shown by Chris Lawlor cProfile is a great tool and can easily be used to print to the screen:\n\npython -m cProfile -s time mine.py &lt;args&gt;\n\n\nor to file:\n\npython -m cProfile -o output.file mine.py &lt;args&gt;\n\n\nPS&gt; If you are using Ubuntu, make sure to install python-profile\n\napt-get install python-profiler \n\n\nIf you output to file you can get nice visualizations using the following tools\n\nPyCallGraph : a tool to create call graph images \n  install:\n\n pip install pycallgraph\n\n\nrun:\n\n pycallgraph mine.py args\n\n\nview:\n\n gimp pycallgraph.png\n\n\nYou can use whatever you like to view the png file, I used gimp\nUnfortunately I often get \n\ndot: graph is too large for cairo-renderer bitmaps. Scaling by 0.257079 to fit\n\nwhich makes my images unusably small.  So I generally create svg files:\n\npycallgraph -f svg -o pycallgraph.svg mine.py &lt;args&gt;\n\n\nPS&gt; make sure to install graphviz (which provides the dot program):\n\npip install graphviz\n\n\nAlternative Graphing using gprof2dot via @maxy / @quodlibetor :\n\npip install gprof2dot\npython -m cProfile -o profile.pstats mine.py\ngprof2dot -f pstats profile.pstats | dot -Tsvg -o mine.svg\n\n    ","url":"/questions/[slug]#solution4","@type":"Answer","upvoteCount":0},{"text":"@Maxy&apos;s comment on this answer helped me out enough that I think it deserves its own answer: I already had cProfile-generated .pstats files and I didn&apos;t want to re-run things with pycallgraph, so I used gprof2dot, and got pretty svgs:\n$ sudo apt-get install graphviz\n$ git clone https://github.com/jrfonseca/gprof2dot\n$ ln -s &quot;$PWD&quot;/gprof2dot/gprof2dot.py ~/bin\n$ cd $PROJECT_DIR\n$ gprof2dot.py -f pstats profile.pstats | dot -Tsvg -o callgraph.svg\n\nand BLAM!\nIt uses dot (the same thing that pycallgraph uses) so output looks similar. I get the impression that gprof2dot loses less information though:\n\n    ","url":"/questions/[slug]#solution5","@type":"Answer","upvoteCount":0},{"text":"Simplest and quickest way to find where all the time is going.\n\n1. pip install snakeviz\n\n2. python -m cProfile -o temp.dat &lt;PROGRAM&gt;.py\n\n3. snakeviz temp.dat\n\n\nDraws a pie chart in a browser. Biggest piece is the problem function. Very simple.\n    ","url":"/questions/[slug]#solution6","@type":"Answer","upvoteCount":0},{"text":"I ran into a handy tool called SnakeViz when researching this topic. SnakeViz is a web-based profiling visualization tool. It is very easy to install and use. The usual way I use it is to generate a stat file with %prun and then do analysis in SnakeViz.\n\nThe main viz technique used is Sunburst chart as shown below, in which the hierarchy of function calls is arranged as layers of arcs and time info encoded in their angular widths.\n\nThe best thing is you can interact with the chart. For example, to zoom in one can click on an arc, and the arc and its descendants will be enlarged as a new sunburst to display more details.\n\n\n    ","url":"/questions/[slug]#solution7","@type":"Answer","upvoteCount":0},{"text":"cProfile is great for profiling, while kcachegrind is great for visualizing the results. The pyprof2calltree in between handles the file conversion.\npython -m cProfile -o script.profile script.py\npyprof2calltree -i script.profile -o script.calltree\nkcachegrind script.calltree\n\nRequired system packages:\n\nkcachegrind (Linux), qcachegrind (MacOs)\n\nSetup on Ubuntu:\napt-get install kcachegrind \npip install pyprof2calltree\n\nThe result:\n\n    ","url":"/questions/[slug]#solution8","@type":"Answer","upvoteCount":0},{"text":"I recently created tuna for visualizing Python runtime and import profiles; this may be helpful here.\n\nInstall with\npip install tuna\n\nCreate a runtime profile\npython3 -m cProfile -o program.prof yourfile.py\n\nor an import profile (Python 3.7+ required)\npython3 -X importprofile yourfile.py 2&gt; import.log\n\nThen just run tuna on the file\ntuna program.prof\n\n    ","url":"/questions/[slug]#solution9","@type":"Answer","upvoteCount":0},{"text":"Also worth mentioning is the GUI cProfile dump viewer RunSnakeRun.  It allows you to sort and select, thereby zooming in on the relevant parts of the program.  The sizes of the rectangles in the picture is proportional to the time taken.  If you mouse over a rectangle it highlights that call in the table and everywhere on the map.  When you double-click on a rectangle it zooms in on that portion.  It will show you who calls that portion and what that portion calls.\n\nThe descriptive information is very helpful.  It shows you the code for that bit which can be helpful when you are dealing with built-in library calls.  It tells you what file and what line to find the code.\n\nAlso want to point at that the OP said &apos;profiling&apos; but it appears he meant &apos;timing&apos;.  Keep in mind programs will run slower when profiled.\n\n\n    ","url":"/questions/[slug]#solution10","@type":"Answer","upvoteCount":0},{"text":"pprofile\n\nline_profiler (already presented here) also inspired  pprofile, which is described as:\n\n\n  Line-granularity, thread-aware deterministic and statistic pure-python\n  profiler\n\n\nIt provides line-granularity as line_profiler, is pure Python, can be used as a standalone command or a module, and can even generate callgrind-format files that can be easily analyzed with [k|q]cachegrind.\n\nvprof\n\nThere is also vprof, a Python package described as:\n\n\n  [...] providing rich and interactive visualizations for various Python program characteristics such as running time and memory usage.\n\n\n\n    ","url":"/questions/[slug]#solution11","@type":"Answer","upvoteCount":0},{"text":"A nice profiling module is the line_profiler (called using the script kernprof.py).  It can be downloaded here.\n\nMy understanding is that cProfile only gives information about total time spent in each function.  So individual lines of code are not timed.  This is an issue in scientific computing since often one single line can take a lot of time.  Also, as I remember, cProfile didn&apos;t catch the time I was spending in say numpy.dot.\n    ","url":"/questions/[slug]#solution12","@type":"Answer","upvoteCount":0},{"text":"The terminal-only (and simplest) solution, in case all those fancy UI&apos;s fail to install or to run:\nignore cProfile completely and replace it with pyinstrument, that will collect and display the tree of calls right after execution.\n\nInstall:  \n\n$ pip install pyinstrument\n\n\nProfile and display result:  \n\n$ python -m pyinstrument ./prog.py\n\n\nWorks with python2 and 3.\n\n[EDIT]\nThe documentation of the API, for profiling only a part of the code, can be found here.\n    ","url":"/questions/[slug]#solution13","@type":"Answer","upvoteCount":0},{"text":"There&apos;s a lot of great answers but they either use command line or some external program for profiling and/or sorting the results.\nI really missed some way I could use in my IDE (eclipse-PyDev) without touching the command line or installing anything. So here it is.\nProfiling without command line\ndef count():\n    from math import sqrt\n    for x in range(10**5):\n        sqrt(x)\n\nif __name__ == &apos;__main__&apos;:\n    import cProfile, pstats\n    cProfile.run(&quot;count()&quot;, &quot;{}.profile&quot;.format(__file__))\n    s = pstats.Stats(&quot;{}.profile&quot;.format(__file__))\n    s.strip_dirs()\n    s.sort_stats(&quot;time&quot;).print_stats(10)\n\nSee docs or other answers for more info.\n    ","url":"/questions/[slug]#solution14","@type":"Answer","upvoteCount":0},{"text":"Following Joe Shaw&apos;s answer about multi-threaded code not to work as expected, I figured that the runcall method in cProfile is merely doing self.enable() and self.disable() calls around the profiled function call, so you can simply do that yourself and have whatever code you want in-between with minimal interference with existing code.\n    ","url":"/questions/[slug]#solution15","@type":"Answer","upvoteCount":0},{"text":"With a statistical profiler like austin, no instrumentation is required, meaning that you can get profiling data out of a Python application simply with\naustin python3 my_script.py\n\nThe raw output isn&apos;t very useful, but you can pipe that to flamegraph.pl\nto get a flame graph representation of that data that gives you a breakdown of where the time (measured in microseconds of real time) is being spent.\naustin python3 my_script.py | flamegraph.pl &gt; my_script_profile.svg\n\nAlternatively, you can also use the web application Speedscope.app for quick visualisation of the collected samples. If you have pprof installed, you can also get austin-python (with e.g. pipx install austin-python) and use the austin2pprof to covert to the pprof format.\nHowever, if you have VS Code installed you could use the Austin extension for a more interactive experience, with source code heat maps, top functions and collected call stacks\n\n    ","url":"/questions/[slug]#solution16","@type":"Answer","upvoteCount":0},{"text":"In Virtaal&apos;s source there&apos;s a very useful class and decorator that can make profiling (even for specific methods/functions) very easy. The output can then be viewed very comfortably in KCacheGrind.\n    ","url":"/questions/[slug]#solution17","@type":"Answer","upvoteCount":0},{"text":"If you want to make a cumulative profiler,\nmeaning to run the function several times in a row and watch the sum of the results.\n\nyou can use this cumulative_profiler decorator:\n\nit&apos;s python &gt;= 3.6 specific, but you can remove nonlocal for it work on older versions.\n\nimport cProfile, pstats\n\nclass _ProfileFunc:\n    def __init__(self, func, sort_stats_by):\n        self.func =  func\n        self.profile_runs = []\n        self.sort_stats_by = sort_stats_by\n\n    def __call__(self, *args, **kwargs):\n        pr = cProfile.Profile()\n        pr.enable()  # this is the profiling section\n        retval = self.func(*args, **kwargs)\n        pr.disable()\n\n        self.profile_runs.append(pr)\n        ps = pstats.Stats(*self.profile_runs).sort_stats(self.sort_stats_by)\n        return retval, ps\n\ndef cumulative_profiler(amount_of_times, sort_stats_by=&apos;time&apos;):\n    def real_decorator(function):\n        def wrapper(*args, **kwargs):\n            nonlocal function, amount_of_times, sort_stats_by  # for python 2.x remove this row\n\n            profiled_func = _ProfileFunc(function, sort_stats_by)\n            for i in range(amount_of_times):\n                retval, ps = profiled_func(*args, **kwargs)\n            ps.print_stats()\n            return retval  # returns the results of the function\n        return wrapper\n\n    if callable(amount_of_times):  # incase you don&apos;t want to specify the amount of times\n        func = amount_of_times  # amount_of_times is the function in here\n        amount_of_times = 5  # the default amount\n        return real_decorator(func)\n    return real_decorator\n\n\nExample\n\nprofiling the function baz \n\nimport time\n\n@cumulative_profiler\ndef baz():\n    time.sleep(1)\n    time.sleep(2)\n    return 1\n\nbaz()\n\n\nbaz ran 5 times and printed this:\n\n         20 function calls in 15.003 seconds\n\n   Ordered by: internal time\n\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n       10   15.003    1.500   15.003    1.500 {built-in method time.sleep}\n        5    0.000    0.000   15.003    3.001 &lt;ipython-input-9-c89afe010372&gt;:3(baz)\n        5    0.000    0.000    0.000    0.000 {method &apos;disable&apos; of &apos;_lsprof.Profiler&apos; objects}\n\n\nspecifying the amount of times\n\n@cumulative_profiler(3)\ndef baz():\n    ...\n\n    ","url":"/questions/[slug]#solution18","@type":"Answer","upvoteCount":0},{"text":"For getting quick profile stats on an IPython notebook.\nOne can embed line_profiler and memory_profiler straight into their notebooks.\nAnother useful package is Pympler. It is a powerful profiling package that&apos;s capable to track classes,objects,functions,memory leaks etc. Examples below, Docs attached.\nGet it!\n!pip install line_profiler\n!pip install memory_profiler\n!pip install pympler\n\nLoad it!\n%load_ext line_profiler\n%load_ext memory_profiler\n\nUse it!\n\n%time\n%time print(&apos;Outputs CPU time,Wall Clock time&apos;) \n#CPU times: user 2 µs, sys: 0 ns, total: 2 µs Wall time: 5.96 µs\n\nGives:\n\nCPU times: CPU level execution time\nsys times: system level execution time\ntotal: CPU time + system time\nWall time: Wall Clock Time\n\n\n%timeit\n%timeit -r 7 -n 1000 print(&apos;Outputs execution time of the snippet&apos;) \n#1000 loops, best of 7: 7.46 ns per loop\n\n\nGives best time out of given number of runs(r) in looping (n) times.\nOutputs details on system caching:\n\nWhen code snippets are executed multiple times, system caches a few opearations and doesn&apos;t execute them again that may hamper the accuracy of the profile reports.\n\n\n\n\n%prun\n%prun -s cumulative &apos;Code to profile&apos; \n\nGives:\n\nnumber of function calls(ncalls)\nhas entries per function call(distinct)\ntime taken per call(percall)\ntime elapsed till that function call(cumtime)\nname of the func/module called etc...\n\n\n\n%memit\n%memit &apos;Code to profile&apos;\n#peak memory: 199.45 MiB, increment: 0.00 MiB\n\nGives:\n\nMemory usage\n\n\n%lprun\n#Example function\ndef fun():\n  for i in range(10):\n    print(i)\n\n#Usage: %lprun &lt;name_of_the_function&gt; function\n%lprun -f fun fun()\n\nGives:\n\nLine wise stats\n\n\n\nsys.getsizeof\nsys.getsizeof(&apos;code to profile&apos;)\n# 64 bytes\n\nReturns the size of an object in bytes.\n\nasizeof() from pympler\nfrom pympler import asizeof\nobj = [1,2,(&quot;hey&quot;,&quot;ha&quot;),3]\nprint(asizeof.asizeof(obj,stats=4))\n\n\npympler.asizeof can be used to investigate how much memory certain Python objects consume.\nIn contrast to sys.getsizeof, asizeof sizes objects recursively\n\n\ntracker from pympler\nfrom pympler import tracker\ntr = tracker.SummaryTracker()\ndef fun():\n  li = [1,2,3]\n  di = {&quot;ha&quot;:&quot;haha&quot;,&quot;duh&quot;:&quot;Umm&quot;}\nfun()\ntr.print_diff()\n\nTracks the lifetime of a function.\n\nPympler package consists of a huge number of high utility functions to profile code. All of which cannot be covered here. See the documentation attached for verbose profile implementations.\nPympler doc\n    ","url":"/questions/[slug]#solution19","@type":"Answer","upvoteCount":0},{"text":"Recently I created a plugin for PyCharm with which you can easily analyse and visualise the results of line_profiler in the PyCharm editor.\nline_profiler has been mentioned in other answers as well and is a great tool to analyse exactly how much time is spent by the python interpreter in certain lines.\nThe PyCharm plugin I&apos;ve created can be found here:\nhttps://plugins.jetbrains.com/plugin/16536-line-profiler\nIt needs a helper package in your python environment called line-profiler-pycharm which can be installed with pip or by the plugin itself.\nAfter installing the plugin in PyCharm:\n\nDecorate any function you want to profile with the line_profiler_pycharm.profile decorator\nRun with the &apos;Profile Lines&apos; runner\n\nScreenshot of results:\n\n    ","url":"/questions/[slug]#solution20","@type":"Answer","upvoteCount":0},{"text":"cProfile is great for quick profiling but most of the time it was ending for me with the errors. Function runctx solves this problem by initializing correctly the environment and variables, hope it can be useful for someone:\n\nimport cProfile\ncProfile.runctx(&apos;foo()&apos;, None, locals())\n\n    ","url":"/questions/[slug]#solution21","@type":"Answer","upvoteCount":0},{"text":"gprof2dot_magic\n\nMagic function for gprof2dot to profile any Python statement as a DOT graph in JupyterLab or Jupyter Notebook.\n\n\n\nGitHub repo: https://github.com/mattijn/gprof2dot_magic\n\ninstallation\n\nMake sure you&apos;ve the Python package gprof2dot_magic.\n\npip install gprof2dot_magic\n\n\nIts dependencies gprof2dot and graphviz will be installed as well\n\nusage\n\nTo enable the magic function, first load the gprof2dot_magic module\n\n%load_ext gprof2dot_magic\n\n\nand then profile any line statement as a DOT graph as such:\n\n%gprof2dot print(&apos;hello world&apos;)\n\n\n\n    ","url":"/questions/[slug]#solution22","@type":"Answer","upvoteCount":0},{"text":"My way is to use yappi (https://github.com/sumerc/yappi). It&apos;s especially useful combined with an RPC server where (even just for debugging) you register method to start, stop and print profiling information, e.g. in this way: \n\n@staticmethod\ndef startProfiler():\n    yappi.start()\n\n@staticmethod\ndef stopProfiler():\n    yappi.stop()\n\n@staticmethod\ndef printProfiler():\n    stats = yappi.get_stats(yappi.SORTTYPE_TTOT, yappi.SORTORDER_DESC, 20)\n    statPrint = &apos;\\n&apos;\n    namesArr = [len(str(stat[0])) for stat in stats.func_stats]\n    log.debug(&quot;namesArr %s&quot;, str(namesArr))\n    maxNameLen = max(namesArr)\n    log.debug(&quot;maxNameLen: %s&quot;, maxNameLen)\n\n    for stat in stats.func_stats:\n        nameAppendSpaces = [&apos; &apos; for i in range(maxNameLen - len(stat[0]))]\n        log.debug(&apos;nameAppendSpaces: %s&apos;, nameAppendSpaces)\n        blankSpace = &apos;&apos;\n        for space in nameAppendSpaces:\n            blankSpace += space\n\n        log.debug(&quot;adding spaces: %s&quot;, len(nameAppendSpaces))\n        statPrint = statPrint + str(stat[0]) + blankSpace + &quot; &quot; + str(stat[1]).ljust(8) + &quot;\\t&quot; + str(\n            round(stat[2], 2)).ljust(8 - len(str(stat[2]))) + &quot;\\t&quot; + str(round(stat[3], 2)) + &quot;\\n&quot;\n\n    log.log(1000, &quot;\\nname&quot; + &apos;&apos;.ljust(maxNameLen - 4) + &quot; ncall \\tttot \\ttsub&quot;)\n    log.log(1000, statPrint)\n\n\nThen when your program work you can start profiler at any time by calling the startProfiler RPC method and dump profiling information to a log file by calling printProfiler (or modify the rpc method to return it to the caller) and get such output:\n\n2014-02-19 16:32:24,128-|SVR-MAIN  |-(Thread-3   )-Level 1000: \nname                                                                                                                                      ncall     ttot    tsub\n2014-02-19 16:32:24,128-|SVR-MAIN  |-(Thread-3   )-Level 1000: \nC:\\Python27\\lib\\sched.py.run:80                                                                                                           22        0.11    0.05\nM:\\02_documents\\_repos\\09_aheadRepos\\apps\\ahdModbusSrv\\pyAheadRpcSrv\\xmlRpc.py.iterFnc:293                                                22        0.11    0.0\nM:\\02_documents\\_repos\\09_aheadRepos\\apps\\ahdModbusSrv\\serverMain.py.makeIteration:515                                                    22        0.11    0.0\nM:\\02_documents\\_repos\\09_aheadRepos\\apps\\ahdModbusSrv\\pyAheadRpcSrv\\PicklingXMLRPC.py._dispatch:66                                       1         0.0     0.0\nC:\\Python27\\lib\\BaseHTTPServer.py.date_time_string:464                                                                                    1         0.0     0.0\nc:\\users\\zasiec~1\\appdata\\local\\temp\\easy_install-hwcsr1\\psutil-1.1.2-py2.7-win32.egg.tmp\\psutil\\_psmswindows.py._get_raw_meminfo:243     4         0.0     0.0\nC:\\Python27\\lib\\SimpleXMLRPCServer.py.decode_request_content:537                                                                          1         0.0     0.0\nc:\\users\\zasiec~1\\appdata\\local\\temp\\easy_install-hwcsr1\\psutil-1.1.2-py2.7-win32.egg.tmp\\psutil\\_psmswindows.py.get_system_cpu_times:148 4         0.0     0.0\n&lt;string&gt;.__new__:8                                                                                                                        220       0.0     0.0\nC:\\Python27\\lib\\socket.py.close:276                                                                                                       4         0.0     0.0\nC:\\Python27\\lib\\threading.py.__init__:558                                                                                                 1         0.0     0.0\n&lt;string&gt;.__new__:8                                                                                                                        4         0.0     0.0\nC:\\Python27\\lib\\threading.py.notify:372                                                                                                   1         0.0     0.0\nC:\\Python27\\lib\\rfc822.py.getheader:285                                                                                                   4         0.0     0.0\nC:\\Python27\\lib\\BaseHTTPServer.py.handle_one_request:301                                                                                  1         0.0     0.0\nC:\\Python27\\lib\\xmlrpclib.py.end:816                                                                                                      3         0.0     0.0\nC:\\Python27\\lib\\SimpleXMLRPCServer.py.do_POST:467                                                                                         1         0.0     0.0\nC:\\Python27\\lib\\SimpleXMLRPCServer.py.is_rpc_path_valid:460                                                                               1         0.0     0.0\nC:\\Python27\\lib\\SocketServer.py.close_request:475                                                                                         1         0.0     0.0\nc:\\users\\zasiec~1\\appdata\\local\\temp\\easy_install-hwcsr1\\psutil-1.1.2-py2.7-win32.egg.tmp\\psutil\\__init__.py.cpu_times:1066               4         0.0     0.0 \n\n\nIt may not be very useful for short scripts but helps to optimize server-type processes especially given the printProfiler method can be called multiple times over time to profile and compare e.g. different program usage scenarios. \n\nIn newer versions of yappi, the following code will work:\n\n@staticmethod\ndef printProfile():\n    yappi.get_func_stats().print_all()\n\n    ","url":"/questions/[slug]#solution23","@type":"Answer","upvoteCount":0},{"text":"To add on to https://stackoverflow.com/a/582337/1070617,\n\nI wrote this module that allows you to use cProfile and view its output easily. More here: https://github.com/ymichael/cprofilev\n\n$ python -m cprofilev /your/python/program\n# Go to http://localhost:4000 to view collected statistics.\n\n\nAlso see: http://ymichael.com/2014/03/08/profiling-python-with-cprofile.html on how to make sense of the collected statistics.\n    ","url":"/questions/[slug]#solution24","@type":"Answer","upvoteCount":0},{"text":"A new tool to handle profiling in Python is PyVmMonitor: http://www.pyvmmonitor.com/\n\nIt has some unique features such as\n\n\nAttach profiler to a running (CPython) program\nOn demand profiling with Yappi integration\nProfile on a different machine\nMultiple processes support (multiprocessing, django...)\nLive sampling/CPU view (with time range selection)\nDeterministic profiling through cProfile/profile integration\nAnalyze existing PStats results\nOpen DOT files\nProgramatic API access\nGroup samples by method or line\nPyDev integration\nPyCharm integration\n\n\nNote: it&apos;s commercial, but free for open source.\n    ","url":"/questions/[slug]#solution25","@type":"Answer","upvoteCount":0},{"text":"It would depend on what you want to see out of profiling. Simple time \nmetrics can be given by (bash). \n\ntime python python_prog.py\n\n\nEven &apos;/usr/bin/time&apos; can output detailed metrics by using &apos;--verbose&apos; flag.\n\nTo check time metrics given by each function and to better understand how much time is spent on functions, you can use the inbuilt cProfile in python. \n\nGoing into more detailed metrics like performance, time is not the only metric. You can worry about memory, threads etc.\nProfiling options:\n1. line_profiler is another profiler used commonly to find out timing metrics line-by-line.\n2. memory_profiler is a tool to profile memory usage.\n3. heapy (from project Guppy) Profile how objects in the heap are used. \n\nThese are some of the common ones I tend to use. But if you want to find out more, try reading this book\nIt is a pretty good book on starting out with performance in mind. You can move onto advanced topics on using Cython and JIT(Just-in-time) compiled python. \n    ","url":"/questions/[slug]#solution26","@type":"Answer","upvoteCount":0},{"text":"I just developed my own profiler inspired from pypref_time:\nhttps://github.com/modaresimr/auto_profiler\nBy adding a decorator it will show a tree of time-consuming functions\n@Profiler(depth=4, on_disable=show)\nInstall by: pip install auto_profiler\n\nExample\nimport time # line number 1\nimport random\n\nfrom auto_profiler import Profiler, Tree\n\ndef f1():\n    mysleep(.6+random.random())\n\ndef mysleep(t):\n    time.sleep(t)\n\ndef fact(i):\n    f1()\n    if(i==1):\n        return 1\n    return i*fact(i-1)\n\n\ndef show(p):\n    print(&apos;Time   [Hits * PerHit] Function name [Called from] [Function Location]\\n&apos;+\\\n          &apos;-----------------------------------------------------------------------&apos;)\n    print(Tree(p.root, threshold=0.5))\n    \n@Profiler(depth=4, on_disable=show)\ndef main():\n    for i in range(5):\n        f1()\n\n    fact(3)\n\n\nif __name__ == &apos;__main__&apos;:\n    main()\n\n\nExample Output\n\nTime   [Hits * PerHit] Function name [Called from] [function location]\n-----------------------------------------------------------------------\n8.974s [1 * 8.974]  main  [auto-profiler/profiler.py:267]  [/test/t2.py:30]\n 5.954s [5 * 1.191]  f1  [/test/t2.py:34]  [/test/t2.py:14]\n    5.954s [5 * 1.191]  mysleep  [/test/t2.py:15]  [/test/t2.py:17]\n        5.954s [5 * 1.191]  &lt;time.sleep&gt;\n|\n|\n|   # The rest is for the example recursive function call fact\n 3.020s [1 * 3.020]  fact  [/test/t2.py:36]  [/test/t2.py:20]\n     0.849s [1 * 0.849]  f1  [/test/t2.py:21]  [/test/t2.py:14]\n        0.849s [1 * 0.849]  mysleep  [/test/t2.py:15]  [/test/t2.py:17]\n            0.849s [1 * 0.849]  &lt;time.sleep&gt;\n     2.171s [1 * 2.171]  fact  [/test/t2.py:24]  [/test/t2.py:20]\n         1.552s [1 * 1.552]  f1  [/test/t2.py:21]  [/test/t2.py:14]\n            1.552s [1 * 1.552]  mysleep  [/test/t2.py:15]  [/test/t2.py:17]\n         0.619s [1 * 0.619]  fact  [/test/t2.py:24]  [/test/t2.py:20]\n             0.619s [1 * 0.619]  f1  [/test/t2.py:21]  [/test/t2.py:14]\n\n    ","url":"/questions/[slug]#solution27","@type":"Answer","upvoteCount":0},{"text":"\n  Ever want to know what the hell that python script is doing? Enter the\n  Inspect Shell. Inspect Shell lets you print/alter globals and run\n  functions without interrupting the running script. Now with\n  auto-complete and command history (only on linux).\n  \n  Inspect Shell is not a pdb-style debugger.\n\n\nhttps://github.com/amoffat/Inspect-Shell\n\nYou could use that (and your wristwatch).\n    ","url":"/questions/[slug]#solution28","@type":"Answer","upvoteCount":0},{"text":"There&apos;s also a statistical profiler called statprof. It&apos;s a sampling profiler, so it adds minimal overhead to your code and gives line-based (not just function-based) timings. It&apos;s more suited to soft real-time applications like games, but may be have less precision than cProfile.\n\nThe version in pypi is a bit old, so can install it with pip by specifying the git repository:\n\npip install git+git://github.com/bos/statprof.py@1a33eba91899afe17a8b752c6dfdec6f05dd0c01\n\n\nYou can run it like this:\n\nimport statprof\n\nwith statprof.profile():\n    my_questionable_function()\n\n\nSee also https://stackoverflow.com/a/10333592/320036\n    ","url":"/questions/[slug]#solution29","@type":"Answer","upvoteCount":0},{"text":"I found cprofiler and other ressources to be more for optimization purpose rather than debugging.\nI made my own testing module instead for simple python scripts speed testing. (In my case 1K+ lines py file was tested using ScriptProfilerPy and speedup the code by 10x in minutes afterwards.\nThe module ScriptProfilerPy() will run your code adding timestamp to it.\nI put the module here:\nhttps://github.com/Lucas-BLP/ScriptProfilerPy\nUse:\nfrom speed_testpy import ScriptProfilerPy\n\nScriptProfilerPy(&quot;path_to_your_script_to_test.py&quot;).Profiler()\n\noutput:\n\n    ","url":"/questions/[slug]#solution30","@type":"Answer","upvoteCount":0}],"@type":"Question"}}</script><meta name="next-head-count" content="22"/><link rel="preload" href="/_next/static/css/c116652e2d6f4ad0.css" as="style"/><link rel="stylesheet" href="/_next/static/css/c116652e2d6f4ad0.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-0d1b80a048d4787e.js"></script><script src="/_next/static/chunks/webpack-42cdea76c8170223.js" defer=""></script><script src="/_next/static/chunks/framework-4556c45dd113b893.js" defer=""></script><script src="/_next/static/chunks/main-ccfab947c79712f4.js" defer=""></script><script src="/_next/static/chunks/pages/_app-c0d2dcb5e85faf18.js" defer=""></script><script src="/_next/static/chunks/294-106ef8570fa99deb.js" defer=""></script><script src="/_next/static/chunks/490-7f0418bb4354ac73.js" defer=""></script><script src="/_next/static/chunks/pages/questions/%5Bslug%5D-50e201fdaa1e0fd1.js" defer=""></script><script src="/_next/static/DSpI0pSdXueTMCIVyw0q4/_buildManifest.js" defer=""></script><script src="/_next/static/DSpI0pSdXueTMCIVyw0q4/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="wrapper"><header><nav class="bg-white border-gray-200 px-4 lg:px-6 py-2.5 dark:bg-gray-800"><div class="flex flex-wrap justify-between items-center mx-auto max-w-screen-xl"><a class="flex items-center" href="/"><img src="/logo-second.png" class="mr-3 h-6 sm:h-9" alt="Solution Checker Logo"/><h1 class="self-center text-xl font-semibold whitespace-nowrap dark:text-white">Solution Checker</h1></a><div class="flex items-center lg:order-2"><button data-collapse-toggle="mobile-menu-2" type="button" class="inline-flex items-center p-2 ml-1 text-sm text-gray-500 rounded-lg lg:hidden hover:bg-gray-100 focus:outline-none focus:ring-2 focus:ring-gray-200 dark:text-gray-400 dark:hover:bg-gray-700 dark:focus:ring-gray-600" aria-controls="mobile-menu-2" aria-expanded="false"><span class="sr-only">Open main menu</span><svg class="w-6 h-6" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M3 5a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 10a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 15a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1z" clip-rule="evenodd"></path></svg><svg class="hidden w-6 h-6" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M4.293 4.293a1 1 0 011.414 0L10 8.586l4.293-4.293a1 1 0 111.414 1.414L11.414 10l4.293 4.293a1 1 0 01-1.414 1.414L10 11.414l-4.293 4.293a1 1 0 01-1.414-1.414L8.586 10 4.293 5.707a1 1 0 010-1.414z" clip-rule="evenodd"></path></svg></button></div><div class="hidden justify-between items-center w-full lg:flex lg:w-auto lg:order-1" id="mobile-menu-2"><ul class="flex flex-col mt-4 font-medium lg:flex-row lg:space-x-8 lg:mt-0"><li><a class="block py-2 pr-4 pl-3 text-gray-700 border-b border-gray-100 hover:bg-gray-50 lg:hover:bg-transparent lg:border-0 lg:hover:text-blue-700 lg:p-0 dark:text-gray-400 lg:dark:hover:text-white dark:hover:bg-gray-700 dark:hover:text-white lg:dark:hover:bg-transparent dark:border-gray-700" aria-current="page" href="/">Home</a></li><li><a class="block py-2 pr-4 pl-3 text-gray-700 border-b border-gray-100 hover:bg-gray-50 lg:hover:bg-transparent lg:border-0 lg:hover:text-blue-700 lg:p-0 dark:text-gray-400 lg:dark:hover:text-white dark:hover:bg-gray-700 dark:hover:text-white lg:dark:hover:bg-transparent dark:border-gray-700" href="/questions?tab=news">Questions</a></li><li><a class="block py-2 pr-4 pl-3 text-gray-700 border-b border-gray-100 hover:bg-gray-50 lg:hover:bg-transparent lg:border-0 lg:hover:text-blue-700 lg:p-0 dark:text-gray-400 lg:dark:hover:text-white dark:hover:bg-gray-700 dark:hover:text-white lg:dark:hover:bg-transparent dark:border-gray-700" href="/post?tab=news">Post</a></li><li><a class="block py-2 pr-4 pl-3 text-gray-700 border-b border-gray-100 hover:bg-gray-50 lg:hover:bg-transparent lg:border-0 lg:hover:text-blue-700 lg:p-0 dark:text-gray-400 lg:dark:hover:text-white dark:hover:bg-gray-700 dark:hover:text-white lg:dark:hover:bg-transparent dark:border-gray-700" href="/questions/how-do-i-profile-a-python-script-1657388346692#">Coding</a></li></ul></div></div></nav></header><div class="main-content"><div class="question my-5"><div class="flex question-header items-center m-auto justify-center"><div class="rounded-xl w-full border p-5 shadow-md bg-white"><div class="flex w-full items-center justify-between border-b pb-3"><div class="flex items-center space-x-3"><div class="text-lg font-bold text-slate-700"><a href="/questions/how-do-i-profile-a-python-script-1657388346692"><h1>How do I profile a Python script?</h1></a></div></div><div class="flex flex-wrap h-auto justify-end items-center space-x-8"></div></div><div class="question-content mt-5">
                
<p><a href="http://en.wikipedia.org/wiki/Project_Euler" rel="noreferrer">Project Euler</a> and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs. With Python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to <code>__main__</code>.</p>

<p>What is a good way to profile how long a Python program takes to run?</p>
    </div></div></div><div class="solution-section"><nav class="flex pagination-solution flex-col justify-end"><h1 class="text-lg font-semibold mb-5">Navigate to solutions: </h1><ul class="inline-flex -space-x-px overflow-auto"><li class="pagination-solution-item"><span data-id="#solution1" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">1</span></li><li class="pagination-solution-item"><span data-id="#solution2" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">2</span></li><li class="pagination-solution-item"><span data-id="#solution3" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">3</span></li><li class="pagination-solution-item"><span data-id="#solution4" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">4</span></li><li class="pagination-solution-item"><span data-id="#solution5" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">5</span></li><li class="pagination-solution-item"><span data-id="#solution6" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">6</span></li><li class="pagination-solution-item"><span data-id="#solution7" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">7</span></li><li class="pagination-solution-item"><span data-id="#solution8" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">8</span></li><li class="pagination-solution-item"><span data-id="#solution9" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">9</span></li><li class="pagination-solution-item"><span data-id="#solution10" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">10</span></li><li class="pagination-solution-item"><span data-id="#solution11" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">11</span></li><li class="pagination-solution-item"><span data-id="#solution12" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">12</span></li><li class="pagination-solution-item"><span data-id="#solution13" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">13</span></li><li class="pagination-solution-item"><span data-id="#solution14" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">14</span></li><li class="pagination-solution-item"><span data-id="#solution15" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">15</span></li><li class="pagination-solution-item"><span data-id="#solution16" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">16</span></li><li class="pagination-solution-item"><span data-id="#solution17" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">17</span></li><li class="pagination-solution-item"><span data-id="#solution18" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">18</span></li><li class="pagination-solution-item"><span data-id="#solution19" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">19</span></li><li class="pagination-solution-item"><span data-id="#solution20" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">20</span></li><li class="pagination-solution-item"><span data-id="#solution21" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">21</span></li><li class="pagination-solution-item"><span data-id="#solution22" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">22</span></li><li class="pagination-solution-item"><span data-id="#solution23" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">23</span></li><li class="pagination-solution-item"><span data-id="#solution24" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">24</span></li><li class="pagination-solution-item"><span data-id="#solution25" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">25</span></li><li class="pagination-solution-item"><span data-id="#solution26" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">26</span></li><li class="pagination-solution-item"><span data-id="#solution27" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">27</span></li><li class="pagination-solution-item"><span data-id="#solution28" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">28</span></li><li class="pagination-solution-item"><span data-id="#solution29" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">29</span></li><li class="pagination-solution-item"><span data-id="#solution30" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">30</span></li></ul></nav><div id="solution1" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 1</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>Python includes a profiler called <a href="https://docs.python.org/3/library/profile.html#module-cProfile" rel="noreferrer">cProfile</a>. It not only gives the total running time, but also times each function separately, and tells you how many times each function was called, making it easy to determine where you should make optimizations.</p>

<p>You can call it from within your code, or from the interpreter, like this:</p>

<pre class="lang-py s-code-block"><code class="hljs language-python"><span class="hljs-keyword">import</span> cProfile
cProfile.run(<span class="hljs-string">'foo()'</span>)
</code></pre>

<p>Even more usefully, you can invoke the cProfile when running a script:</p>

<pre class="lang-py s-code-block"><code class="hljs language-python">python -m cProfile myscript.py
</code></pre>

<p>To make it even easier, I made a little batch file called 'profile.bat':</p>

<pre class="lang-py s-code-block"><code class="hljs language-python">python -m cProfile %<span class="hljs-number">1</span>
</code></pre>

<p>So all I have to do is run:</p>

<pre class="lang-py s-code-block"><code class="hljs language-python">profile euler048.py
</code></pre>

<p>And I get this:</p>

<pre class="lang-none s-code-block"><code>1007 function calls in 0.061 CPU seconds

Ordered by: standard name
ncalls  tottime  percall  cumtime  percall filename:lineno(function)
    1    0.000    0.000    0.061    0.061 &lt;string&gt;:1(&lt;module&gt;)
 1000    0.051    0.000    0.051    0.000 euler048.py:2(&lt;lambda&gt;)
    1    0.005    0.005    0.061    0.061 euler048.py:2(&lt;module&gt;)
    1    0.000    0.000    0.061    0.061 {execfile}
    1    0.002    0.002    0.053    0.053 {map}
    1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler objects}
    1    0.000    0.000    0.000    0.000 {range}
    1    0.003    0.003    0.003    0.003 {sum}
</code></pre>

<p>EDIT: Updated link to a good video resource from PyCon 2013 titled 
<a href="https://web.archive.org/web/20170318204046/http://lanyrd.com/2013/pycon/scdywg/" rel="noreferrer"><strong><em>Python Profiling</em></strong></a><br>
<a href="https://www.youtube.com/watch?v=QJwVYlDzAXs" rel="noreferrer">Also via YouTube</a>.</p>
    </div></div></div></div><div id="solution2" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 2</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>A while ago I made <a href="http://pycallgraph.slowchop.com/" rel="noreferrer"><code>pycallgraph</code></a> which generates a visualisation from your Python code. <strong>Edit:</strong> I've updated the example to work with 3.3, the latest release as of this writing.</p>

<p>After a <code>pip install pycallgraph</code> and installing <a href="http://www.graphviz.org/" rel="noreferrer">GraphViz</a> you can run it from the command line:</p>

<pre class="lang-py s-code-block"><code class="hljs language-python">pycallgraph graphviz -- ./mypythonscript.py
</code></pre>

<p>Or, you can profile particular parts of your code:</p>

<pre class="lang-py s-code-block"><code class="hljs language-python"><span class="hljs-keyword">from</span> pycallgraph <span class="hljs-keyword">import</span> PyCallGraph
<span class="hljs-keyword">from</span> pycallgraph.output <span class="hljs-keyword">import</span> GraphvizOutput

<span class="hljs-keyword">with</span> PyCallGraph(output=GraphvizOutput()):
    code_to_profile()
</code></pre>

<p>Either of these will generate a <code>pycallgraph.png</code> file similar to the image below:</p>

<p><img src="https://i.stack.imgur.com/aiNEA.png" alt="enter image description here"></p>
    </div></div></div></div><div id="solution3" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 3</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>It's worth pointing out that using the profiler only works (by default) on the main thread, and you won't get any information from other threads if you use them.  This can be a bit of a gotcha as it is completely unmentioned in the <a href="http://docs.python.org/library/profile.html" rel="noreferrer">profiler documentation</a>.</p>

<p>If you also want to profile threads, you'll want to look at the <a href="http://docs.python.org/library/threading.html#threading.setprofile" rel="noreferrer" title="threading.setprofile() function"><code>threading.setprofile()</code> function</a> in the docs.</p>

<p>You could also create your own <code>threading.Thread</code> subclass to do it:</p>

<pre class="lang-py s-code-block"><code class="hljs language-python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">ProfiledThread</span>(threading.Thread):
    <span class="hljs-comment"># Overrides threading.Thread.run()</span>
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">run</span>(<span class="hljs-params">self</span>):
        profiler = cProfile.Profile()
        <span class="hljs-keyword">try</span>:
            <span class="hljs-keyword">return</span> profiler.runcall(threading.Thread.run, self)
        <span class="hljs-keyword">finally</span>:
            profiler.dump_stats(<span class="hljs-string">'myprofile-%d.profile'</span> % (self.ident,))
</code></pre>

<p>and use that <code>ProfiledThread</code> class instead of the standard one.  It might give you more flexibility, but I'm not sure it's worth it, especially if you are using third-party code which wouldn't use your class.</p>
    </div></div></div></div><div id="solution4" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 4</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>The python wiki is a great page for profiling resources:
<a href="http://wiki.python.org/moin/PythonSpeed/PerformanceTips#Profiling_Code" rel="noreferrer">http://wiki.python.org/moin/PythonSpeed/PerformanceTips#Profiling_Code</a></p>

<p>as is the python docs:
<a href="http://docs.python.org/library/profile.html" rel="noreferrer">http://docs.python.org/library/profile.html</a></p>

<p>as shown by Chris Lawlor cProfile is a great tool and can easily be used to print to the screen:</p>

<pre class="lang-py s-code-block"><code class="hljs language-python">python -m cProfile -s time mine.py &lt;args&gt;
</code></pre>

<p>or to file:</p>

<pre class="lang-py s-code-block"><code class="hljs language-python">python -m cProfile -o output.file mine.py &lt;args&gt;
</code></pre>

<p>PS&gt; If you are using Ubuntu, make sure to install python-profile</p>

<pre class="lang-py s-code-block"><code class="hljs language-python">apt-get install python-profiler 
</code></pre>

<p>If you output to file you can get nice visualizations using the following tools</p>

<p>PyCallGraph : a tool to create call graph images <br>
  install:<br></p>

<pre class="lang-py s-code-block"><code class="hljs language-python"> pip install pycallgraph
</code></pre>

<p>run:</p>

<pre class="lang-py s-code-block"><code class="hljs language-python"> pycallgraph mine.py args
</code></pre>

<p>view:</p>

<pre class="lang-py s-code-block"><code class="hljs language-python"> gimp pycallgraph.png
</code></pre>

<p><em>You can use whatever you like to view the png file, I used gimp</em><br>
Unfortunately I often get </p>

<p>dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.257079 to fit</p>

<p>which makes my images unusably small.  So I generally create svg files:</p>

<pre class="lang-py s-code-block"><code class="hljs language-python">pycallgraph -f svg -o pycallgraph.svg mine.py &lt;args&gt;
</code></pre>

<p>PS&gt; make sure to install graphviz (which provides the dot program):</p>

<pre class="lang-py s-code-block"><code class="hljs language-python">pip install graphviz
</code></pre>

<p>Alternative Graphing using gprof2dot via @maxy / @quodlibetor :</p>

<pre class="lang-py s-code-block"><code class="hljs language-python">pip install gprof2dot
python -m cProfile -o profile.pstats mine.py
gprof2dot -f pstats profile.pstats | dot -Tsvg -o mine.svg
</code></pre>
    </div></div></div></div><div id="solution5" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 5</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>@Maxy's comment on <a href="https://stackoverflow.com/a/7693928/25616">this answer</a> helped me out enough that I think it deserves its own answer: I already had cProfile-generated .pstats files and I didn't want to re-run things with pycallgraph, so I used <a href="https://github.com/jrfonseca/gprof2dot" rel="noreferrer">gprof2dot</a>, and got pretty svgs:</p>
<pre class="lang-py s-code-block"><code class="hljs language-python">$ sudo apt-get install graphviz
$ git clone https://github.com/jrfonseca/gprof2dot
$ ln -s <span class="hljs-string">"$PWD"</span>/gprof2dot/gprof2dot.py ~/<span class="hljs-built_in">bin</span>
$ cd $PROJECT_DIR
$ gprof2dot.py -f pstats profile.pstats | dot -Tsvg -o callgraph.svg
</code></pre>
<p>and BLAM!</p>
<p>It uses dot (the same thing that pycallgraph uses) so output looks similar. I get the impression that gprof2dot loses less information though:</p>
<p><a href="https://i.stack.imgur.com/JjSvt.png" rel="noreferrer"><img src="https://i.stack.imgur.com/JjSvt.png" alt="gprof2dot example output"></a></p>
    </div></div></div></div><div id="solution6" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 6</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p><strong>Simplest</strong> and <strong>quickest</strong> way to find where all the time is going.</p>

<pre class="lang-py s-code-block"><code class="hljs language-python"><span class="hljs-number">1.</span> pip install snakeviz

<span class="hljs-number">2.</span> python -m cProfile -o temp.dat &lt;PROGRAM&gt;.py

<span class="hljs-number">3.</span> snakeviz temp.dat
</code></pre>

<p>Draws a pie chart in a browser. Biggest piece is the problem function. Very simple.</p>
    </div></div></div></div><div id="solution7" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 7</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>I ran into a handy tool called <a href="https://jiffyclub.github.io/snakeviz/">SnakeViz</a> when researching this topic. SnakeViz is a web-based profiling visualization tool. It is very easy to install and use. The usual way I use it is to generate a stat file with <code>%prun</code> and then do analysis in SnakeViz.</p>

<p>The main viz technique used is <strong>Sunburst chart</strong> as shown below, in which the hierarchy of function calls is arranged as layers of arcs and time info encoded in their angular widths.</p>

<p>The best thing is you can interact with the chart. For example, to zoom in one can click on an arc, and the arc and its descendants will be enlarged as a new sunburst to display more details.</p>

<p><a href="https://i.stack.imgur.com/kCmSY.png"><img src="https://i.stack.imgur.com/kCmSY.png" alt="enter image description here"></a></p>
    </div></div></div></div><div id="solution8" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 8</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p><a href="https://docs.python.org/2/library/profile.html" rel="noreferrer"><code>cProfile</code></a> is great for profiling, while <a href="https://kcachegrind.github.io/html/Home.html" rel="noreferrer"><code>kcachegrind</code></a> is great for visualizing the results. The <a href="https://pypi.python.org/pypi/pyprof2calltree" rel="noreferrer"><code>pyprof2calltree</code></a> in between handles the file conversion.</p>
<pre class="lang-py s-code-block"><code class="hljs language-python">python -m cProfile -o script.profile script.py
pyprof2calltree -i script.profile -o script.calltree
kcachegrind script.calltree
</code></pre>
<p>Required system packages:</p>
<ul>
<li><code>kcachegrind</code> (Linux), <code>qcachegrind</code> (MacOs)</li>
</ul>
<p>Setup on Ubuntu:</p>
<pre class="lang-py s-code-block"><code class="hljs language-python">apt-get install kcachegrind 
pip install pyprof2calltree
</code></pre>
<p>The result:</p>
<p><a href="https://i.stack.imgur.com/1TFZe.png" rel="noreferrer"><img src="https://i.stack.imgur.com/1TFZe.png" alt="Screenshot of the result"></a></p>
    </div></div></div></div><div id="solution9" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 9</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>I recently created <a href="https://github.com/nschloe/tuna" rel="noreferrer">tuna</a> for visualizing Python runtime and import profiles; this may be helpful here.</p>
<p><a href="https://i.stack.imgur.com/ZpP6M.gif" rel="noreferrer"><img src="https://i.stack.imgur.com/ZpP6M.gif" alt="enter image description here"></a></p>
<p>Install with</p>
<pre class="lang-py s-code-block"><code class="hljs language-python">pip install tuna
</code></pre>
<p>Create a runtime profile</p>
<pre class="lang-py s-code-block"><code class="hljs language-python">python3 -m cProfile -o program.prof yourfile.py
</code></pre>
<p>or an import profile (Python 3.7+ required)</p>
<pre class="lang-py s-code-block"><code class="hljs language-python">python3 -X importprofile yourfile.py <span class="hljs-number">2</span>&gt; <span class="hljs-keyword">import</span>.log
</code></pre>
<p>Then just run tuna on the file</p>
<pre class="lang-py s-code-block"><code class="hljs language-python">tuna program.prof
</code></pre>
    </div></div></div></div><div id="solution10" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 10</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>Also worth mentioning is the GUI cProfile dump viewer <a href="http://www.vrplumber.com/programming/runsnakerun/">RunSnakeRun</a>.  It allows you to sort and select, thereby zooming in on the relevant parts of the program.  The sizes of the rectangles in the picture is proportional to the time taken.  If you mouse over a rectangle it highlights that call in the table and everywhere on the map.  When you double-click on a rectangle it zooms in on that portion.  It will show you who calls that portion and what that portion calls.</p>

<p>The descriptive information is very helpful.  It shows you the code for that bit which can be helpful when you are dealing with built-in library calls.  It tells you what file and what line to find the code.</p>

<p>Also want to point at that the OP said 'profiling' but it appears he meant 'timing'.  Keep in mind programs will run slower when profiled.</p>

<p><img src="https://i.stack.imgur.com/2GahD.png" alt="enter image description here"></p>
    </div></div></div></div><div id="solution11" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 11</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<h1>pprofile</h1>

<p><code>line_profiler</code> (already presented here) also inspired  <a href="https://github.com/vpelletier/pprofile" rel="noreferrer"><code>pprofile</code></a>, which is described as:</p>

<blockquote>
  <p>Line-granularity, thread-aware deterministic and statistic pure-python
  profiler</p>
</blockquote>

<p>It provides line-granularity as <code>line_profiler</code>, is pure Python, can be used as a standalone command or a module, and can even generate callgrind-format files that can be easily analyzed with <code>[k|q]cachegrind</code>.</p>

<h1>vprof</h1>

<p>There is also <a href="https://github.com/nvdv/vprof" rel="noreferrer">vprof</a>, a Python package described as:</p>

<blockquote>
  <p>[...] providing rich and interactive visualizations for various Python program characteristics such as running time and memory usage.</p>
</blockquote>

<p><a href="https://i.stack.imgur.com/uafO3.png" rel="noreferrer"><img src="https://i.stack.imgur.com/uafO3.png" alt="heatmap"></a></p>
    </div></div></div></div><div id="solution12" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 12</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>A nice profiling module is the line_profiler (called using the script kernprof.py).  It can be downloaded <a href="http://packages.python.org/line_profiler/" rel="noreferrer">here</a>.</p>

<p>My understanding is that cProfile only gives information about total time spent in each function.  So individual lines of code are not timed.  This is an issue in scientific computing since often one single line can take a lot of time.  Also, as I remember, cProfile didn't catch the time I was spending in say numpy.dot.</p>
    </div></div></div></div><div id="solution13" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 13</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>The terminal-only (and simplest) solution, in case all those fancy UI's fail to install or to run:<br>
ignore <code>cProfile</code> completely and replace it with <code>pyinstrument</code>, that will collect and display the tree of calls right after execution.</p>

<p>Install:  </p>

<pre class="lang-py s-code-block"><code class="hljs language-python">$ pip install pyinstrument
</code></pre>

<p>Profile and display result:  </p>

<pre class="lang-py s-code-block"><code class="hljs language-python">$ python -m pyinstrument ./prog.py
</code></pre>

<p>Works with python2 and 3.</p>

<p>[EDIT]
The documentation of the API, for profiling only a part of the code, can be found <a href="https://github.com/joerick/pyinstrument#profile-a-specific-chunk-of-code" rel="noreferrer">here</a>.</p>
    </div></div></div></div><div id="solution14" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 14</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>There's a lot of great answers but they either use command line or some external program for profiling and/or sorting the results.</p>
<p>I really missed some way I could use in my IDE (eclipse-PyDev) without touching the command line or installing anything. So here it is.</p>
<h1>Profiling without command line</h1>
<pre class="lang-py s-code-block"><code class="hljs language-python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">count</span>():
    <span class="hljs-keyword">from</span> math <span class="hljs-keyword">import</span> sqrt
    <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>**<span class="hljs-number">5</span>):
        sqrt(x)

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    <span class="hljs-keyword">import</span> cProfile, pstats
    cProfile.run(<span class="hljs-string">"count()"</span>, <span class="hljs-string">"{}.profile"</span>.<span class="hljs-built_in">format</span>(__file__))
    s = pstats.Stats(<span class="hljs-string">"{}.profile"</span>.<span class="hljs-built_in">format</span>(__file__))
    s.strip_dirs()
    s.sort_stats(<span class="hljs-string">"time"</span>).print_stats(<span class="hljs-number">10</span>)
</code></pre>
<p>See <a href="https://docs.python.org/3.4/library/profile.html" rel="noreferrer">docs</a> or other answers for more info.</p>
    </div></div></div></div><div id="solution15" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 15</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>Following Joe Shaw's answer about multi-threaded code not to work as expected, I figured that the <code>runcall</code> method in cProfile is merely doing <code>self.enable()</code> and <code>self.disable()</code> calls around the profiled function call, so you can simply do that yourself and have whatever code you want in-between with minimal interference with existing code.</p>
    </div></div></div></div><div id="solution16" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 16</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>With a statistical profiler like <a href="https://github.com/P403n1x87/austin" rel="noreferrer">austin</a>, no instrumentation is required, meaning that you can get profiling data out of a Python application simply with</p>
<pre class="lang-py s-code-block"><code class="hljs language-python">austin python3 my_script.py
</code></pre>
<p>The raw output isn't very useful, but you can pipe that to <a href="https://github.com/brendangregg/FlameGraph/blob/master/flamegraph.pl" rel="noreferrer">flamegraph.pl</a>
to get a flame graph representation of that data that gives you a breakdown of where the time (measured in microseconds of real time) is being spent.</p>
<pre class="lang-py s-code-block"><code class="hljs language-python">austin python3 my_script.py | flamegraph.pl &gt; my_script_profile.svg
</code></pre>
<p>Alternatively, you can also use the web application <a href="http://speedscope.app/" rel="noreferrer">Speedscope.app</a> for quick visualisation of the collected samples. If you have <a href="https://github.com/google/pprof" rel="noreferrer">pprof</a> installed, you can also get <a href="https://github.com/P403n1x87/austin-python" rel="noreferrer">austin-python</a> (with e.g. <code>pipx install austin-python</code>) and use the <code>austin2pprof</code> to covert to the pprof format.</p>
<p>However, if you have VS Code installed you could use the <a href="https://marketplace.visualstudio.com/items?itemName=p403n1x87.austin-vscode" rel="noreferrer">Austin extension</a> for a more interactive experience, with source code heat maps, top functions and collected call stacks</p>
<p><img src="https://github.com/P403n1x87/austin-vscode/raw/main/art/demo.gif" alt="Austin VS Code extension"></p>
    </div></div></div></div><div id="solution17" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 17</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>In Virtaal's <a href="https://github.com/translate/virtaal/blob/master/devsupport/profiling.py" rel="nofollow noreferrer">source</a> there's a very useful class and decorator that can make profiling (even for specific methods/functions) very easy. The output can then be viewed very comfortably in KCacheGrind.</p>
    </div></div></div></div><div id="solution18" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 18</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>If you want to make a cumulative profiler,
meaning to run the function several times in a row and watch the sum of the results.</p>

<p>you can use this <code>cumulative_profiler</code> decorator:</p>

<p>it's python &gt;= 3.6 specific, but you can remove <code>nonlocal</code> for it work on older versions.</p>

<pre class="lang-py s-code-block"><code class="hljs language-python"><span class="hljs-keyword">import</span> cProfile, pstats

<span class="hljs-keyword">class</span> <span class="hljs-title class_">_ProfileFunc</span>:
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, func, sort_stats_by</span>):
        self.func =  func
        self.profile_runs = []
        self.sort_stats_by = sort_stats_by

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__call__</span>(<span class="hljs-params">self, *args, **kwargs</span>):
        pr = cProfile.Profile()
        pr.enable()  <span class="hljs-comment"># this is the profiling section</span>
        retval = self.func(*args, **kwargs)
        pr.disable()

        self.profile_runs.append(pr)
        ps = pstats.Stats(*self.profile_runs).sort_stats(self.sort_stats_by)
        <span class="hljs-keyword">return</span> retval, ps

<span class="hljs-keyword">def</span> <span class="hljs-title function_">cumulative_profiler</span>(<span class="hljs-params">amount_of_times, sort_stats_by=<span class="hljs-string">'time'</span></span>):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">real_decorator</span>(<span class="hljs-params">function</span>):
        <span class="hljs-keyword">def</span> <span class="hljs-title function_">wrapper</span>(<span class="hljs-params">*args, **kwargs</span>):
            <span class="hljs-keyword">nonlocal</span> function, amount_of_times, sort_stats_by  <span class="hljs-comment"># for python 2.x remove this row</span>

            profiled_func = _ProfileFunc(function, sort_stats_by)
            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(amount_of_times):
                retval, ps = profiled_func(*args, **kwargs)
            ps.print_stats()
            <span class="hljs-keyword">return</span> retval  <span class="hljs-comment"># returns the results of the function</span>
        <span class="hljs-keyword">return</span> wrapper

    <span class="hljs-keyword">if</span> <span class="hljs-built_in">callable</span>(amount_of_times):  <span class="hljs-comment"># incase you don't want to specify the amount of times</span>
        func = amount_of_times  <span class="hljs-comment"># amount_of_times is the function in here</span>
        amount_of_times = <span class="hljs-number">5</span>  <span class="hljs-comment"># the default amount</span>
        <span class="hljs-keyword">return</span> real_decorator(func)
    <span class="hljs-keyword">return</span> real_decorator
</code></pre>

<p><strong>Example</strong></p>

<p>profiling the function <code>baz</code> </p>

<pre class="lang-py s-code-block"><code class="hljs language-python"><span class="hljs-keyword">import</span> time

<span class="hljs-meta">@cumulative_profiler</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">baz</span>():
    time.sleep(<span class="hljs-number">1</span>)
    time.sleep(<span class="hljs-number">2</span>)
    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>

baz()
</code></pre>

<p><code>baz</code> ran 5 times and printed this:</p>

<pre class="lang-py s-code-block"><code class="hljs language-python">         <span class="hljs-number">20</span> function calls <span class="hljs-keyword">in</span> <span class="hljs-number">15.003</span> seconds

   Ordered by: internal time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
       <span class="hljs-number">10</span>   <span class="hljs-number">15.003</span>    <span class="hljs-number">1.500</span>   <span class="hljs-number">15.003</span>    <span class="hljs-number">1.500</span> {built-<span class="hljs-keyword">in</span> method time.sleep}
        <span class="hljs-number">5</span>    <span class="hljs-number">0.000</span>    <span class="hljs-number">0.000</span>   <span class="hljs-number">15.003</span>    <span class="hljs-number">3.001</span> &lt;ipython-<span class="hljs-built_in">input</span>-<span class="hljs-number">9</span>-c89afe010372&gt;:<span class="hljs-number">3</span>(baz)
        <span class="hljs-number">5</span>    <span class="hljs-number">0.000</span>    <span class="hljs-number">0.000</span>    <span class="hljs-number">0.000</span>    <span class="hljs-number">0.000</span> {method <span class="hljs-string">'disable'</span> of <span class="hljs-string">'_lsprof.Profiler'</span> objects}
</code></pre>

<p>specifying the amount of times</p>

<pre class="lang-py s-code-block"><code class="hljs language-python"><span class="hljs-meta">@cumulative_profiler(<span class="hljs-params"><span class="hljs-number">3</span></span>)</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">baz</span>():
    ...
</code></pre>
    </div></div></div></div><div id="solution19" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 19</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>For getting quick profile stats on an IPython notebook.
One can embed <strong>line_profiler</strong> and <strong>memory_profiler</strong> straight into their notebooks.</p>
<p>Another useful package is <strong>Pympler</strong>. It is a powerful profiling package that's capable to track classes,objects,functions,memory leaks etc. Examples below, Docs attached.</p>
<h2>Get it!</h2>
<pre class="lang-py s-code-block"><code class="hljs language-python">!pip install line_profiler
!pip install memory_profiler
!pip install pympler
</code></pre>
<h2>Load it!</h2>
<pre class="lang-py s-code-block"><code class="hljs language-python">%load_ext line_profiler
%load_ext memory_profiler
</code></pre>
<h2>Use it!</h2>
<hr>
<h1>%time</h1>
<pre class="lang-py s-code-block"><code class="hljs language-python">%time <span class="hljs-built_in">print</span>(<span class="hljs-string">'Outputs CPU time,Wall Clock time'</span>) 
<span class="hljs-comment">#CPU times: user 2 µs, sys: 0 ns, total: 2 µs Wall time: 5.96 µs</span>
</code></pre>
<p>Gives:</p>
<ul>
<li>CPU times: CPU level execution time</li>
<li>sys times: system level execution time</li>
<li>total: CPU time + system time</li>
<li>Wall time: Wall Clock Time</li>
</ul>
<hr>
<h1>%timeit</h1>
<pre class="lang-py s-code-block"><code class="hljs language-python">%timeit -r <span class="hljs-number">7</span> -n <span class="hljs-number">1000</span> <span class="hljs-built_in">print</span>(<span class="hljs-string">'Outputs execution time of the snippet'</span>) 
<span class="hljs-comment">#1000 loops, best of 7: 7.46 ns per loop</span>
</code></pre>
<ul>
<li>Gives best time out of given number of runs(r) in looping (n) times.</li>
<li>Outputs details on system caching:
<ul>
<li>When code snippets are executed multiple times, system caches a few opearations and doesn't execute them again that may hamper the accuracy of the profile reports.</li>
</ul>
</li>
</ul>
<hr>
<h1>%prun</h1>
<pre class="lang-py s-code-block"><code class="hljs language-python">%prun -s cumulative <span class="hljs-string">'Code to profile'</span> 
</code></pre>
<p>Gives:</p>
<ul>
<li>number of function calls(ncalls)</li>
<li>has entries per function call(distinct)</li>
<li>time taken per call(percall)</li>
<li>time elapsed till that function call(cumtime)</li>
<li>name of the func/module called etc...</li>
</ul>
<p><a href="https://i.stack.imgur.com/1IkgA.png" rel="noreferrer"><img src="https://i.stack.imgur.com/1IkgA.png" alt="Cumulative profile"></a></p>
<hr>
<h1>%memit</h1>
<pre class="lang-py s-code-block"><code class="hljs language-python">%memit <span class="hljs-string">'Code to profile'</span>
<span class="hljs-comment">#peak memory: 199.45 MiB, increment: 0.00 MiB</span>
</code></pre>
<p>Gives:</p>
<ul>
<li>Memory usage</li>
</ul>
<hr>
<h1>%lprun</h1>
<pre class="lang-py s-code-block"><code class="hljs language-python"><span class="hljs-comment">#Example function</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">fun</span>():
  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">10</span>):
    <span class="hljs-built_in">print</span>(i)

<span class="hljs-comment">#Usage: %lprun &lt;name_of_the_function&gt; function</span>
%lprun -f fun fun()
</code></pre>
<p>Gives:</p>
<ul>
<li>Line wise stats</li>
</ul>
<p><a href="https://i.stack.imgur.com/rusPA.png" rel="noreferrer"><img src="https://i.stack.imgur.com/rusPA.png" alt="LineProfile"></a></p>
<hr>
<h1>sys.getsizeof</h1>
<pre class="lang-py s-code-block"><code class="hljs language-python">sys.getsizeof(<span class="hljs-string">'code to profile'</span>)
<span class="hljs-comment"># 64 bytes</span>
</code></pre>
<p>Returns the size of an object in bytes.</p>
<hr>
<h1>asizeof() from pympler</h1>
<pre class="lang-py s-code-block"><code class="hljs language-python"><span class="hljs-keyword">from</span> pympler <span class="hljs-keyword">import</span> asizeof
obj = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,(<span class="hljs-string">"hey"</span>,<span class="hljs-string">"ha"</span>),<span class="hljs-number">3</span>]
<span class="hljs-built_in">print</span>(asizeof.asizeof(obj,stats=<span class="hljs-number">4</span>))

</code></pre>
<p>pympler.asizeof can be used to investigate how much memory certain Python objects consume.
In contrast to sys.getsizeof, asizeof sizes objects recursively</p>
<p><a href="https://i.stack.imgur.com/8jxQX.png" rel="noreferrer"><img src="https://i.stack.imgur.com/8jxQX.png" alt="pympler.asizeof"></a></p>
<hr>
<h1>tracker from pympler</h1>
<pre class="lang-py s-code-block"><code class="hljs language-python"><span class="hljs-keyword">from</span> pympler <span class="hljs-keyword">import</span> tracker
tr = tracker.SummaryTracker()
<span class="hljs-keyword">def</span> <span class="hljs-title function_">fun</span>():
  li = [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>]
  di = {<span class="hljs-string">"ha"</span>:<span class="hljs-string">"haha"</span>,<span class="hljs-string">"duh"</span>:<span class="hljs-string">"Umm"</span>}
fun()
tr.print_diff()
</code></pre>
<p>Tracks the lifetime of a function.</p>
<p><a href="https://i.stack.imgur.com/SrRj9.png" rel="noreferrer"><img src="https://i.stack.imgur.com/SrRj9.png" alt="tracker output"></a></p>
<p>Pympler package consists of a huge number of high utility functions to profile code. All of which cannot be covered here. See the documentation attached for verbose profile implementations.</p>
<h3>Pympler <a href="https://readthedocs.org/projects/pympler/downloads/pdf/latest/" rel="noreferrer">doc</a></h3>
    </div></div></div></div><div id="solution20" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 20</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>Recently I created a plugin for PyCharm with which you can easily analyse and visualise the results of <code>line_profiler</code> in the PyCharm editor.</p>
<p><code>line_profiler</code> has been mentioned in other answers as well and is a great tool to analyse exactly how much time is spent by the python interpreter in certain lines.</p>
<p>The PyCharm plugin I've created can be found here:
<a href="https://plugins.jetbrains.com/plugin/16536-line-profiler" rel="noreferrer">https://plugins.jetbrains.com/plugin/16536-line-profiler</a></p>
<p>It needs a helper package in your python environment called <code>line-profiler-pycharm</code> which can be installed with pip or by the plugin itself.</p>
<p>After installing the plugin in PyCharm:</p>
<ol>
<li>Decorate any function you want to profile with the <code>line_profiler_pycharm.profile</code> decorator</li>
<li>Run with the 'Profile Lines' runner</li>
</ol>
<p>Screenshot of results:
<a href="https://i.stack.imgur.com/nj0LP.png" rel="noreferrer"><img src="https://i.stack.imgur.com/nj0LP.png" alt="Line Profiler Pycharm results"></a></p>
    </div></div></div></div><div id="solution21" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 21</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>cProfile is great for quick profiling but most of the time it was ending for me with the errors. Function runctx solves this problem by initializing correctly the environment and variables, hope it can be useful for someone:</p>

<pre class="lang-py s-code-block"><code class="hljs language-python"><span class="hljs-keyword">import</span> cProfile
cProfile.runctx(<span class="hljs-string">'foo()'</span>, <span class="hljs-literal">None</span>, <span class="hljs-built_in">locals</span>())
</code></pre>
    </div></div></div></div><div id="solution22" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 22</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p><strong>gprof2dot_magic</strong></p>

<p>Magic function for <code>gprof2dot</code> to profile any Python statement as a DOT graph in JupyterLab or Jupyter Notebook.</p>

<p><a href="https://i.stack.imgur.com/IE4Py.gif" rel="noreferrer"><img src="https://i.stack.imgur.com/IE4Py.gif" alt="enter image description here"></a></p>

<p>GitHub repo: <a href="https://github.com/mattijn/gprof2dot_magic" rel="noreferrer">https://github.com/mattijn/gprof2dot_magic</a></p>

<p><strong>installation</strong></p>

<p>Make sure you've the Python package <code>gprof2dot_magic</code>.</p>

<pre class="lang-py s-code-block"><code class="hljs language-python">pip install gprof2dot_magic
</code></pre>

<p>Its dependencies <code>gprof2dot</code> and <code>graphviz</code> will be installed as well</p>

<p><strong>usage</strong></p>

<p>To enable the magic function, first load the <code>gprof2dot_magic</code> module</p>

<pre class="lang-py s-code-block"><code class="hljs language-python">%load_ext gprof2dot_magic
</code></pre>

<p>and then profile any line statement as a DOT graph as such:</p>

<pre class="lang-py s-code-block"><code class="hljs language-python">%gprof2dot <span class="hljs-built_in">print</span>(<span class="hljs-string">'hello world'</span>)
</code></pre>

<p><a href="https://i.stack.imgur.com/fiGeD.png" rel="noreferrer"><img src="https://i.stack.imgur.com/fiGeD.png" alt="enter image description here"></a></p>
    </div></div></div></div><div id="solution23" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 23</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>My way is to use yappi (<a href="https://github.com/sumerc/yappi" rel="nofollow noreferrer">https://github.com/sumerc/yappi</a>). It's especially useful combined with an RPC server where (even just for debugging) you register method to start, stop and print profiling information, e.g. in this way: </p>

<pre class="lang-py s-code-block"><code class="hljs language-python"><span class="hljs-meta">@staticmethod</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">startProfiler</span>():
    yappi.start()

<span class="hljs-meta">@staticmethod</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">stopProfiler</span>():
    yappi.stop()

<span class="hljs-meta">@staticmethod</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">printProfiler</span>():
    stats = yappi.get_stats(yappi.SORTTYPE_TTOT, yappi.SORTORDER_DESC, <span class="hljs-number">20</span>)
    statPrint = <span class="hljs-string">'\n'</span>
    namesArr = [<span class="hljs-built_in">len</span>(<span class="hljs-built_in">str</span>(stat[<span class="hljs-number">0</span>])) <span class="hljs-keyword">for</span> stat <span class="hljs-keyword">in</span> stats.func_stats]
    log.debug(<span class="hljs-string">"namesArr %s"</span>, <span class="hljs-built_in">str</span>(namesArr))
    maxNameLen = <span class="hljs-built_in">max</span>(namesArr)
    log.debug(<span class="hljs-string">"maxNameLen: %s"</span>, maxNameLen)

    <span class="hljs-keyword">for</span> stat <span class="hljs-keyword">in</span> stats.func_stats:
        nameAppendSpaces = [<span class="hljs-string">' '</span> <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(maxNameLen - <span class="hljs-built_in">len</span>(stat[<span class="hljs-number">0</span>]))]
        log.debug(<span class="hljs-string">'nameAppendSpaces: %s'</span>, nameAppendSpaces)
        blankSpace = <span class="hljs-string">''</span>
        <span class="hljs-keyword">for</span> space <span class="hljs-keyword">in</span> nameAppendSpaces:
            blankSpace += space

        log.debug(<span class="hljs-string">"adding spaces: %s"</span>, <span class="hljs-built_in">len</span>(nameAppendSpaces))
        statPrint = statPrint + <span class="hljs-built_in">str</span>(stat[<span class="hljs-number">0</span>]) + blankSpace + <span class="hljs-string">" "</span> + <span class="hljs-built_in">str</span>(stat[<span class="hljs-number">1</span>]).ljust(<span class="hljs-number">8</span>) + <span class="hljs-string">"\t"</span> + <span class="hljs-built_in">str</span>(
            <span class="hljs-built_in">round</span>(stat[<span class="hljs-number">2</span>], <span class="hljs-number">2</span>)).ljust(<span class="hljs-number">8</span> - <span class="hljs-built_in">len</span>(<span class="hljs-built_in">str</span>(stat[<span class="hljs-number">2</span>]))) + <span class="hljs-string">"\t"</span> + <span class="hljs-built_in">str</span>(<span class="hljs-built_in">round</span>(stat[<span class="hljs-number">3</span>], <span class="hljs-number">2</span>)) + <span class="hljs-string">"\n"</span>

    log.log(<span class="hljs-number">1000</span>, <span class="hljs-string">"\nname"</span> + <span class="hljs-string">''</span>.ljust(maxNameLen - <span class="hljs-number">4</span>) + <span class="hljs-string">" ncall \tttot \ttsub"</span>)
    log.log(<span class="hljs-number">1000</span>, statPrint)
</code></pre>

<p>Then when your program work you can start profiler at any time by calling the <code>startProfiler</code> RPC method and dump profiling information to a log file by calling <code>printProfiler</code> (or modify the rpc method to return it to the caller) and get such output:</p>

<pre class="lang-py s-code-block"><code class="hljs language-python"><span class="hljs-number">2014</span>-02-<span class="hljs-number">19</span> <span class="hljs-number">16</span>:<span class="hljs-number">32</span>:<span class="hljs-number">24</span>,<span class="hljs-number">128</span>-|SVR-MAIN  |-(Thread-<span class="hljs-number">3</span>   )-Level <span class="hljs-number">1000</span>: 
name                                                                                                                                      ncall     ttot    tsub
<span class="hljs-number">2014</span>-02-<span class="hljs-number">19</span> <span class="hljs-number">16</span>:<span class="hljs-number">32</span>:<span class="hljs-number">24</span>,<span class="hljs-number">128</span>-|SVR-MAIN  |-(Thread-<span class="hljs-number">3</span>   )-Level <span class="hljs-number">1000</span>: 
C:\Python27\lib\sched.py.run:<span class="hljs-number">80</span>                                                                                                           <span class="hljs-number">22</span>        <span class="hljs-number">0.11</span>    <span class="hljs-number">0.05</span>
M:\02_documents\_repos\09_aheadRepos\apps\ahdModbusSrv\pyAheadRpcSrv\xmlRpc.py.iterFnc:<span class="hljs-number">293</span>                                                <span class="hljs-number">22</span>        <span class="hljs-number">0.11</span>    <span class="hljs-number">0.0</span>
M:\02_documents\_repos\09_aheadRepos\apps\ahdModbusSrv\serverMain.py.makeIteration:<span class="hljs-number">515</span>                                                    <span class="hljs-number">22</span>        <span class="hljs-number">0.11</span>    <span class="hljs-number">0.0</span>
M:\02_documents\_repos\09_aheadRepos\apps\ahdModbusSrv\pyAheadRpcSrv\PicklingXMLRPC.py._dispatch:<span class="hljs-number">66</span>                                       <span class="hljs-number">1</span>         <span class="hljs-number">0.0</span>     <span class="hljs-number">0.0</span>
C:\Python27\lib\BaseHTTPServer.py.date_time_string:<span class="hljs-number">464</span>                                                                                    <span class="hljs-number">1</span>         <span class="hljs-number">0.0</span>     <span class="hljs-number">0.0</span>
c:\users\zasiec~<span class="hljs-number">1</span>\appdata\local\temp\easy_install-hwcsr1\psutil-<span class="hljs-number">1.1</span><span class="hljs-number">.2</span>-py2<span class="hljs-number">.7</span>-win32.egg.tmp\psutil\_psmswindows.py._get_raw_meminfo:<span class="hljs-number">243</span>     <span class="hljs-number">4</span>         <span class="hljs-number">0.0</span>     <span class="hljs-number">0.0</span>
C:\Python27\lib\SimpleXMLRPCServer.py.decode_request_content:<span class="hljs-number">537</span>                                                                          <span class="hljs-number">1</span>         <span class="hljs-number">0.0</span>     <span class="hljs-number">0.0</span>
c:\users\zasiec~<span class="hljs-number">1</span>\appdata\local\temp\easy_install-hwcsr1\psutil-<span class="hljs-number">1.1</span><span class="hljs-number">.2</span>-py2<span class="hljs-number">.7</span>-win32.egg.tmp\psutil\_psmswindows.py.get_system_cpu_times:<span class="hljs-number">148</span> <span class="hljs-number">4</span>         <span class="hljs-number">0.0</span>     <span class="hljs-number">0.0</span>
&lt;string&gt;.__new__:<span class="hljs-number">8</span>                                                                                                                        <span class="hljs-number">220</span>       <span class="hljs-number">0.0</span>     <span class="hljs-number">0.0</span>
C:\Python27\lib\socket.py.close:<span class="hljs-number">276</span>                                                                                                       <span class="hljs-number">4</span>         <span class="hljs-number">0.0</span>     <span class="hljs-number">0.0</span>
C:\Python27\lib\threading.py.__init__:<span class="hljs-number">558</span>                                                                                                 <span class="hljs-number">1</span>         <span class="hljs-number">0.0</span>     <span class="hljs-number">0.0</span>
&lt;string&gt;.__new__:<span class="hljs-number">8</span>                                                                                                                        <span class="hljs-number">4</span>         <span class="hljs-number">0.0</span>     <span class="hljs-number">0.0</span>
C:\Python27\lib\threading.py.notify:<span class="hljs-number">372</span>                                                                                                   <span class="hljs-number">1</span>         <span class="hljs-number">0.0</span>     <span class="hljs-number">0.0</span>
C:\Python27\lib\rfc822.py.getheader:<span class="hljs-number">285</span>                                                                                                   <span class="hljs-number">4</span>         <span class="hljs-number">0.0</span>     <span class="hljs-number">0.0</span>
C:\Python27\lib\BaseHTTPServer.py.handle_one_request:<span class="hljs-number">301</span>                                                                                  <span class="hljs-number">1</span>         <span class="hljs-number">0.0</span>     <span class="hljs-number">0.0</span>
C:\Python27\lib\xmlrpclib.py.end:<span class="hljs-number">816</span>                                                                                                      <span class="hljs-number">3</span>         <span class="hljs-number">0.0</span>     <span class="hljs-number">0.0</span>
C:\Python27\lib\SimpleXMLRPCServer.py.do_POST:<span class="hljs-number">467</span>                                                                                         <span class="hljs-number">1</span>         <span class="hljs-number">0.0</span>     <span class="hljs-number">0.0</span>
C:\Python27\lib\SimpleXMLRPCServer.py.is_rpc_path_valid:<span class="hljs-number">460</span>                                                                               <span class="hljs-number">1</span>         <span class="hljs-number">0.0</span>     <span class="hljs-number">0.0</span>
C:\Python27\lib\SocketServer.py.close_request:<span class="hljs-number">475</span>                                                                                         <span class="hljs-number">1</span>         <span class="hljs-number">0.0</span>     <span class="hljs-number">0.0</span>
c:\users\zasiec~<span class="hljs-number">1</span>\appdata\local\temp\easy_install-hwcsr1\psutil-<span class="hljs-number">1.1</span><span class="hljs-number">.2</span>-py2<span class="hljs-number">.7</span>-win32.egg.tmp\psutil\__init__.py.cpu_times:<span class="hljs-number">1066</span>               <span class="hljs-number">4</span>         <span class="hljs-number">0.0</span>     <span class="hljs-number">0.0</span> 
</code></pre>

<p>It may not be very useful for short scripts but helps to optimize server-type processes especially given the <code>printProfiler</code> method can be called multiple times over time to profile and compare e.g. different program usage scenarios. </p>

<p>In newer versions of yappi, the following code will work:</p>

<pre class="lang-py s-code-block"><code class="hljs language-python"><span class="hljs-meta">@staticmethod</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">printProfile</span>():
    yappi.get_func_stats().print_all()
</code></pre>
    </div></div></div></div><div id="solution24" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 24</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>To add on to <a href="https://stackoverflow.com/a/582337/1070617">https://stackoverflow.com/a/582337/1070617</a>,</p>

<p>I wrote this module that allows you to use cProfile and view its output easily. More here: <a href="https://github.com/ymichael/cprofilev" rel="nofollow noreferrer">https://github.com/ymichael/cprofilev</a></p>

<pre class="lang-py s-code-block"><code class="hljs language-python">$ python -m cprofilev /your/python/program
<span class="hljs-comment"># Go to http://localhost:4000 to view collected statistics.</span>
</code></pre>

<p>Also see: <a href="http://ymichael.com/2014/03/08/profiling-python-with-cprofile.html" rel="nofollow noreferrer">http://ymichael.com/2014/03/08/profiling-python-with-cprofile.html</a> on how to make sense of the collected statistics.</p>
    </div></div></div></div><div id="solution25" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 25</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>A new tool to handle profiling in Python is PyVmMonitor: <a href="http://www.pyvmmonitor.com/" rel="noreferrer">http://www.pyvmmonitor.com/</a></p>

<p>It has some unique features such as</p>

<ul>
<li>Attach profiler to a running (CPython) program</li>
<li>On demand profiling with Yappi integration</li>
<li>Profile on a different machine</li>
<li>Multiple processes support (multiprocessing, django...)</li>
<li>Live sampling/CPU view (with time range selection)</li>
<li>Deterministic profiling through cProfile/profile integration</li>
<li>Analyze existing PStats results</li>
<li>Open DOT files</li>
<li>Programatic API access</li>
<li>Group samples by method or line</li>
<li>PyDev integration</li>
<li>PyCharm integration</li>
</ul>

<p>Note: it's commercial, but free for open source.</p>
    </div></div></div></div><div id="solution26" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 26</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>It would depend on what you want to see out of profiling. Simple time 
metrics can be given by (bash). </p>

<pre class="lang-py s-code-block"><code class="hljs language-python">time python python_prog.py
</code></pre>

<p>Even '/usr/bin/time' can output detailed metrics by using '--verbose' flag.</p>

<p>To check time metrics given by each function and to better understand how much time is spent on functions, you can use the inbuilt cProfile in python. </p>

<p>Going into more detailed metrics like performance, time is not the only metric. You can worry about memory, threads etc.<br>
Profiling options:<br>
1. <strong>line_profiler</strong> is another profiler used commonly to find out timing metrics line-by-line.<br>
2. <strong>memory_profiler</strong> is a tool to profile memory usage.<br>
3. <strong>heapy (from project Guppy)</strong> Profile how objects in the heap are used. </p>

<p>These are some of the common ones I tend to use. But if you want to find out more, try reading this <a href="http://shop.oreilly.com/product/0636920028963.do" rel="noreferrer">book</a>
It is a pretty good book on starting out with performance in mind. You can move onto advanced topics on using Cython and JIT(Just-in-time) compiled python. </p>
    </div></div></div></div><div id="solution27" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 27</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>I just developed my own profiler inspired from pypref_time:</p>
<p><a href="https://github.com/modaresimr/auto_profiler" rel="nofollow noreferrer">https://github.com/modaresimr/auto_profiler</a></p>
<p>By adding a decorator it will show a tree of time-consuming functions</p>
<p><code>@Profiler(depth=4, on_disable=show)</code></p>
<pre class="lang-py s-code-block"><code class="hljs language-python">Install by: pip install auto_profiler
</code></pre>
<h1>Example</h1>
<pre class="lang-py s-code-block"><code class="hljs language-python"><span class="hljs-keyword">import</span> time <span class="hljs-comment"># line number 1</span>
<span class="hljs-keyword">import</span> random

<span class="hljs-keyword">from</span> auto_profiler <span class="hljs-keyword">import</span> Profiler, Tree

<span class="hljs-keyword">def</span> <span class="hljs-title function_">f1</span>():
    mysleep(<span class="hljs-number">.6</span>+random.random())

<span class="hljs-keyword">def</span> <span class="hljs-title function_">mysleep</span>(<span class="hljs-params">t</span>):
    time.sleep(t)

<span class="hljs-keyword">def</span> <span class="hljs-title function_">fact</span>(<span class="hljs-params">i</span>):
    f1()
    <span class="hljs-keyword">if</span>(i==<span class="hljs-number">1</span>):
        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>
    <span class="hljs-keyword">return</span> i*fact(i-<span class="hljs-number">1</span>)


<span class="hljs-keyword">def</span> <span class="hljs-title function_">show</span>(<span class="hljs-params">p</span>):
    <span class="hljs-built_in">print</span>(<span class="hljs-string">'Time   [Hits * PerHit] Function name [Called from] [Function Location]\n'</span>+\
          <span class="hljs-string">'-----------------------------------------------------------------------'</span>)
    <span class="hljs-built_in">print</span>(Tree(p.root, threshold=<span class="hljs-number">0.5</span>))
    
<span class="hljs-meta">@Profiler(<span class="hljs-params">depth=<span class="hljs-number">4</span>, on_disable=show</span>)</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">5</span>):
        f1()

    fact(<span class="hljs-number">3</span>)


<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">'__main__'</span>:
    main()

</code></pre>
<h2>Example Output</h2>
<pre class="lang-py s-code-block"><code class="hljs language-python">
Time   [Hits * PerHit] Function name [Called <span class="hljs-keyword">from</span>] [function location]
-----------------------------------------------------------------------
<span class="hljs-number">8.974</span>s [<span class="hljs-number">1</span> * <span class="hljs-number">8.974</span>]  main  [auto-profiler/profiler.py:<span class="hljs-number">267</span>]  [/test/t2.py:<span class="hljs-number">30</span>]
 <span class="hljs-number">5.954</span>s [<span class="hljs-number">5</span> * <span class="hljs-number">1.191</span>]  f1  [/test/t2.py:<span class="hljs-number">34</span>]  [/test/t2.py:<span class="hljs-number">14</span>]
    <span class="hljs-number">5.954</span>s [<span class="hljs-number">5</span> * <span class="hljs-number">1.191</span>]  mysleep  [/test/t2.py:<span class="hljs-number">15</span>]  [/test/t2.py:<span class="hljs-number">17</span>]
        <span class="hljs-number">5.954</span>s [<span class="hljs-number">5</span> * <span class="hljs-number">1.191</span>]  &lt;time.sleep&gt;
|
|
|   <span class="hljs-comment"># The rest is for the example recursive function call fact</span>
 <span class="hljs-number">3.020</span>s [<span class="hljs-number">1</span> * <span class="hljs-number">3.020</span>]  fact  [/test/t2.py:<span class="hljs-number">36</span>]  [/test/t2.py:<span class="hljs-number">20</span>]
     <span class="hljs-number">0.849</span>s [<span class="hljs-number">1</span> * <span class="hljs-number">0.849</span>]  f1  [/test/t2.py:<span class="hljs-number">21</span>]  [/test/t2.py:<span class="hljs-number">14</span>]
        <span class="hljs-number">0.849</span>s [<span class="hljs-number">1</span> * <span class="hljs-number">0.849</span>]  mysleep  [/test/t2.py:<span class="hljs-number">15</span>]  [/test/t2.py:<span class="hljs-number">17</span>]
            <span class="hljs-number">0.849</span>s [<span class="hljs-number">1</span> * <span class="hljs-number">0.849</span>]  &lt;time.sleep&gt;
     <span class="hljs-number">2.171</span>s [<span class="hljs-number">1</span> * <span class="hljs-number">2.171</span>]  fact  [/test/t2.py:<span class="hljs-number">24</span>]  [/test/t2.py:<span class="hljs-number">20</span>]
         <span class="hljs-number">1.552</span>s [<span class="hljs-number">1</span> * <span class="hljs-number">1.552</span>]  f1  [/test/t2.py:<span class="hljs-number">21</span>]  [/test/t2.py:<span class="hljs-number">14</span>]
            <span class="hljs-number">1.552</span>s [<span class="hljs-number">1</span> * <span class="hljs-number">1.552</span>]  mysleep  [/test/t2.py:<span class="hljs-number">15</span>]  [/test/t2.py:<span class="hljs-number">17</span>]
         <span class="hljs-number">0.619</span>s [<span class="hljs-number">1</span> * <span class="hljs-number">0.619</span>]  fact  [/test/t2.py:<span class="hljs-number">24</span>]  [/test/t2.py:<span class="hljs-number">20</span>]
             <span class="hljs-number">0.619</span>s [<span class="hljs-number">1</span> * <span class="hljs-number">0.619</span>]  f1  [/test/t2.py:<span class="hljs-number">21</span>]  [/test/t2.py:<span class="hljs-number">14</span>]
</code></pre>
    </div></div></div></div><div id="solution28" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 28</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<blockquote>
  <p>Ever want to know what the hell that python script is doing? Enter the
  Inspect Shell. Inspect Shell lets you print/alter globals and run
  functions without interrupting the running script. Now with
  auto-complete and command history (only on linux).</p>
  
  <p>Inspect Shell is not a pdb-style debugger.</p>
</blockquote>

<p><a href="https://github.com/amoffat/Inspect-Shell" rel="nofollow">https://github.com/amoffat/Inspect-Shell</a></p>

<p>You could use that (and your wristwatch).</p>
    </div></div></div></div><div id="solution29" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 29</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>There's also a statistical profiler called <a href="https://pypi.python.org/pypi/statprof/" rel="nofollow noreferrer"><code>statprof</code></a>. It's a sampling profiler, so it adds minimal overhead to your code and gives line-based (not just function-based) timings. It's more suited to soft real-time applications like games, but may be have less precision than cProfile.</p>

<p>The <a href="https://pypi.python.org/pypi/statprof/" rel="nofollow noreferrer">version in pypi</a> is a bit old, so can install it with <code>pip</code> by specifying <a href="https://github.com/bos/statprof.py" rel="nofollow noreferrer">the git repository</a>:</p>

<pre class="lang-py s-code-block"><code class="hljs language-python">pip install git+git://github.com/bos/statprof.py@1a33eba91899afe17a8b752c6dfdec6f05dd0c01
</code></pre>

<p>You can run it like this:</p>

<pre class="lang-py s-code-block"><code class="hljs language-python"><span class="hljs-keyword">import</span> statprof

<span class="hljs-keyword">with</span> statprof.profile():
    my_questionable_function()
</code></pre>

<p>See also <a href="https://stackoverflow.com/a/10333592/320036">https://stackoverflow.com/a/10333592/320036</a></p>
    </div></div></div></div><div id="solution30" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h1 class="text-4xl font-semibold mb-5">Solution 30</h1><div class="tags-wrap h-max space-x-8"><div class="tags"></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>I found cprofiler and other ressources to be more for optimization purpose rather than debugging.</p>
<p>I made my own testing module instead for simple python scripts speed testing. (In my case 1K+ lines py file was tested using ScriptProfilerPy and speedup the code by 10x in minutes afterwards.</p>
<p>The module ScriptProfilerPy() will run your code adding timestamp to it.
I put the module here:
<a href="https://github.com/Lucas-BLP/ScriptProfilerPy" rel="nofollow noreferrer">https://github.com/Lucas-BLP/ScriptProfilerPy</a></p>
<p>Use:</p>
<pre class="lang-py s-code-block"><code class="hljs language-python"><span class="hljs-keyword">from</span> speed_testpy <span class="hljs-keyword">import</span> ScriptProfilerPy

ScriptProfilerPy(<span class="hljs-string">"path_to_your_script_to_test.py"</span>).Profiler()
</code></pre>
<p>output:
<a href="https://i.stack.imgur.com/RkRZD.png" rel="nofollow noreferrer"><img src="https://i.stack.imgur.com/RkRZD.png" alt="Output of the code after testing"></a></p>
    </div></div></div></div></div></div><div class="widget"><a href="/questions/reference:-what-is-variable-scope-which-variables-are-accessible-from-where-and-what-are-%22undefined-variable%22-errors-1657384644697">Reference: What is variable scope, which variables are accessible from where and what are &quot;undefined variable&quot; errors?</a><a href="/questions/what-is-an-undefined-referenceunresolved-external-symbol-error-and-how-do-i-fix-it-1657384255179">What is an undefined reference/unresolved external symbol error and how do I fix it?</a><a href="/questions/how-do-i-merge-two-dictionaries-in-a-single-expression-1657387593160">How do I merge two dictionaries in a single expression?</a><a href="/questions/persist-variables-between-page-loads-1657388558452">Persist variables between page loads</a><a href="/questions/is-it-possible-for-flex-items-to-align-tightly-to-the-items-above-them-1657388511179">Is it possible for flex items to align tightly to the items above them?</a><a href="/questions/accessing-an-array-out-of-bounds-gives-no-error-why-1657387979932">Accessing an array out of bounds gives no error, why?</a><a href="/questions/sorting-object-property-by-values-1657388367300">Sorting object property by values</a><a href="/questions/how-do-i-make-git-forget-about-a-file-that-was-tracked-but-is-now-in-.gitignore-1657387328843">How do I make Git forget about a file that was tracked, but is now in .gitignore?</a><a href="/questions/how-can-i-prevent-sql-injection-in-php-1657384220094">How can I prevent SQL injection in PHP?</a><a href="/questions/what-is-dependency-injection-1657387953056">What is dependency injection?</a><a href="/questions/what-does-if-__name__-%22__main__%22:-do-1657384825815">What does if __name__ == &quot;__main__&quot;: do?</a><a href="/questions/using-fflush(stdin)-1657387602771">Using fflush(stdin)</a><a href="/questions/how-can-i-vertically-align-elements-in-a-div-1657385504431">How can I vertically align elements in a div?</a><a href="/questions/serialize-and-deserialize-json-and-json-array-in-unity-1657388273270">Serialize and Deserialize Json and Json Array in Unity</a><a href="/questions/understanding-slicing-1657384397680">Understanding slicing</a><a href="/questions/how-to-check-if-element-is-visible-after-scrolling-1657387987960">How to check if element is visible after scrolling?</a><a href="/questions/how-should-a-model-be-structured-in-mvc-closed-1657388394807">How should a model be structured in MVC? [closed]</a><a href="/questions/reference-what-does-this-symbol-mean-in-php-1657384561666">Reference — What does this symbol mean in PHP?</a><a href="/questions/why-are-floating-point-numbers-inaccurate-1657387346111">Why are floating point numbers inaccurate?</a><a href="/questions/what-is-a-stackoverflowerror-1657388319634">What is a StackOverflowError?</a></div></div><span class="cursor-pointer text-lg p-2" style="position:fixed;bottom:20px;left:20px;background:#000;z-index:2000;color:white">Go go top</span></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"data":{"answer":["\n\u0026lt;p\u0026gt;Python includes a profiler called \u0026lt;a href=\u0026quot;https://docs.python.org/3/library/profile.html#module-cProfile\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;cProfile\u0026lt;/a\u0026gt;. It not only gives the total running time, but also times each function separately, and tells you how many times each function was called, making it easy to determine where you should make optimizations.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;You can call it from within your code, or from the interpreter, like this:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; cProfile\ncProfile.run(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;foo()\u0026apos;\u0026lt;/span\u0026gt;)\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Even more usefully, you can invoke the cProfile when running a script:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;python -m cProfile myscript.py\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;To make it even easier, I made a little batch file called \u0026apos;profile.bat\u0026apos;:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;python -m cProfile %\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;So all I have to do is run:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;profile euler048.py\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;And I get this:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-none s-code-block\u0026quot;\u0026gt;\u0026lt;code\u0026gt;1007 function calls in 0.061 CPU seconds\n\nOrdered by: standard name\nncalls  tottime  percall  cumtime  percall filename:lineno(function)\n    1    0.000    0.000    0.061    0.061 \u0026amp;lt;string\u0026amp;gt;:1(\u0026amp;lt;module\u0026amp;gt;)\n 1000    0.051    0.000    0.051    0.000 euler048.py:2(\u0026amp;lt;lambda\u0026amp;gt;)\n    1    0.005    0.005    0.061    0.061 euler048.py:2(\u0026amp;lt;module\u0026amp;gt;)\n    1    0.000    0.000    0.061    0.061 {execfile}\n    1    0.002    0.002    0.053    0.053 {map}\n    1    0.000    0.000    0.000    0.000 {method \u0026apos;disable\u0026apos; of \u0026apos;_lsprof.Profiler objects}\n    1    0.000    0.000    0.000    0.000 {range}\n    1    0.003    0.003    0.003    0.003 {sum}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;EDIT: Updated link to a good video resource from PyCon 2013 titled \n\u0026lt;a href=\u0026quot;https://web.archive.org/web/20170318204046/http://lanyrd.com/2013/pycon/scdywg/\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;\u0026lt;strong\u0026gt;\u0026lt;em\u0026gt;Python Profiling\u0026lt;/em\u0026gt;\u0026lt;/strong\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;br\u0026gt;\n\u0026lt;a href=\u0026quot;https://www.youtube.com/watch?v=QJwVYlDzAXs\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;Also via YouTube\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;A while ago I made \u0026lt;a href=\u0026quot;http://pycallgraph.slowchop.com/\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;\u0026lt;code\u0026gt;pycallgraph\u0026lt;/code\u0026gt;\u0026lt;/a\u0026gt; which generates a visualisation from your Python code. \u0026lt;strong\u0026gt;Edit:\u0026lt;/strong\u0026gt; I\u0026apos;ve updated the example to work with 3.3, the latest release as of this writing.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;After a \u0026lt;code\u0026gt;pip install pycallgraph\u0026lt;/code\u0026gt; and installing \u0026lt;a href=\u0026quot;http://www.graphviz.org/\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;GraphViz\u0026lt;/a\u0026gt; you can run it from the command line:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;pycallgraph graphviz -- ./mypythonscript.py\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Or, you can profile particular parts of your code:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; pycallgraph \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; PyCallGraph\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; pycallgraph.output \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; GraphvizOutput\n\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;with\u0026lt;/span\u0026gt; PyCallGraph(output=GraphvizOutput()):\n    code_to_profile()\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Either of these will generate a \u0026lt;code\u0026gt;pycallgraph.png\u0026lt;/code\u0026gt; file similar to the image below:\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;\u0026lt;img src=\u0026quot;https://i.stack.imgur.com/aiNEA.png\u0026quot; alt=\u0026quot;enter image description here\u0026quot;\u0026gt;\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;It\u0026apos;s worth pointing out that using the profiler only works (by default) on the main thread, and you won\u0026apos;t get any information from other threads if you use them.  This can be a bit of a gotcha as it is completely unmentioned in the \u0026lt;a href=\u0026quot;http://docs.python.org/library/profile.html\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;profiler documentation\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;If you also want to profile threads, you\u0026apos;ll want to look at the \u0026lt;a href=\u0026quot;http://docs.python.org/library/threading.html#threading.setprofile\u0026quot; rel=\u0026quot;noreferrer\u0026quot; title=\u0026quot;threading.setprofile() function\u0026quot;\u0026gt;\u0026lt;code\u0026gt;threading.setprofile()\u0026lt;/code\u0026gt; function\u0026lt;/a\u0026gt; in the docs.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;You could also create your own \u0026lt;code\u0026gt;threading.Thread\u0026lt;/code\u0026gt; subclass to do it:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;class\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title class_\u0026quot;\u0026gt;ProfiledThread\u0026lt;/span\u0026gt;(threading.Thread):\n    \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# Overrides threading.Thread.run()\u0026lt;/span\u0026gt;\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;run\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;self\u0026lt;/span\u0026gt;):\n        profiler = cProfile.Profile()\n        \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;try\u0026lt;/span\u0026gt;:\n            \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;return\u0026lt;/span\u0026gt; profiler.runcall(threading.Thread.run, self)\n        \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;finally\u0026lt;/span\u0026gt;:\n            profiler.dump_stats(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;myprofile-%d.profile\u0026apos;\u0026lt;/span\u0026gt; % (self.ident,))\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;and use that \u0026lt;code\u0026gt;ProfiledThread\u0026lt;/code\u0026gt; class instead of the standard one.  It might give you more flexibility, but I\u0026apos;m not sure it\u0026apos;s worth it, especially if you are using third-party code which wouldn\u0026apos;t use your class.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;The python wiki is a great page for profiling resources:\n\u0026lt;a href=\u0026quot;http://wiki.python.org/moin/PythonSpeed/PerformanceTips#Profiling_Code\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;http://wiki.python.org/moin/PythonSpeed/PerformanceTips#Profiling_Code\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;as is the python docs:\n\u0026lt;a href=\u0026quot;http://docs.python.org/library/profile.html\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;http://docs.python.org/library/profile.html\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;as shown by Chris Lawlor cProfile is a great tool and can easily be used to print to the screen:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;python -m cProfile -s time mine.py \u0026amp;lt;args\u0026amp;gt;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;or to file:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;python -m cProfile -o output.file mine.py \u0026amp;lt;args\u0026amp;gt;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;PS\u0026amp;gt; If you are using Ubuntu, make sure to install python-profile\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;apt-get install python-profiler \n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;If you output to file you can get nice visualizations using the following tools\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;PyCallGraph : a tool to create call graph images \u0026lt;br\u0026gt;\n  install:\u0026lt;br\u0026gt;\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt; pip install pycallgraph\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;run:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt; pycallgraph mine.py args\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;view:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt; gimp pycallgraph.png\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;\u0026lt;em\u0026gt;You can use whatever you like to view the png file, I used gimp\u0026lt;/em\u0026gt;\u0026lt;br\u0026gt;\nUnfortunately I often get \u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;dot: graph is too large for cairo-renderer bitmaps. Scaling by 0.257079 to fit\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;which makes my images unusably small.  So I generally create svg files:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;pycallgraph -f svg -o pycallgraph.svg mine.py \u0026amp;lt;args\u0026amp;gt;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;PS\u0026amp;gt; make sure to install graphviz (which provides the dot program):\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;pip install graphviz\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Alternative Graphing using gprof2dot via @maxy / @quodlibetor :\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;pip install gprof2dot\npython -m cProfile -o profile.pstats mine.py\ngprof2dot -f pstats profile.pstats | dot -Tsvg -o mine.svg\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n    ","\n\u0026lt;p\u0026gt;@Maxy\u0026apos;s comment on \u0026lt;a href=\u0026quot;https://stackoverflow.com/a/7693928/25616\u0026quot;\u0026gt;this answer\u0026lt;/a\u0026gt; helped me out enough that I think it deserves its own answer: I already had cProfile-generated .pstats files and I didn\u0026apos;t want to re-run things with pycallgraph, so I used \u0026lt;a href=\u0026quot;https://github.com/jrfonseca/gprof2dot\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;gprof2dot\u0026lt;/a\u0026gt;, and got pretty svgs:\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;$ sudo apt-get install graphviz\n$ git clone https://github.com/jrfonseca/gprof2dot\n$ ln -s \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;$PWD\u0026quot;\u0026lt;/span\u0026gt;/gprof2dot/gprof2dot.py ~/\u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;bin\u0026lt;/span\u0026gt;\n$ cd $PROJECT_DIR\n$ gprof2dot.py -f pstats profile.pstats | dot -Tsvg -o callgraph.svg\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;and BLAM!\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;It uses dot (the same thing that pycallgraph uses) so output looks similar. I get the impression that gprof2dot loses less information though:\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;a href=\u0026quot;https://i.stack.imgur.com/JjSvt.png\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;\u0026lt;img src=\u0026quot;https://i.stack.imgur.com/JjSvt.png\u0026quot; alt=\u0026quot;gprof2dot example output\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;Simplest\u0026lt;/strong\u0026gt; and \u0026lt;strong\u0026gt;quickest\u0026lt;/strong\u0026gt; way to find where all the time is going.\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1.\u0026lt;/span\u0026gt; pip install snakeviz\n\n\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;2.\u0026lt;/span\u0026gt; python -m cProfile -o temp.dat \u0026amp;lt;PROGRAM\u0026amp;gt;.py\n\n\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;3.\u0026lt;/span\u0026gt; snakeviz temp.dat\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Draws a pie chart in a browser. Biggest piece is the problem function. Very simple.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;I ran into a handy tool called \u0026lt;a href=\u0026quot;https://jiffyclub.github.io/snakeviz/\u0026quot;\u0026gt;SnakeViz\u0026lt;/a\u0026gt; when researching this topic. SnakeViz is a web-based profiling visualization tool. It is very easy to install and use. The usual way I use it is to generate a stat file with \u0026lt;code\u0026gt;%prun\u0026lt;/code\u0026gt; and then do analysis in SnakeViz.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;The main viz technique used is \u0026lt;strong\u0026gt;Sunburst chart\u0026lt;/strong\u0026gt; as shown below, in which the hierarchy of function calls is arranged as layers of arcs and time info encoded in their angular widths.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;The best thing is you can interact with the chart. For example, to zoom in one can click on an arc, and the arc and its descendants will be enlarged as a new sunburst to display more details.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;\u0026lt;a href=\u0026quot;https://i.stack.imgur.com/kCmSY.png\u0026quot;\u0026gt;\u0026lt;img src=\u0026quot;https://i.stack.imgur.com/kCmSY.png\u0026quot; alt=\u0026quot;enter image description here\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;\u0026lt;a href=\u0026quot;https://docs.python.org/2/library/profile.html\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;\u0026lt;code\u0026gt;cProfile\u0026lt;/code\u0026gt;\u0026lt;/a\u0026gt; is great for profiling, while \u0026lt;a href=\u0026quot;https://kcachegrind.github.io/html/Home.html\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;\u0026lt;code\u0026gt;kcachegrind\u0026lt;/code\u0026gt;\u0026lt;/a\u0026gt; is great for visualizing the results. The \u0026lt;a href=\u0026quot;https://pypi.python.org/pypi/pyprof2calltree\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;\u0026lt;code\u0026gt;pyprof2calltree\u0026lt;/code\u0026gt;\u0026lt;/a\u0026gt; in between handles the file conversion.\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;python -m cProfile -o script.profile script.py\npyprof2calltree -i script.profile -o script.calltree\nkcachegrind script.calltree\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;Required system packages:\u0026lt;/p\u0026gt;\n\u0026lt;ul\u0026gt;\n\u0026lt;li\u0026gt;\u0026lt;code\u0026gt;kcachegrind\u0026lt;/code\u0026gt; (Linux), \u0026lt;code\u0026gt;qcachegrind\u0026lt;/code\u0026gt; (MacOs)\u0026lt;/li\u0026gt;\n\u0026lt;/ul\u0026gt;\n\u0026lt;p\u0026gt;Setup on Ubuntu:\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;apt-get install kcachegrind \npip install pyprof2calltree\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;The result:\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;a href=\u0026quot;https://i.stack.imgur.com/1TFZe.png\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;\u0026lt;img src=\u0026quot;https://i.stack.imgur.com/1TFZe.png\u0026quot; alt=\u0026quot;Screenshot of the result\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;I recently created \u0026lt;a href=\u0026quot;https://github.com/nschloe/tuna\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;tuna\u0026lt;/a\u0026gt; for visualizing Python runtime and import profiles; this may be helpful here.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;a href=\u0026quot;https://i.stack.imgur.com/ZpP6M.gif\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;\u0026lt;img src=\u0026quot;https://i.stack.imgur.com/ZpP6M.gif\u0026quot; alt=\u0026quot;enter image description here\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;Install with\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;pip install tuna\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;Create a runtime profile\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;python3 -m cProfile -o program.prof yourfile.py\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;or an import profile (Python 3.7+ required)\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;python3 -X importprofile yourfile.py \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;2\u0026lt;/span\u0026gt;\u0026amp;gt; \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt;.log\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;Then just run tuna on the file\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;tuna program.prof\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n    ","\n\u0026lt;p\u0026gt;Also worth mentioning is the GUI cProfile dump viewer \u0026lt;a href=\u0026quot;http://www.vrplumber.com/programming/runsnakerun/\u0026quot;\u0026gt;RunSnakeRun\u0026lt;/a\u0026gt;.  It allows you to sort and select, thereby zooming in on the relevant parts of the program.  The sizes of the rectangles in the picture is proportional to the time taken.  If you mouse over a rectangle it highlights that call in the table and everywhere on the map.  When you double-click on a rectangle it zooms in on that portion.  It will show you who calls that portion and what that portion calls.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;The descriptive information is very helpful.  It shows you the code for that bit which can be helpful when you are dealing with built-in library calls.  It tells you what file and what line to find the code.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;Also want to point at that the OP said \u0026apos;profiling\u0026apos; but it appears he meant \u0026apos;timing\u0026apos;.  Keep in mind programs will run slower when profiled.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;\u0026lt;img src=\u0026quot;https://i.stack.imgur.com/2GahD.png\u0026quot; alt=\u0026quot;enter image description here\u0026quot;\u0026gt;\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;h1\u0026gt;pprofile\u0026lt;/h1\u0026gt;\n\n\u0026lt;p\u0026gt;\u0026lt;code\u0026gt;line_profiler\u0026lt;/code\u0026gt; (already presented here) also inspired  \u0026lt;a href=\u0026quot;https://github.com/vpelletier/pprofile\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;\u0026lt;code\u0026gt;pprofile\u0026lt;/code\u0026gt;\u0026lt;/a\u0026gt;, which is described as:\u0026lt;/p\u0026gt;\n\n\u0026lt;blockquote\u0026gt;\n  \u0026lt;p\u0026gt;Line-granularity, thread-aware deterministic and statistic pure-python\n  profiler\u0026lt;/p\u0026gt;\n\u0026lt;/blockquote\u0026gt;\n\n\u0026lt;p\u0026gt;It provides line-granularity as \u0026lt;code\u0026gt;line_profiler\u0026lt;/code\u0026gt;, is pure Python, can be used as a standalone command or a module, and can even generate callgrind-format files that can be easily analyzed with \u0026lt;code\u0026gt;[k|q]cachegrind\u0026lt;/code\u0026gt;.\u0026lt;/p\u0026gt;\n\n\u0026lt;h1\u0026gt;vprof\u0026lt;/h1\u0026gt;\n\n\u0026lt;p\u0026gt;There is also \u0026lt;a href=\u0026quot;https://github.com/nvdv/vprof\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;vprof\u0026lt;/a\u0026gt;, a Python package described as:\u0026lt;/p\u0026gt;\n\n\u0026lt;blockquote\u0026gt;\n  \u0026lt;p\u0026gt;[...] providing rich and interactive visualizations for various Python program characteristics such as running time and memory usage.\u0026lt;/p\u0026gt;\n\u0026lt;/blockquote\u0026gt;\n\n\u0026lt;p\u0026gt;\u0026lt;a href=\u0026quot;https://i.stack.imgur.com/uafO3.png\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;\u0026lt;img src=\u0026quot;https://i.stack.imgur.com/uafO3.png\u0026quot; alt=\u0026quot;heatmap\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;A nice profiling module is the line_profiler (called using the script kernprof.py).  It can be downloaded \u0026lt;a href=\u0026quot;http://packages.python.org/line_profiler/\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;here\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;My understanding is that cProfile only gives information about total time spent in each function.  So individual lines of code are not timed.  This is an issue in scientific computing since often one single line can take a lot of time.  Also, as I remember, cProfile didn\u0026apos;t catch the time I was spending in say numpy.dot.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;The terminal-only (and simplest) solution, in case all those fancy UI\u0026apos;s fail to install or to run:\u0026lt;br\u0026gt;\nignore \u0026lt;code\u0026gt;cProfile\u0026lt;/code\u0026gt; completely and replace it with \u0026lt;code\u0026gt;pyinstrument\u0026lt;/code\u0026gt;, that will collect and display the tree of calls right after execution.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;Install:  \u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;$ pip install pyinstrument\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Profile and display result:  \u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;$ python -m pyinstrument ./prog.py\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Works with python2 and 3.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;[EDIT]\nThe documentation of the API, for profiling only a part of the code, can be found \u0026lt;a href=\u0026quot;https://github.com/joerick/pyinstrument#profile-a-specific-chunk-of-code\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;here\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;There\u0026apos;s a lot of great answers but they either use command line or some external program for profiling and/or sorting the results.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;I really missed some way I could use in my IDE (eclipse-PyDev) without touching the command line or installing anything. So here it is.\u0026lt;/p\u0026gt;\n\u0026lt;h1\u0026gt;Profiling without command line\u0026lt;/h1\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;count\u0026lt;/span\u0026gt;():\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; math \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; sqrt\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;for\u0026lt;/span\u0026gt; x \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;in\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;range\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;10\u0026lt;/span\u0026gt;**\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;5\u0026lt;/span\u0026gt;):\n        sqrt(x)\n\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;if\u0026lt;/span\u0026gt; __name__ == \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;__main__\u0026apos;\u0026lt;/span\u0026gt;:\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; cProfile, pstats\n    cProfile.run(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;count()\u0026quot;\u0026lt;/span\u0026gt;, \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;{}.profile\u0026quot;\u0026lt;/span\u0026gt;.\u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;format\u0026lt;/span\u0026gt;(__file__))\n    s = pstats.Stats(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;{}.profile\u0026quot;\u0026lt;/span\u0026gt;.\u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;format\u0026lt;/span\u0026gt;(__file__))\n    s.strip_dirs()\n    s.sort_stats(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;time\u0026quot;\u0026lt;/span\u0026gt;).print_stats(\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;10\u0026lt;/span\u0026gt;)\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;See \u0026lt;a href=\u0026quot;https://docs.python.org/3.4/library/profile.html\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;docs\u0026lt;/a\u0026gt; or other answers for more info.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;Following Joe Shaw\u0026apos;s answer about multi-threaded code not to work as expected, I figured that the \u0026lt;code\u0026gt;runcall\u0026lt;/code\u0026gt; method in cProfile is merely doing \u0026lt;code\u0026gt;self.enable()\u0026lt;/code\u0026gt; and \u0026lt;code\u0026gt;self.disable()\u0026lt;/code\u0026gt; calls around the profiled function call, so you can simply do that yourself and have whatever code you want in-between with minimal interference with existing code.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;With a statistical profiler like \u0026lt;a href=\u0026quot;https://github.com/P403n1x87/austin\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;austin\u0026lt;/a\u0026gt;, no instrumentation is required, meaning that you can get profiling data out of a Python application simply with\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;austin python3 my_script.py\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;The raw output isn\u0026apos;t very useful, but you can pipe that to \u0026lt;a href=\u0026quot;https://github.com/brendangregg/FlameGraph/blob/master/flamegraph.pl\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;flamegraph.pl\u0026lt;/a\u0026gt;\nto get a flame graph representation of that data that gives you a breakdown of where the time (measured in microseconds of real time) is being spent.\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;austin python3 my_script.py | flamegraph.pl \u0026amp;gt; my_script_profile.svg\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;Alternatively, you can also use the web application \u0026lt;a href=\u0026quot;http://speedscope.app/\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;Speedscope.app\u0026lt;/a\u0026gt; for quick visualisation of the collected samples. If you have \u0026lt;a href=\u0026quot;https://github.com/google/pprof\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;pprof\u0026lt;/a\u0026gt; installed, you can also get \u0026lt;a href=\u0026quot;https://github.com/P403n1x87/austin-python\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;austin-python\u0026lt;/a\u0026gt; (with e.g. \u0026lt;code\u0026gt;pipx install austin-python\u0026lt;/code\u0026gt;) and use the \u0026lt;code\u0026gt;austin2pprof\u0026lt;/code\u0026gt; to covert to the pprof format.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;However, if you have VS Code installed you could use the \u0026lt;a href=\u0026quot;https://marketplace.visualstudio.com/items?itemName=p403n1x87.austin-vscode\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;Austin extension\u0026lt;/a\u0026gt; for a more interactive experience, with source code heat maps, top functions and collected call stacks\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;img src=\u0026quot;https://github.com/P403n1x87/austin-vscode/raw/main/art/demo.gif\u0026quot; alt=\u0026quot;Austin VS Code extension\u0026quot;\u0026gt;\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;In Virtaal\u0026apos;s \u0026lt;a href=\u0026quot;https://github.com/translate/virtaal/blob/master/devsupport/profiling.py\u0026quot; rel=\u0026quot;nofollow noreferrer\u0026quot;\u0026gt;source\u0026lt;/a\u0026gt; there\u0026apos;s a very useful class and decorator that can make profiling (even for specific methods/functions) very easy. The output can then be viewed very comfortably in KCacheGrind.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;If you want to make a cumulative profiler,\nmeaning to run the function several times in a row and watch the sum of the results.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;you can use this \u0026lt;code\u0026gt;cumulative_profiler\u0026lt;/code\u0026gt; decorator:\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;it\u0026apos;s python \u0026amp;gt;= 3.6 specific, but you can remove \u0026lt;code\u0026gt;nonlocal\u0026lt;/code\u0026gt; for it work on older versions.\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; cProfile, pstats\n\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;class\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title class_\u0026quot;\u0026gt;_ProfileFunc\u0026lt;/span\u0026gt;:\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;__init__\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;self, func, sort_stats_by\u0026lt;/span\u0026gt;):\n        self.func =  func\n        self.profile_runs = []\n        self.sort_stats_by = sort_stats_by\n\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;__call__\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;self, *args, **kwargs\u0026lt;/span\u0026gt;):\n        pr = cProfile.Profile()\n        pr.enable()  \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# this is the profiling section\u0026lt;/span\u0026gt;\n        retval = self.func(*args, **kwargs)\n        pr.disable()\n\n        self.profile_runs.append(pr)\n        ps = pstats.Stats(*self.profile_runs).sort_stats(self.sort_stats_by)\n        \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;return\u0026lt;/span\u0026gt; retval, ps\n\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;cumulative_profiler\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;amount_of_times, sort_stats_by=\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;time\u0026apos;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;):\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;real_decorator\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;function\u0026lt;/span\u0026gt;):\n        \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;wrapper\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;*args, **kwargs\u0026lt;/span\u0026gt;):\n            \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;nonlocal\u0026lt;/span\u0026gt; function, amount_of_times, sort_stats_by  \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# for python 2.x remove this row\u0026lt;/span\u0026gt;\n\n            profiled_func = _ProfileFunc(function, sort_stats_by)\n            \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;for\u0026lt;/span\u0026gt; i \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;in\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;range\u0026lt;/span\u0026gt;(amount_of_times):\n                retval, ps = profiled_func(*args, **kwargs)\n            ps.print_stats()\n            \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;return\u0026lt;/span\u0026gt; retval  \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# returns the results of the function\u0026lt;/span\u0026gt;\n        \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;return\u0026lt;/span\u0026gt; wrapper\n\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;if\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;callable\u0026lt;/span\u0026gt;(amount_of_times):  \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# incase you don\u0026apos;t want to specify the amount of times\u0026lt;/span\u0026gt;\n        func = amount_of_times  \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# amount_of_times is the function in here\u0026lt;/span\u0026gt;\n        amount_of_times = \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;5\u0026lt;/span\u0026gt;  \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# the default amount\u0026lt;/span\u0026gt;\n        \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;return\u0026lt;/span\u0026gt; real_decorator(func)\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;return\u0026lt;/span\u0026gt; real_decorator\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;Example\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;profiling the function \u0026lt;code\u0026gt;baz\u0026lt;/code\u0026gt; \u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; time\n\n\u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;@cumulative_profiler\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;baz\u0026lt;/span\u0026gt;():\n    time.sleep(\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;)\n    time.sleep(\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;2\u0026lt;/span\u0026gt;)\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;return\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;\n\nbaz()\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;\u0026lt;code\u0026gt;baz\u0026lt;/code\u0026gt; ran 5 times and printed this:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;         \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;20\u0026lt;/span\u0026gt; function calls \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;in\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;15.003\u0026lt;/span\u0026gt; seconds\n\n   Ordered by: internal time\n\n   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n       \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;10\u0026lt;/span\u0026gt;   \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;15.003\u0026lt;/span\u0026gt;    \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1.500\u0026lt;/span\u0026gt;   \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;15.003\u0026lt;/span\u0026gt;    \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1.500\u0026lt;/span\u0026gt; {built-\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;in\u0026lt;/span\u0026gt; method time.sleep}\n        \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;5\u0026lt;/span\u0026gt;    \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.000\u0026lt;/span\u0026gt;    \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.000\u0026lt;/span\u0026gt;   \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;15.003\u0026lt;/span\u0026gt;    \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;3.001\u0026lt;/span\u0026gt; \u0026amp;lt;ipython-\u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;input\u0026lt;/span\u0026gt;-\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;9\u0026lt;/span\u0026gt;-c89afe010372\u0026amp;gt;:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;3\u0026lt;/span\u0026gt;(baz)\n        \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;5\u0026lt;/span\u0026gt;    \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.000\u0026lt;/span\u0026gt;    \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.000\u0026lt;/span\u0026gt;    \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.000\u0026lt;/span\u0026gt;    \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.000\u0026lt;/span\u0026gt; {method \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;disable\u0026apos;\u0026lt;/span\u0026gt; of \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;_lsprof.Profiler\u0026apos;\u0026lt;/span\u0026gt; objects}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;specifying the amount of times\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;@cumulative_profiler(\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;3\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;)\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;baz\u0026lt;/span\u0026gt;():\n    ...\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n    ","\n\u0026lt;p\u0026gt;For getting quick profile stats on an IPython notebook.\nOne can embed \u0026lt;strong\u0026gt;line_profiler\u0026lt;/strong\u0026gt; and \u0026lt;strong\u0026gt;memory_profiler\u0026lt;/strong\u0026gt; straight into their notebooks.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;Another useful package is \u0026lt;strong\u0026gt;Pympler\u0026lt;/strong\u0026gt;. It is a powerful profiling package that\u0026apos;s capable to track classes,objects,functions,memory leaks etc. Examples below, Docs attached.\u0026lt;/p\u0026gt;\n\u0026lt;h2\u0026gt;Get it!\u0026lt;/h2\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;!pip install line_profiler\n!pip install memory_profiler\n!pip install pympler\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;h2\u0026gt;Load it!\u0026lt;/h2\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;%load_ext line_profiler\n%load_ext memory_profiler\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;h2\u0026gt;Use it!\u0026lt;/h2\u0026gt;\n\u0026lt;hr\u0026gt;\n\u0026lt;h1\u0026gt;%time\u0026lt;/h1\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;%time \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;print\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;Outputs CPU time,Wall Clock time\u0026apos;\u0026lt;/span\u0026gt;) \n\u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;#CPU times: user 2 µs, sys: 0 ns, total: 2 µs Wall time: 5.96 µs\u0026lt;/span\u0026gt;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;Gives:\u0026lt;/p\u0026gt;\n\u0026lt;ul\u0026gt;\n\u0026lt;li\u0026gt;CPU times: CPU level execution time\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;sys times: system level execution time\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;total: CPU time + system time\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;Wall time: Wall Clock Time\u0026lt;/li\u0026gt;\n\u0026lt;/ul\u0026gt;\n\u0026lt;hr\u0026gt;\n\u0026lt;h1\u0026gt;%timeit\u0026lt;/h1\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;%timeit -r \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;7\u0026lt;/span\u0026gt; -n \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1000\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;print\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;Outputs execution time of the snippet\u0026apos;\u0026lt;/span\u0026gt;) \n\u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;#1000 loops, best of 7: 7.46 ns per loop\u0026lt;/span\u0026gt;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;ul\u0026gt;\n\u0026lt;li\u0026gt;Gives best time out of given number of runs(r) in looping (n) times.\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;Outputs details on system caching:\n\u0026lt;ul\u0026gt;\n\u0026lt;li\u0026gt;When code snippets are executed multiple times, system caches a few opearations and doesn\u0026apos;t execute them again that may hamper the accuracy of the profile reports.\u0026lt;/li\u0026gt;\n\u0026lt;/ul\u0026gt;\n\u0026lt;/li\u0026gt;\n\u0026lt;/ul\u0026gt;\n\u0026lt;hr\u0026gt;\n\u0026lt;h1\u0026gt;%prun\u0026lt;/h1\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;%prun -s cumulative \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;Code to profile\u0026apos;\u0026lt;/span\u0026gt; \n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;Gives:\u0026lt;/p\u0026gt;\n\u0026lt;ul\u0026gt;\n\u0026lt;li\u0026gt;number of function calls(ncalls)\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;has entries per function call(distinct)\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;time taken per call(percall)\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;time elapsed till that function call(cumtime)\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;name of the func/module called etc...\u0026lt;/li\u0026gt;\n\u0026lt;/ul\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;a href=\u0026quot;https://i.stack.imgur.com/1IkgA.png\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;\u0026lt;img src=\u0026quot;https://i.stack.imgur.com/1IkgA.png\u0026quot; alt=\u0026quot;Cumulative profile\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n\u0026lt;hr\u0026gt;\n\u0026lt;h1\u0026gt;%memit\u0026lt;/h1\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;%memit \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;Code to profile\u0026apos;\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;#peak memory: 199.45 MiB, increment: 0.00 MiB\u0026lt;/span\u0026gt;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;Gives:\u0026lt;/p\u0026gt;\n\u0026lt;ul\u0026gt;\n\u0026lt;li\u0026gt;Memory usage\u0026lt;/li\u0026gt;\n\u0026lt;/ul\u0026gt;\n\u0026lt;hr\u0026gt;\n\u0026lt;h1\u0026gt;%lprun\u0026lt;/h1\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;#Example function\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;fun\u0026lt;/span\u0026gt;():\n  \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;for\u0026lt;/span\u0026gt; i \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;in\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;range\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;10\u0026lt;/span\u0026gt;):\n    \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;print\u0026lt;/span\u0026gt;(i)\n\n\u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;#Usage: %lprun \u0026amp;lt;name_of_the_function\u0026amp;gt; function\u0026lt;/span\u0026gt;\n%lprun -f fun fun()\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;Gives:\u0026lt;/p\u0026gt;\n\u0026lt;ul\u0026gt;\n\u0026lt;li\u0026gt;Line wise stats\u0026lt;/li\u0026gt;\n\u0026lt;/ul\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;a href=\u0026quot;https://i.stack.imgur.com/rusPA.png\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;\u0026lt;img src=\u0026quot;https://i.stack.imgur.com/rusPA.png\u0026quot; alt=\u0026quot;LineProfile\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n\u0026lt;hr\u0026gt;\n\u0026lt;h1\u0026gt;sys.getsizeof\u0026lt;/h1\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;sys.getsizeof(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;code to profile\u0026apos;\u0026lt;/span\u0026gt;)\n\u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# 64 bytes\u0026lt;/span\u0026gt;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;Returns the size of an object in bytes.\u0026lt;/p\u0026gt;\n\u0026lt;hr\u0026gt;\n\u0026lt;h1\u0026gt;asizeof() from pympler\u0026lt;/h1\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; pympler \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; asizeof\nobj = [\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;,\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;2\u0026lt;/span\u0026gt;,(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;hey\u0026quot;\u0026lt;/span\u0026gt;,\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;ha\u0026quot;\u0026lt;/span\u0026gt;),\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;3\u0026lt;/span\u0026gt;]\n\u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;print\u0026lt;/span\u0026gt;(asizeof.asizeof(obj,stats=\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;4\u0026lt;/span\u0026gt;))\n\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;pympler.asizeof can be used to investigate how much memory certain Python objects consume.\nIn contrast to sys.getsizeof, asizeof sizes objects recursively\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;a href=\u0026quot;https://i.stack.imgur.com/8jxQX.png\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;\u0026lt;img src=\u0026quot;https://i.stack.imgur.com/8jxQX.png\u0026quot; alt=\u0026quot;pympler.asizeof\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n\u0026lt;hr\u0026gt;\n\u0026lt;h1\u0026gt;tracker from pympler\u0026lt;/h1\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; pympler \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; tracker\ntr = tracker.SummaryTracker()\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;fun\u0026lt;/span\u0026gt;():\n  li = [\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;,\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;2\u0026lt;/span\u0026gt;,\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;3\u0026lt;/span\u0026gt;]\n  di = {\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;ha\u0026quot;\u0026lt;/span\u0026gt;:\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;haha\u0026quot;\u0026lt;/span\u0026gt;,\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;duh\u0026quot;\u0026lt;/span\u0026gt;:\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;Umm\u0026quot;\u0026lt;/span\u0026gt;}\nfun()\ntr.print_diff()\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;Tracks the lifetime of a function.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;a href=\u0026quot;https://i.stack.imgur.com/SrRj9.png\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;\u0026lt;img src=\u0026quot;https://i.stack.imgur.com/SrRj9.png\u0026quot; alt=\u0026quot;tracker output\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;Pympler package consists of a huge number of high utility functions to profile code. All of which cannot be covered here. See the documentation attached for verbose profile implementations.\u0026lt;/p\u0026gt;\n\u0026lt;h3\u0026gt;Pympler \u0026lt;a href=\u0026quot;https://readthedocs.org/projects/pympler/downloads/pdf/latest/\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;doc\u0026lt;/a\u0026gt;\u0026lt;/h3\u0026gt;\n    ","\n\u0026lt;p\u0026gt;Recently I created a plugin for PyCharm with which you can easily analyse and visualise the results of \u0026lt;code\u0026gt;line_profiler\u0026lt;/code\u0026gt; in the PyCharm editor.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;code\u0026gt;line_profiler\u0026lt;/code\u0026gt; has been mentioned in other answers as well and is a great tool to analyse exactly how much time is spent by the python interpreter in certain lines.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;The PyCharm plugin I\u0026apos;ve created can be found here:\n\u0026lt;a href=\u0026quot;https://plugins.jetbrains.com/plugin/16536-line-profiler\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;https://plugins.jetbrains.com/plugin/16536-line-profiler\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;It needs a helper package in your python environment called \u0026lt;code\u0026gt;line-profiler-pycharm\u0026lt;/code\u0026gt; which can be installed with pip or by the plugin itself.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;After installing the plugin in PyCharm:\u0026lt;/p\u0026gt;\n\u0026lt;ol\u0026gt;\n\u0026lt;li\u0026gt;Decorate any function you want to profile with the \u0026lt;code\u0026gt;line_profiler_pycharm.profile\u0026lt;/code\u0026gt; decorator\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;Run with the \u0026apos;Profile Lines\u0026apos; runner\u0026lt;/li\u0026gt;\n\u0026lt;/ol\u0026gt;\n\u0026lt;p\u0026gt;Screenshot of results:\n\u0026lt;a href=\u0026quot;https://i.stack.imgur.com/nj0LP.png\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;\u0026lt;img src=\u0026quot;https://i.stack.imgur.com/nj0LP.png\u0026quot; alt=\u0026quot;Line Profiler Pycharm results\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;cProfile is great for quick profiling but most of the time it was ending for me with the errors. Function runctx solves this problem by initializing correctly the environment and variables, hope it can be useful for someone:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; cProfile\ncProfile.runctx(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;foo()\u0026apos;\u0026lt;/span\u0026gt;, \u0026lt;span class=\u0026quot;hljs-literal\u0026quot;\u0026gt;None\u0026lt;/span\u0026gt;, \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;locals\u0026lt;/span\u0026gt;())\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n    ","\n\u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;gprof2dot_magic\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;Magic function for \u0026lt;code\u0026gt;gprof2dot\u0026lt;/code\u0026gt; to profile any Python statement as a DOT graph in JupyterLab or Jupyter Notebook.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;\u0026lt;a href=\u0026quot;https://i.stack.imgur.com/IE4Py.gif\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;\u0026lt;img src=\u0026quot;https://i.stack.imgur.com/IE4Py.gif\u0026quot; alt=\u0026quot;enter image description here\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;GitHub repo: \u0026lt;a href=\u0026quot;https://github.com/mattijn/gprof2dot_magic\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;https://github.com/mattijn/gprof2dot_magic\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;installation\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;Make sure you\u0026apos;ve the Python package \u0026lt;code\u0026gt;gprof2dot_magic\u0026lt;/code\u0026gt;.\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;pip install gprof2dot_magic\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Its dependencies \u0026lt;code\u0026gt;gprof2dot\u0026lt;/code\u0026gt; and \u0026lt;code\u0026gt;graphviz\u0026lt;/code\u0026gt; will be installed as well\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;usage\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;To enable the magic function, first load the \u0026lt;code\u0026gt;gprof2dot_magic\u0026lt;/code\u0026gt; module\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;%load_ext gprof2dot_magic\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;and then profile any line statement as a DOT graph as such:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;%gprof2dot \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;print\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;hello world\u0026apos;\u0026lt;/span\u0026gt;)\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;\u0026lt;a href=\u0026quot;https://i.stack.imgur.com/fiGeD.png\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;\u0026lt;img src=\u0026quot;https://i.stack.imgur.com/fiGeD.png\u0026quot; alt=\u0026quot;enter image description here\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;My way is to use yappi (\u0026lt;a href=\u0026quot;https://github.com/sumerc/yappi\u0026quot; rel=\u0026quot;nofollow noreferrer\u0026quot;\u0026gt;https://github.com/sumerc/yappi\u0026lt;/a\u0026gt;). It\u0026apos;s especially useful combined with an RPC server where (even just for debugging) you register method to start, stop and print profiling information, e.g. in this way: \u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;@staticmethod\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;startProfiler\u0026lt;/span\u0026gt;():\n    yappi.start()\n\n\u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;@staticmethod\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;stopProfiler\u0026lt;/span\u0026gt;():\n    yappi.stop()\n\n\u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;@staticmethod\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;printProfiler\u0026lt;/span\u0026gt;():\n    stats = yappi.get_stats(yappi.SORTTYPE_TTOT, yappi.SORTORDER_DESC, \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;20\u0026lt;/span\u0026gt;)\n    statPrint = \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;\\n\u0026apos;\u0026lt;/span\u0026gt;\n    namesArr = [\u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;len\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;str\u0026lt;/span\u0026gt;(stat[\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0\u0026lt;/span\u0026gt;])) \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;for\u0026lt;/span\u0026gt; stat \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;in\u0026lt;/span\u0026gt; stats.func_stats]\n    log.debug(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;namesArr %s\u0026quot;\u0026lt;/span\u0026gt;, \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;str\u0026lt;/span\u0026gt;(namesArr))\n    maxNameLen = \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;max\u0026lt;/span\u0026gt;(namesArr)\n    log.debug(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;maxNameLen: %s\u0026quot;\u0026lt;/span\u0026gt;, maxNameLen)\n\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;for\u0026lt;/span\u0026gt; stat \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;in\u0026lt;/span\u0026gt; stats.func_stats:\n        nameAppendSpaces = [\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos; \u0026apos;\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;for\u0026lt;/span\u0026gt; i \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;in\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;range\u0026lt;/span\u0026gt;(maxNameLen - \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;len\u0026lt;/span\u0026gt;(stat[\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0\u0026lt;/span\u0026gt;]))]\n        log.debug(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;nameAppendSpaces: %s\u0026apos;\u0026lt;/span\u0026gt;, nameAppendSpaces)\n        blankSpace = \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;\u0026apos;\u0026lt;/span\u0026gt;\n        \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;for\u0026lt;/span\u0026gt; space \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;in\u0026lt;/span\u0026gt; nameAppendSpaces:\n            blankSpace += space\n\n        log.debug(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;adding spaces: %s\u0026quot;\u0026lt;/span\u0026gt;, \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;len\u0026lt;/span\u0026gt;(nameAppendSpaces))\n        statPrint = statPrint + \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;str\u0026lt;/span\u0026gt;(stat[\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0\u0026lt;/span\u0026gt;]) + blankSpace + \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot; \u0026quot;\u0026lt;/span\u0026gt; + \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;str\u0026lt;/span\u0026gt;(stat[\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;]).ljust(\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;8\u0026lt;/span\u0026gt;) + \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;\\t\u0026quot;\u0026lt;/span\u0026gt; + \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;str\u0026lt;/span\u0026gt;(\n            \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;round\u0026lt;/span\u0026gt;(stat[\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;2\u0026lt;/span\u0026gt;], \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;2\u0026lt;/span\u0026gt;)).ljust(\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;8\u0026lt;/span\u0026gt; - \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;len\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;str\u0026lt;/span\u0026gt;(stat[\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;2\u0026lt;/span\u0026gt;]))) + \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;\\t\u0026quot;\u0026lt;/span\u0026gt; + \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;str\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;round\u0026lt;/span\u0026gt;(stat[\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;3\u0026lt;/span\u0026gt;], \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;2\u0026lt;/span\u0026gt;)) + \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;\\n\u0026quot;\u0026lt;/span\u0026gt;\n\n    log.log(\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1000\u0026lt;/span\u0026gt;, \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;\\nname\u0026quot;\u0026lt;/span\u0026gt; + \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;\u0026apos;\u0026lt;/span\u0026gt;.ljust(maxNameLen - \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;4\u0026lt;/span\u0026gt;) + \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot; ncall \\tttot \\ttsub\u0026quot;\u0026lt;/span\u0026gt;)\n    log.log(\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1000\u0026lt;/span\u0026gt;, statPrint)\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Then when your program work you can start profiler at any time by calling the \u0026lt;code\u0026gt;startProfiler\u0026lt;/code\u0026gt; RPC method and dump profiling information to a log file by calling \u0026lt;code\u0026gt;printProfiler\u0026lt;/code\u0026gt; (or modify the rpc method to return it to the caller) and get such output:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;2014\u0026lt;/span\u0026gt;-02-\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;19\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;16\u0026lt;/span\u0026gt;:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;32\u0026lt;/span\u0026gt;:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;24\u0026lt;/span\u0026gt;,\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;128\u0026lt;/span\u0026gt;-|SVR-MAIN  |-(Thread-\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;3\u0026lt;/span\u0026gt;   )-Level \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1000\u0026lt;/span\u0026gt;: \nname                                                                                                                                      ncall     ttot    tsub\n\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;2014\u0026lt;/span\u0026gt;-02-\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;19\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;16\u0026lt;/span\u0026gt;:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;32\u0026lt;/span\u0026gt;:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;24\u0026lt;/span\u0026gt;,\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;128\u0026lt;/span\u0026gt;-|SVR-MAIN  |-(Thread-\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;3\u0026lt;/span\u0026gt;   )-Level \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1000\u0026lt;/span\u0026gt;: \nC:\\Python27\\lib\\sched.py.run:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;80\u0026lt;/span\u0026gt;                                                                                                           \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;22\u0026lt;/span\u0026gt;        \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.11\u0026lt;/span\u0026gt;    \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.05\u0026lt;/span\u0026gt;\nM:\\02_documents\\_repos\\09_aheadRepos\\apps\\ahdModbusSrv\\pyAheadRpcSrv\\xmlRpc.py.iterFnc:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;293\u0026lt;/span\u0026gt;                                                \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;22\u0026lt;/span\u0026gt;        \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.11\u0026lt;/span\u0026gt;    \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;\nM:\\02_documents\\_repos\\09_aheadRepos\\apps\\ahdModbusSrv\\serverMain.py.makeIteration:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;515\u0026lt;/span\u0026gt;                                                    \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;22\u0026lt;/span\u0026gt;        \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.11\u0026lt;/span\u0026gt;    \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;\nM:\\02_documents\\_repos\\09_aheadRepos\\apps\\ahdModbusSrv\\pyAheadRpcSrv\\PicklingXMLRPC.py._dispatch:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;66\u0026lt;/span\u0026gt;                                       \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;         \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;     \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;\nC:\\Python27\\lib\\BaseHTTPServer.py.date_time_string:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;464\u0026lt;/span\u0026gt;                                                                                    \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;         \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;     \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;\nc:\\users\\zasiec~\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;\\appdata\\local\\temp\\easy_install-hwcsr1\\psutil-\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1.1\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;.2\u0026lt;/span\u0026gt;-py2\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;.7\u0026lt;/span\u0026gt;-win32.egg.tmp\\psutil\\_psmswindows.py._get_raw_meminfo:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;243\u0026lt;/span\u0026gt;     \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;4\u0026lt;/span\u0026gt;         \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;     \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;\nC:\\Python27\\lib\\SimpleXMLRPCServer.py.decode_request_content:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;537\u0026lt;/span\u0026gt;                                                                          \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;         \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;     \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;\nc:\\users\\zasiec~\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;\\appdata\\local\\temp\\easy_install-hwcsr1\\psutil-\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1.1\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;.2\u0026lt;/span\u0026gt;-py2\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;.7\u0026lt;/span\u0026gt;-win32.egg.tmp\\psutil\\_psmswindows.py.get_system_cpu_times:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;148\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;4\u0026lt;/span\u0026gt;         \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;     \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;\n\u0026amp;lt;string\u0026amp;gt;.__new__:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;8\u0026lt;/span\u0026gt;                                                                                                                        \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;220\u0026lt;/span\u0026gt;       \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;     \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;\nC:\\Python27\\lib\\socket.py.close:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;276\u0026lt;/span\u0026gt;                                                                                                       \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;4\u0026lt;/span\u0026gt;         \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;     \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;\nC:\\Python27\\lib\\threading.py.__init__:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;558\u0026lt;/span\u0026gt;                                                                                                 \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;         \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;     \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;\n\u0026amp;lt;string\u0026amp;gt;.__new__:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;8\u0026lt;/span\u0026gt;                                                                                                                        \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;4\u0026lt;/span\u0026gt;         \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;     \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;\nC:\\Python27\\lib\\threading.py.notify:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;372\u0026lt;/span\u0026gt;                                                                                                   \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;         \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;     \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;\nC:\\Python27\\lib\\rfc822.py.getheader:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;285\u0026lt;/span\u0026gt;                                                                                                   \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;4\u0026lt;/span\u0026gt;         \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;     \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;\nC:\\Python27\\lib\\BaseHTTPServer.py.handle_one_request:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;301\u0026lt;/span\u0026gt;                                                                                  \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;         \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;     \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;\nC:\\Python27\\lib\\xmlrpclib.py.end:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;816\u0026lt;/span\u0026gt;                                                                                                      \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;3\u0026lt;/span\u0026gt;         \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;     \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;\nC:\\Python27\\lib\\SimpleXMLRPCServer.py.do_POST:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;467\u0026lt;/span\u0026gt;                                                                                         \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;         \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;     \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;\nC:\\Python27\\lib\\SimpleXMLRPCServer.py.is_rpc_path_valid:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;460\u0026lt;/span\u0026gt;                                                                               \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;         \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;     \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;\nC:\\Python27\\lib\\SocketServer.py.close_request:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;475\u0026lt;/span\u0026gt;                                                                                         \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;         \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;     \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;\nc:\\users\\zasiec~\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;\\appdata\\local\\temp\\easy_install-hwcsr1\\psutil-\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1.1\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;.2\u0026lt;/span\u0026gt;-py2\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;.7\u0026lt;/span\u0026gt;-win32.egg.tmp\\psutil\\__init__.py.cpu_times:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1066\u0026lt;/span\u0026gt;               \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;4\u0026lt;/span\u0026gt;         \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt;     \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.0\u0026lt;/span\u0026gt; \n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;It may not be very useful for short scripts but helps to optimize server-type processes especially given the \u0026lt;code\u0026gt;printProfiler\u0026lt;/code\u0026gt; method can be called multiple times over time to profile and compare e.g. different program usage scenarios. \u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;In newer versions of yappi, the following code will work:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;@staticmethod\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;printProfile\u0026lt;/span\u0026gt;():\n    yappi.get_func_stats().print_all()\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n    ","\n\u0026lt;p\u0026gt;To add on to \u0026lt;a href=\u0026quot;https://stackoverflow.com/a/582337/1070617\u0026quot;\u0026gt;https://stackoverflow.com/a/582337/1070617\u0026lt;/a\u0026gt;,\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;I wrote this module that allows you to use cProfile and view its output easily. More here: \u0026lt;a href=\u0026quot;https://github.com/ymichael/cprofilev\u0026quot; rel=\u0026quot;nofollow noreferrer\u0026quot;\u0026gt;https://github.com/ymichael/cprofilev\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;$ python -m cprofilev /your/python/program\n\u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# Go to http://localhost:4000 to view collected statistics.\u0026lt;/span\u0026gt;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Also see: \u0026lt;a href=\u0026quot;http://ymichael.com/2014/03/08/profiling-python-with-cprofile.html\u0026quot; rel=\u0026quot;nofollow noreferrer\u0026quot;\u0026gt;http://ymichael.com/2014/03/08/profiling-python-with-cprofile.html\u0026lt;/a\u0026gt; on how to make sense of the collected statistics.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;A new tool to handle profiling in Python is PyVmMonitor: \u0026lt;a href=\u0026quot;http://www.pyvmmonitor.com/\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;http://www.pyvmmonitor.com/\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;It has some unique features such as\u0026lt;/p\u0026gt;\n\n\u0026lt;ul\u0026gt;\n\u0026lt;li\u0026gt;Attach profiler to a running (CPython) program\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;On demand profiling with Yappi integration\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;Profile on a different machine\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;Multiple processes support (multiprocessing, django...)\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;Live sampling/CPU view (with time range selection)\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;Deterministic profiling through cProfile/profile integration\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;Analyze existing PStats results\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;Open DOT files\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;Programatic API access\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;Group samples by method or line\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;PyDev integration\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;PyCharm integration\u0026lt;/li\u0026gt;\n\u0026lt;/ul\u0026gt;\n\n\u0026lt;p\u0026gt;Note: it\u0026apos;s commercial, but free for open source.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;It would depend on what you want to see out of profiling. Simple time \nmetrics can be given by (bash). \u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;time python python_prog.py\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Even \u0026apos;/usr/bin/time\u0026apos; can output detailed metrics by using \u0026apos;--verbose\u0026apos; flag.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;To check time metrics given by each function and to better understand how much time is spent on functions, you can use the inbuilt cProfile in python. \u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;Going into more detailed metrics like performance, time is not the only metric. You can worry about memory, threads etc.\u0026lt;br\u0026gt;\nProfiling options:\u0026lt;br\u0026gt;\n1. \u0026lt;strong\u0026gt;line_profiler\u0026lt;/strong\u0026gt; is another profiler used commonly to find out timing metrics line-by-line.\u0026lt;br\u0026gt;\n2. \u0026lt;strong\u0026gt;memory_profiler\u0026lt;/strong\u0026gt; is a tool to profile memory usage.\u0026lt;br\u0026gt;\n3. \u0026lt;strong\u0026gt;heapy (from project Guppy)\u0026lt;/strong\u0026gt; Profile how objects in the heap are used. \u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;These are some of the common ones I tend to use. But if you want to find out more, try reading this \u0026lt;a href=\u0026quot;http://shop.oreilly.com/product/0636920028963.do\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;book\u0026lt;/a\u0026gt;\nIt is a pretty good book on starting out with performance in mind. You can move onto advanced topics on using Cython and JIT(Just-in-time) compiled python. \u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;I just developed my own profiler inspired from pypref_time:\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;a href=\u0026quot;https://github.com/modaresimr/auto_profiler\u0026quot; rel=\u0026quot;nofollow noreferrer\u0026quot;\u0026gt;https://github.com/modaresimr/auto_profiler\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;By adding a decorator it will show a tree of time-consuming functions\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;code\u0026gt;@Profiler(depth=4, on_disable=show)\u0026lt;/code\u0026gt;\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;Install by: pip install auto_profiler\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;h1\u0026gt;Example\u0026lt;/h1\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; time \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# line number 1\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; random\n\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; auto_profiler \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; Profiler, Tree\n\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;f1\u0026lt;/span\u0026gt;():\n    mysleep(\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;.6\u0026lt;/span\u0026gt;+random.random())\n\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;mysleep\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;t\u0026lt;/span\u0026gt;):\n    time.sleep(t)\n\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;fact\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;i\u0026lt;/span\u0026gt;):\n    f1()\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;if\u0026lt;/span\u0026gt;(i==\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;):\n        \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;return\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;return\u0026lt;/span\u0026gt; i*fact(i-\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;)\n\n\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;show\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;p\u0026lt;/span\u0026gt;):\n    \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;print\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;Time   [Hits * PerHit] Function name [Called from] [Function Location]\\n\u0026apos;\u0026lt;/span\u0026gt;+\\\n          \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;-----------------------------------------------------------------------\u0026apos;\u0026lt;/span\u0026gt;)\n    \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;print\u0026lt;/span\u0026gt;(Tree(p.root, threshold=\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.5\u0026lt;/span\u0026gt;))\n    \n\u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;@Profiler(\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;depth=\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;4\u0026lt;/span\u0026gt;, on_disable=show\u0026lt;/span\u0026gt;)\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;main\u0026lt;/span\u0026gt;():\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;for\u0026lt;/span\u0026gt; i \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;in\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;range\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;5\u0026lt;/span\u0026gt;):\n        f1()\n\n    fact(\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;3\u0026lt;/span\u0026gt;)\n\n\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;if\u0026lt;/span\u0026gt; __name__ == \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;__main__\u0026apos;\u0026lt;/span\u0026gt;:\n    main()\n\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;h2\u0026gt;Example Output\u0026lt;/h2\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\nTime   [Hits * PerHit] Function name [Called \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt;] [function location]\n-----------------------------------------------------------------------\n\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;8.974\u0026lt;/span\u0026gt;s [\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt; * \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;8.974\u0026lt;/span\u0026gt;]  main  [auto-profiler/profiler.py:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;267\u0026lt;/span\u0026gt;]  [/test/t2.py:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;30\u0026lt;/span\u0026gt;]\n \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;5.954\u0026lt;/span\u0026gt;s [\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;5\u0026lt;/span\u0026gt; * \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1.191\u0026lt;/span\u0026gt;]  f1  [/test/t2.py:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;34\u0026lt;/span\u0026gt;]  [/test/t2.py:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;14\u0026lt;/span\u0026gt;]\n    \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;5.954\u0026lt;/span\u0026gt;s [\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;5\u0026lt;/span\u0026gt; * \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1.191\u0026lt;/span\u0026gt;]  mysleep  [/test/t2.py:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;15\u0026lt;/span\u0026gt;]  [/test/t2.py:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;17\u0026lt;/span\u0026gt;]\n        \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;5.954\u0026lt;/span\u0026gt;s [\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;5\u0026lt;/span\u0026gt; * \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1.191\u0026lt;/span\u0026gt;]  \u0026amp;lt;time.sleep\u0026amp;gt;\n|\n|\n|   \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# The rest is for the example recursive function call fact\u0026lt;/span\u0026gt;\n \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;3.020\u0026lt;/span\u0026gt;s [\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt; * \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;3.020\u0026lt;/span\u0026gt;]  fact  [/test/t2.py:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;36\u0026lt;/span\u0026gt;]  [/test/t2.py:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;20\u0026lt;/span\u0026gt;]\n     \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.849\u0026lt;/span\u0026gt;s [\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt; * \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.849\u0026lt;/span\u0026gt;]  f1  [/test/t2.py:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;21\u0026lt;/span\u0026gt;]  [/test/t2.py:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;14\u0026lt;/span\u0026gt;]\n        \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.849\u0026lt;/span\u0026gt;s [\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt; * \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.849\u0026lt;/span\u0026gt;]  mysleep  [/test/t2.py:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;15\u0026lt;/span\u0026gt;]  [/test/t2.py:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;17\u0026lt;/span\u0026gt;]\n            \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.849\u0026lt;/span\u0026gt;s [\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt; * \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.849\u0026lt;/span\u0026gt;]  \u0026amp;lt;time.sleep\u0026amp;gt;\n     \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;2.171\u0026lt;/span\u0026gt;s [\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt; * \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;2.171\u0026lt;/span\u0026gt;]  fact  [/test/t2.py:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;24\u0026lt;/span\u0026gt;]  [/test/t2.py:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;20\u0026lt;/span\u0026gt;]\n         \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1.552\u0026lt;/span\u0026gt;s [\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt; * \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1.552\u0026lt;/span\u0026gt;]  f1  [/test/t2.py:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;21\u0026lt;/span\u0026gt;]  [/test/t2.py:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;14\u0026lt;/span\u0026gt;]\n            \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1.552\u0026lt;/span\u0026gt;s [\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt; * \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1.552\u0026lt;/span\u0026gt;]  mysleep  [/test/t2.py:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;15\u0026lt;/span\u0026gt;]  [/test/t2.py:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;17\u0026lt;/span\u0026gt;]\n         \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.619\u0026lt;/span\u0026gt;s [\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt; * \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.619\u0026lt;/span\u0026gt;]  fact  [/test/t2.py:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;24\u0026lt;/span\u0026gt;]  [/test/t2.py:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;20\u0026lt;/span\u0026gt;]\n             \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.619\u0026lt;/span\u0026gt;s [\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt; * \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0.619\u0026lt;/span\u0026gt;]  f1  [/test/t2.py:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;21\u0026lt;/span\u0026gt;]  [/test/t2.py:\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;14\u0026lt;/span\u0026gt;]\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n    ","\n\u0026lt;blockquote\u0026gt;\n  \u0026lt;p\u0026gt;Ever want to know what the hell that python script is doing? Enter the\n  Inspect Shell. Inspect Shell lets you print/alter globals and run\n  functions without interrupting the running script. Now with\n  auto-complete and command history (only on linux).\u0026lt;/p\u0026gt;\n  \n  \u0026lt;p\u0026gt;Inspect Shell is not a pdb-style debugger.\u0026lt;/p\u0026gt;\n\u0026lt;/blockquote\u0026gt;\n\n\u0026lt;p\u0026gt;\u0026lt;a href=\u0026quot;https://github.com/amoffat/Inspect-Shell\u0026quot; rel=\u0026quot;nofollow\u0026quot;\u0026gt;https://github.com/amoffat/Inspect-Shell\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;You could use that (and your wristwatch).\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;There\u0026apos;s also a statistical profiler called \u0026lt;a href=\u0026quot;https://pypi.python.org/pypi/statprof/\u0026quot; rel=\u0026quot;nofollow noreferrer\u0026quot;\u0026gt;\u0026lt;code\u0026gt;statprof\u0026lt;/code\u0026gt;\u0026lt;/a\u0026gt;. It\u0026apos;s a sampling profiler, so it adds minimal overhead to your code and gives line-based (not just function-based) timings. It\u0026apos;s more suited to soft real-time applications like games, but may be have less precision than cProfile.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;The \u0026lt;a href=\u0026quot;https://pypi.python.org/pypi/statprof/\u0026quot; rel=\u0026quot;nofollow noreferrer\u0026quot;\u0026gt;version in pypi\u0026lt;/a\u0026gt; is a bit old, so can install it with \u0026lt;code\u0026gt;pip\u0026lt;/code\u0026gt; by specifying \u0026lt;a href=\u0026quot;https://github.com/bos/statprof.py\u0026quot; rel=\u0026quot;nofollow noreferrer\u0026quot;\u0026gt;the git repository\u0026lt;/a\u0026gt;:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;pip install git+git://github.com/bos/statprof.py@1a33eba91899afe17a8b752c6dfdec6f05dd0c01\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;You can run it like this:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; statprof\n\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;with\u0026lt;/span\u0026gt; statprof.profile():\n    my_questionable_function()\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;See also \u0026lt;a href=\u0026quot;https://stackoverflow.com/a/10333592/320036\u0026quot;\u0026gt;https://stackoverflow.com/a/10333592/320036\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;I found cprofiler and other ressources to be more for optimization purpose rather than debugging.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;I made my own testing module instead for simple python scripts speed testing. (In my case 1K+ lines py file was tested using ScriptProfilerPy and speedup the code by 10x in minutes afterwards.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;The module ScriptProfilerPy() will run your code adding timestamp to it.\nI put the module here:\n\u0026lt;a href=\u0026quot;https://github.com/Lucas-BLP/ScriptProfilerPy\u0026quot; rel=\u0026quot;nofollow noreferrer\u0026quot;\u0026gt;https://github.com/Lucas-BLP/ScriptProfilerPy\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;Use:\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; speed_testpy \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; ScriptProfilerPy\n\nScriptProfilerPy(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;path_to_your_script_to_test.py\u0026quot;\u0026lt;/span\u0026gt;).Profiler()\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;output:\n\u0026lt;a href=\u0026quot;https://i.stack.imgur.com/RkRZD.png\u0026quot; rel=\u0026quot;nofollow noreferrer\u0026quot;\u0026gt;\u0026lt;img src=\u0026quot;https://i.stack.imgur.com/RkRZD.png\u0026quot; alt=\u0026quot;Output of the code after testing\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n    "],"id":536,"title":"How do I profile a Python script?","content":"\n                \n\u0026lt;p\u0026gt;\u0026lt;a href=\u0026quot;http://en.wikipedia.org/wiki/Project_Euler\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;Project Euler\u0026lt;/a\u0026gt; and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs. With Python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to \u0026lt;code\u0026gt;__main__\u0026lt;/code\u0026gt;.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;What is a good way to profile how long a Python program takes to run?\u0026lt;/p\u0026gt;\n    ","slug":"how-do-i-profile-a-python-script-1657388346692","postType":"QUESTION","createdAt":"2022-07-09T17:39:06.000Z","updatedAt":"2022-07-09T17:39:06.000Z","tags":[],"relatedQuestions":[]},"randomQuestions":[{"title":"Reference: What is variable scope, which variables are accessible from where and what are \"undefined variable\" errors?","slug":"reference:-what-is-variable-scope-which-variables-are-accessible-from-where-and-what-are-\"undefined-variable\"-errors-1657384644697"},{"title":"What is an undefined reference/unresolved external symbol error and how do I fix it?","slug":"what-is-an-undefined-referenceunresolved-external-symbol-error-and-how-do-i-fix-it-1657384255179"},{"title":"How do I merge two dictionaries in a single expression?","slug":"how-do-i-merge-two-dictionaries-in-a-single-expression-1657387593160"},{"title":"Persist variables between page loads","slug":"persist-variables-between-page-loads-1657388558452"},{"title":"Is it possible for flex items to align tightly to the items above them?","slug":"is-it-possible-for-flex-items-to-align-tightly-to-the-items-above-them-1657388511179"},{"title":"Accessing an array out of bounds gives no error, why?","slug":"accessing-an-array-out-of-bounds-gives-no-error-why-1657387979932"},{"title":"Sorting object property by values","slug":"sorting-object-property-by-values-1657388367300"},{"title":"How do I make Git forget about a file that was tracked, but is now in .gitignore?","slug":"how-do-i-make-git-forget-about-a-file-that-was-tracked-but-is-now-in-.gitignore-1657387328843"},{"title":"How can I prevent SQL injection in PHP?","slug":"how-can-i-prevent-sql-injection-in-php-1657384220094"},{"title":"What is dependency injection?","slug":"what-is-dependency-injection-1657387953056"},{"title":"What does if __name__ == \"__main__\": do?","slug":"what-does-if-__name__-\"__main__\":-do-1657384825815"},{"title":"Using fflush(stdin)","slug":"using-fflush(stdin)-1657387602771"},{"title":"How can I vertically align elements in a div?","slug":"how-can-i-vertically-align-elements-in-a-div-1657385504431"},{"title":"Serialize and Deserialize Json and Json Array in Unity","slug":"serialize-and-deserialize-json-and-json-array-in-unity-1657388273270"},{"title":"Understanding slicing","slug":"understanding-slicing-1657384397680"},{"title":"How to check if element is visible after scrolling?","slug":"how-to-check-if-element-is-visible-after-scrolling-1657387987960"},{"title":"How should a model be structured in MVC? [closed]","slug":"how-should-a-model-be-structured-in-mvc-closed-1657388394807"},{"title":"Reference — What does this symbol mean in PHP?","slug":"reference-what-does-this-symbol-mean-in-php-1657384561666"},{"title":"Why are floating point numbers inaccurate?","slug":"why-are-floating-point-numbers-inaccurate-1657387346111"},{"title":"What is a StackOverflowError?","slug":"what-is-a-stackoverflowerror-1657388319634"}]},"__N_SSG":true},"page":"/questions/[slug]","query":{"slug":"how-do-i-profile-a-python-script-1657388346692"},"buildId":"DSpI0pSdXueTMCIVyw0q4","isFallback":false,"gsp":true,"locale":"en","locales":["en"],"defaultLocale":"en","scriptLoader":[]}</script></body></html>