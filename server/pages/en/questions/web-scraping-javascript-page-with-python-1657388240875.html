<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content="@solutionschecker.com"/><meta name="twitter:creator" content="@solutionschecker.com"/><meta property="og:url" content="https://solutionschecker.com"/><meta property="og:type" content="website"/><meta property="og:image" content="https://solutionschecker.com/solutions-checker-banner.png"/><meta property="og:image:alt" content="Find solution for coding, HTML, CSS, JAVASCRIPT, MYSQL, PHP, PYTHON,... quickly. - solutionschecker.com"/><script type="application/ld+json">{"@context":"https://schema.org","@type":"Organization","logo":"/logo.svg","url":"https://solutionschecker.com"}</script><title>Web-scraping JavaScript page with Python | Solutions Checker</title><meta name="robots" content="index,follow"/><meta name="description" content="I&#x27;m trying to develop a simple web scraper. I want to extract text without the HTML code. It works on plain HTML, but not in some pages where JavaScript code adds text.
For example, if some JavaScript code adds some text, I can&#x27;t see it, because when I call:
response = urllib2.urlopen(request)

I get the original text without the added one (because JavaScript is executed in the client).
So, I&#x27;m looking for some ideas to solve this problem.
    "/><meta property="og:title" content="Web-scraping JavaScript page with Python | Solutions Checker"/><meta property="og:description" content="I&#x27;m trying to develop a simple web scraper. I want to extract text without the HTML code. It works on plain HTML, but not in some pages where JavaScript code adds text.
For example, if some JavaScript code adds some text, I can&#x27;t see it, because when I call:
response = urllib2.urlopen(request)

I get the original text without the added one (because JavaScript is executed in the client).
So, I&#x27;m looking for some ideas to solve this problem.
    "/><script type="application/ld+json">{"@context":"https://schema.org","@type":"QAPage","mainEntity":{"name":"Web-scraping JavaScript page with Python","text":"I&apos;m trying to develop a simple web scraper. I want to extract text without the HTML code. It works on plain HTML, but not in some pages where JavaScript code adds text.\nFor example, if some JavaScript code adds some text, I can&apos;t see it, because when I call:\nresponse = urllib2.urlopen(request)\n\nI get the original text without the added one (because JavaScript is executed in the client).\nSo, I&apos;m looking for some ideas to solve this problem.\n    ","answerCount":18,"upVoteCount":500,"suggestedAnswer":[{"text":"EDIT Sept 2021: phantomjs isn&apos;t maintained any more, either\nEDIT 30/Dec/2017: This answer appears in top results of Google searches, so I decided to update it. The old answer is still at the end.\ndryscape isn&apos;t maintained anymore and the library dryscape developers recommend is Python 2 only. I have found using Selenium&apos;s python library with Phantom JS as a web driver fast enough and easy to get the work done.\nOnce you have installed Phantom JS, make sure the phantomjs binary is available in the current path:\nphantomjs --version\n# result:\n2.1.1\n\n#Example\nTo give an example, I created a sample page with following HTML code. (link):\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n  &lt;meta charset=&quot;utf-8&quot;&gt;\n  &lt;title&gt;Javascript scraping test&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n  &lt;p id=&apos;intro-text&apos;&gt;No javascript support&lt;/p&gt;\n  &lt;script&gt;\n     document.getElementById(&apos;intro-text&apos;).innerHTML = &apos;Yay! Supports javascript&apos;;\n  &lt;/script&gt; \n&lt;/body&gt;\n&lt;/html&gt;\n\nwithout javascript it says: No javascript support and with javascript: Yay! Supports javascript\n#Scraping without JS support:\nimport requests\nfrom bs4 import BeautifulSoup\nresponse = requests.get(my_url)\nsoup = BeautifulSoup(response.text)\nsoup.find(id=&quot;intro-text&quot;)\n# Result:\n&lt;p id=&quot;intro-text&quot;&gt;No javascript support&lt;/p&gt;\n\n#Scraping with JS support:\nfrom selenium import webdriver\ndriver = webdriver.PhantomJS()\ndriver.get(my_url)\np_element = driver.find_element_by_id(id_=&apos;intro-text&apos;)\nprint(p_element.text)\n# result:\n&apos;Yay! Supports javascript&apos;\n\n\nYou can also use Python library dryscrape to scrape javascript driven websites.\n#Scraping with JS support:\nimport dryscrape\nfrom bs4 import BeautifulSoup\nsession = dryscrape.Session()\nsession.visit(my_url)\nresponse = session.body()\nsoup = BeautifulSoup(response)\nsoup.find(id=&quot;intro-text&quot;)\n# Result:\n&lt;p id=&quot;intro-text&quot;&gt;Yay! Supports javascript&lt;/p&gt;\n\n    ","url":"/questions/[slug]#solution1","@type":"Answer","upvoteCount":0},{"text":"We are not getting the correct results because any javascript generated content needs to be rendered on the DOM. When we fetch an HTML page, we fetch the initial, unmodified by javascript, DOM.\n\nTherefore we need to render the javascript content before we crawl the page.\n\nAs selenium is already mentioned many times in this thread (and how slow it gets sometimes was mentioned also), I will list two other possible solutions.\n\n\n\nSolution 1: This is a very nice tutorial on how to use Scrapy to crawl javascript generated content and we are going to follow just that.\n\nWhat we will need:\n\n\nDocker installed in our machine. This is a plus over other solutions until this point, as it utilizes an OS-independent platform.\nInstall Splash following the instruction listed for our corresponding OS.Quoting from splash documentation:\n\n\n  Splash is a javascript rendering service. Its a lightweight web browser with an HTTP API, implemented in Python 3 using Twisted and QT5. \n\n\nEssentially we are going to use Splash to render Javascript generated content.\nRun the splash server: sudo docker run -p 8050:8050 scrapinghub/splash.\nInstall the scrapy-splash plugin: pip install scrapy-splash\nAssuming that we already have a Scrapy project created (if not, let&apos;s make one), we will follow the guide and update the settings.py:\n\n\n  Then go to your scrapy projects settings.py and set these middlewares:\n\nDOWNLOADER_MIDDLEWARES = {\n      &apos;scrapy_splash.SplashCookiesMiddleware&apos;: 723,\n      &apos;scrapy_splash.SplashMiddleware&apos;: 725,\n      &apos;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware&apos;: 810,\n}\n\n  \n  The URL of the Splash server(if youre using Win or OSX this should be the URL of the docker machine: How to get a Docker container&apos;s IP address from the host?):\n\nSPLASH_URL = &apos;http://localhost:8050&apos;\n\n  \n  And finally you need to set these values too:\n\nDUPEFILTER_CLASS = &apos;scrapy_splash.SplashAwareDupeFilter&apos;\nHTTPCACHE_STORAGE = &apos;scrapy_splash.SplashAwareFSCacheStorage&apos;\n\n\nFinally, we can use a SplashRequest:\n\n\n  In a normal spider you have Request objects which you can use to open URLs. If the page you want to open contains JS generated data you have to use SplashRequest(or SplashFormRequest) to render the page. Heres a simple example:\n\nclass MySpider(scrapy.Spider):\n    name = &quot;jsscraper&quot;\n    start_urls = [&quot;http://quotes.toscrape.com/js/&quot;]\n\n    def start_requests(self):\n        for url in self.start_urls:\n        yield SplashRequest(\n            url=url, callback=self.parse, endpoint=&apos;render.html&apos;\n        )\n\n    def parse(self, response):\n        for q in response.css(&quot;div.quote&quot;):\n        quote = QuoteItem()\n        quote[&quot;author&quot;] = q.css(&quot;.author::text&quot;).extract_first()\n        quote[&quot;quote&quot;] = q.css(&quot;.text::text&quot;).extract_first()\n        yield quote\n\n  \n  SplashRequest renders the URL as html and returns the response which you can use in the callback(parse) method.\n\n\n\n\n\nSolution 2: Let&apos;s call this experimental at the moment (May 2018)...\nThis solution is for Python&apos;s version 3.6 only (at the moment).\n\nDo you know the requests module (well who doesn&apos;t)?\nNow it has a web crawling little sibling: requests-HTML:\n\n\n  This library intends to make parsing HTML (e.g. scraping the web) as simple and intuitive as possible.\n\n\n\nInstall requests-html: pipenv install requests-html\nMake a request to the page&apos;s url:\n\nfrom requests_html import HTMLSession\n\nsession = HTMLSession()\nr = session.get(a_page_url)\n\nRender the response to get the Javascript generated bits:\n\nr.html.render()\n\n\n\nFinally, the module seems to offer scraping capabilities.\nAlternatively, we can try the well-documented way of using BeautifulSoup with the r.html object we just rendered.\n    ","url":"/questions/[slug]#solution2","@type":"Answer","upvoteCount":0},{"text":"Maybe selenium can do it.\n\nfrom selenium import webdriver\nimport time\n\ndriver = webdriver.Firefox()\ndriver.get(url)\ntime.sleep(5)\nhtmlSource = driver.page_source\n\n    ","url":"/questions/[slug]#solution3","@type":"Answer","upvoteCount":0},{"text":"If you have ever used the Requests module for python before, I recently found out that the developer created a new module called Requests-HTML which now also has the ability to render JavaScript.\n\nYou can also visit https://html.python-requests.org/ to learn more about this module, or if your only interested about rendering JavaScript then you can visit https://html.python-requests.org/?#javascript-support to directly learn how to use the module to render JavaScript using Python.\n\nEssentially, Once you correctly install the Requests-HTML module, the following example, which is shown on the above link, shows how you can use this module to scrape a website and render JavaScript contained within the website:\n\nfrom requests_html import HTMLSession\nsession = HTMLSession()\n\nr = session.get(&apos;http://python-requests.org/&apos;)\n\nr.html.render()\n\nr.html.search(&apos;Python 2 will retire in only {months} months!&apos;)[&apos;months&apos;]\n\n&apos;&lt;time&gt;25&lt;/time&gt;&apos; #This is the result.\n\n\nI recently learnt about this from a YouTube video. Click Here! to watch the YouTube video, which demonstrates how the module works.\n    ","url":"/questions/[slug]#solution4","@type":"Answer","upvoteCount":0},{"text":"It sounds like the data you&apos;re really looking for can be accessed via secondary URL called by some javascript on the primary page.\n\nWhile you could try running javascript on the server to handle this, a simpler approach  to might be to load up the page using Firefox and use a tool like Charles or Firebug to identify exactly what that secondary URL is. Then you can just query that URL directly for the data you are interested in.\n    ","url":"/questions/[slug]#solution5","@type":"Answer","upvoteCount":0},{"text":"This seems to be a good solution also, taken from a great blog post\n\nimport sys  \nfrom PyQt4.QtGui import *  \nfrom PyQt4.QtCore import *  \nfrom PyQt4.QtWebKit import *  \nfrom lxml import html \n\n#Take this class for granted.Just use result of rendering.\nclass Render(QWebPage):  \n  def __init__(self, url):  \n    self.app = QApplication(sys.argv)  \n    QWebPage.__init__(self)  \n    self.loadFinished.connect(self._loadFinished)  \n    self.mainFrame().load(QUrl(url))  \n    self.app.exec_()  \n\n  def _loadFinished(self, result):  \n    self.frame = self.mainFrame()  \n    self.app.quit()  \n\nurl = &apos;http://pycoders.com/archive/&apos;  \nr = Render(url)  \nresult = r.frame.toHtml()\n# This step is important.Converting QString to Ascii for lxml to process\n\n# The following returns an lxml element tree\narchive_links = html.fromstring(str(result.toAscii()))\nprint archive_links\n\n# The following returns an array containing the URLs\nraw_links = archive_links.xpath(&apos;//div[@class=&quot;campaign&quot;]/a/@href&apos;)\nprint raw_links\n\n    ","url":"/questions/[slug]#solution6","@type":"Answer","upvoteCount":0},{"text":"Selenium is the best for scraping JS and Ajax content.\n\nCheck this article for extracting data from the web using Python\n\n$ pip install selenium\n\n\nThen download Chrome webdriver.\n\nfrom selenium import webdriver\n\nbrowser = webdriver.Chrome()\n\nbrowser.get(&quot;https://www.python.org/&quot;)\n\nnav = browser.find_element_by_id(&quot;mainnav&quot;)\n\nprint(nav.text)\n\n\nEasy, right?\n    ","url":"/questions/[slug]#solution7","@type":"Answer","upvoteCount":0},{"text":"You can also execute javascript using webdriver.\nfrom selenium import webdriver\n\ndriver = webdriver.Firefox()\ndriver.get(url)\ndriver.execute_script(&apos;document.title&apos;)\n\nor store the value in a variable\nresult = driver.execute_script(&apos;var text = document.title ; return text&apos;)\n\n    ","url":"/questions/[slug]#solution8","@type":"Answer","upvoteCount":0},{"text":"I personally prefer using scrapy and selenium and dockerizing both in separate containers. This way you can install both with minimal hassle and crawl modern websites that almost all contain javascript in one form or another. Here&apos;s an example:\n\nUse the scrapy startproject to create your scraper and write your spider, the skeleton can be as simple as this:\n\nimport scrapy\n\n\nclass MySpider(scrapy.Spider):\n    name = &apos;my_spider&apos;\n    start_urls = [&apos;https://somewhere.com&apos;]\n\n    def start_requests(self):\n        yield scrapy.Request(url=self.start_urls[0])\n\n\n    def parse(self, response):\n\n        # do stuff with results, scrape items etc.\n        # now were just checking everything worked\n\n        print(response.body)\n\n\nThe real magic happens in the middlewares.py. Overwrite two methods in the downloader middleware,  __init__ and  process_request, in the following way:\n\n# import some additional modules that we need\nimport os\nfrom copy import deepcopy\nfrom time import sleep\n\nfrom scrapy import signals\nfrom scrapy.http import HtmlResponse\nfrom selenium import webdriver\n\nclass SampleProjectDownloaderMiddleware(object):\n\ndef __init__(self):\n    SELENIUM_LOCATION = os.environ.get(&apos;SELENIUM_LOCATION&apos;, &apos;NOT_HERE&apos;)\n    SELENIUM_URL = f&apos;http://{SELENIUM_LOCATION}:4444/wd/hub&apos;\n    chrome_options = webdriver.ChromeOptions()\n\n    # chrome_options.add_experimental_option(&quot;mobileEmulation&quot;, mobile_emulation)\n    self.driver = webdriver.Remote(command_executor=SELENIUM_URL,\n                                   desired_capabilities=chrome_options.to_capabilities())\n\n\ndef process_request(self, request, spider):\n\n    self.driver.get(request.url)\n\n    # sleep a bit so the page has time to load\n    # or monitor items on page to continue as soon as page ready\n    sleep(4)\n\n    # if you need to manipulate the page content like clicking and scrolling, you do it here\n    # self.driver.find_element_by_css_selector(&apos;.my-class&apos;).click()\n\n    # you only need the now properly and completely rendered html from your page to get results\n    body = deepcopy(self.driver.page_source)\n\n    # copy the current url in case of redirects\n    url = deepcopy(self.driver.current_url)\n\n    return HtmlResponse(url, body=body, encoding=&apos;utf-8&apos;, request=request)\n\n\nDont forget to enable this middlware by uncommenting the next lines in the settings.py file:\n\nDOWNLOADER_MIDDLEWARES = {\n&apos;sample_project.middlewares.SampleProjectDownloaderMiddleware&apos;: 543,}\n\n\nNext for dockerization. Create your Dockerfile from a lightweight image (I&apos;m using python Alpine here), copy your project directory to it, install requirements:\n\n# Use an official Python runtime as a parent image\nFROM python:3.6-alpine\n\n# install some packages necessary to scrapy and then curl because it&apos;s  handy for debugging\nRUN apk --update add linux-headers libffi-dev openssl-dev build-base libxslt-dev libxml2-dev curl python-dev\n\nWORKDIR /my_scraper\n\nADD requirements.txt /my_scraper/\n\nRUN pip install -r requirements.txt\n\nADD . /scrapers\n\n\nAnd finally bring it all together in docker-compose.yaml:\n\nversion: &apos;2&apos;\nservices:\n  selenium:\n    image: selenium/standalone-chrome\n    ports:\n      - &quot;4444:4444&quot;\n    shm_size: 1G\n\n  my_scraper:\n    build: .\n    depends_on:\n      - &quot;selenium&quot;\n    environment:\n      - SELENIUM_LOCATION=samplecrawler_selenium_1\n    volumes:\n      - .:/my_scraper\n    # use this command to keep the container running\n    command: tail -f /dev/null\n\n\nRun docker-compose up -d. If you&apos;re doing this the first time it will take a while for it to fetch the latest selenium/standalone-chrome and the build your scraper image as well. \n\nOnce it&apos;s done, you can check that your containers are running with docker ps and also check that the name of the selenium container matches that of the environment variable that we passed to our scraper container (here, it was SELENIUM_LOCATION=samplecrawler_selenium_1). \n\nEnter your scraper container with docker exec -ti YOUR_CONTAINER_NAME sh , the command for me was docker exec -ti samplecrawler_my_scraper_1 sh, cd into the right directory and run your scraper with scrapy crawl my_spider.\n\nThe entire thing is on my github page and you can get it from here\n    ","url":"/questions/[slug]#solution9","@type":"Answer","upvoteCount":0},{"text":"A mix of BeautifulSoup and Selenium works very well for me.\n\nfrom selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nfrom bs4 import BeautifulSoup as bs\n\ndriver = webdriver.Firefox()\ndriver.get(&quot;http://somedomain/url_that_delays_loading&quot;)\n    try:\n        element = WebDriverWait(driver, 10).until(\n        EC.presence_of_element_located((By.ID, &quot;myDynamicElement&quot;))) #waits 10 seconds until element is located. Can have other wait conditions  such as visibility_of_element_located or text_to_be_present_in_element\n\n        html = driver.page_source\n        soup = bs(html, &quot;lxml&quot;)\n        dynamic_text = soup.find_all(&quot;p&quot;, {&quot;class&quot;:&quot;class_name&quot;}) #or other attributes, optional\n    else:\n        print(&quot;Couldnt locate element&quot;)\n\n\nP.S. You can find more wait conditions here\n    ","url":"/questions/[slug]#solution10","@type":"Answer","upvoteCount":0},{"text":"Using PyQt5\n\nfrom PyQt5.QtWidgets import QApplication\nfrom PyQt5.QtCore import QUrl\nfrom PyQt5.QtWebEngineWidgets import QWebEnginePage\nimport sys\nimport bs4 as bs\nimport urllib.request\n\n\nclass Client(QWebEnginePage):\n    def __init__(self,url):\n        global app\n        self.app = QApplication(sys.argv)\n        QWebEnginePage.__init__(self)\n        self.html = &quot;&quot;\n        self.loadFinished.connect(self.on_load_finished)\n        self.load(QUrl(url))\n        self.app.exec_()\n\n    def on_load_finished(self):\n        self.html = self.toHtml(self.Callable)\n        print(&quot;Load Finished&quot;)\n\n    def Callable(self,data):\n        self.html = data\n        self.app.quit()\n\n# url = &quot;&quot;\n# client_response = Client(url)\n# print(client_response.html)\n\n    ","url":"/questions/[slug]#solution11","@type":"Answer","upvoteCount":0},{"text":"You&apos;ll want to use urllib, requests, beautifulSoup and selenium web driver in your script for different parts of the page, (to name a few).\nSometimes you&apos;ll get what you need with just one of these modules.\nSometimes you&apos;ll need two, three, or all of these modules.\nSometimes you&apos;ll need to switch off the js on your browser.\nSometimes you&apos;ll need header info in your script.\nNo websites can be scraped the same way and no website can be scraped in the same way forever without having to modify your crawler, usually after a few months. But they can all be scraped! Where there&apos;s a will there&apos;s a way for sure.\nIf you need scraped data continuously into the future just scrape everything you need and store it in .dat files with pickle.\nJust keep searching how to try what with these modules and copying and pasting your errors into the Google.\n    ","url":"/questions/[slug]#solution12","@type":"Answer","upvoteCount":0},{"text":"Pyppeteer\nYou might consider Pyppeteer, a Python port of the Chrome/Chromium driver front-end Puppeteer.\nHere&apos;s a simple example to show how you can use Pyppeteer to access data that was injected into the page dynamically:\nimport asyncio\nfrom pyppeteer import launch\n\nasync def main():\n    browser = await launch({&quot;headless&quot;: True})\n    [page] = await browser.pages()\n\n    # normally, you go to a live site...\n    #await page.goto(&quot;http://www.example.com&quot;)\n    # but for this example, just set the HTML directly:\n    await page.setContent(&quot;&quot;&quot;\n    &lt;body&gt;\n    &lt;script&gt;\n    // inject content dynamically with JS, not part of the static HTML!\n    document.body.innerHTML = `&lt;p&gt;hello world&lt;/p&gt;`; \n    &lt;/script&gt;\n    &lt;/body&gt;\n    &quot;&quot;&quot;)\n    print(await page.content()) # shows that the `&lt;p&gt;` was inserted\n\n    # evaluate a JS expression in browser context and scrape the data\n    expr = &quot;document.querySelector(&apos;p&apos;).textContent&quot;\n    print(await page.evaluate(expr, force_expr=True)) # =&gt; hello world\n\n    await browser.close()\n\nasyncio.get_event_loop().run_until_complete(main())\n\nSee Pyppeteer&apos;s reference docs.\n    ","url":"/questions/[slug]#solution13","@type":"Answer","upvoteCount":0},{"text":"Try accessing the API directly\nA common scenario you&apos;ll see in scraping is that the data is being requested asynchronously from an API endpoint by the webpage. A minimal example of this would be the following site:\n\n\n&lt;body&gt;\n&lt;script&gt;\nfetch(&quot;https://jsonplaceholder.typicode.com/posts/1&quot;)\n  .then(res =&gt; {\n    if (!res.ok) throw Error(res.status);\n    \n    return res.json();\n  })\n  .then(data =&gt; {\n    // inject data dynamically via JS after page load\n    document.body.innerText = data.title;\n  })\n  .catch(err =&gt; console.error(err))\n;\n&lt;/script&gt;\n&lt;/body&gt;\n Run code snippetHide resultsExpand snippet\n\n\nIn many cases, the API will be protected by CORS or an access token or prohibitively rate limited, but in other cases it&apos;s publicly-accessible and you can bypass the website entirely. For CORS issues, you might try cors-anywhere.\nThe general procedure is to use your browser&apos;s developer tools&apos; network tab to search the requests made by the page for keywords/substrings of the data you want to scrape. Often, you&apos;ll see an unprotected API request endpoint with a JSON payload that you can access directly with urllib or requests modules. That&apos;s the case with the above runnable snippet which you can use to practice. After clicking &quot;run snippet&quot;, here&apos;s how I found the endpoint in my network tab:\n\nThis example is contrived; the endpoint URL will likely be non-obvious from looking at the static markup because it could be dynamically assembled, minified and buried under dozens of other requests and endpoints. The network request will also show any relevant request payload details like access token you may need.\nAfter obtaining the endpoint URL and relevant details, build a request in Python using a standard HTTP library and request the data:\n&gt;&gt;&gt; import requests\n&gt;&gt;&gt; res = requests.get(&quot;https://jsonplaceholder.typicode.com/posts/1&quot;)\n&gt;&gt;&gt; data = res.json()\n&gt;&gt;&gt; data[&quot;title&quot;]\n&apos;sunt aut facere repellat provident occaecati excepturi optio reprehenderit&apos;\n\nWhen you can get away with it, this tends to be much easier, faster and more reliable than scraping the page with Selenium, Pyppeteer, Scrapy or whatever the popular scraping libraries are at the time you&apos;re reading this post.\nIf you&apos;re unlucky and the data hasn&apos;t arrived via an API request that returns the data in a nice format, it could be part of the original browser&apos;s payload in a &lt;script&gt; tag, either as a JSON string or (more likely) a JS object. For example:\n\n\n&lt;body&gt;\n&lt;script&gt;\n  var someHardcodedData = {\n    userId: 1,\n    id: 1,\n    title: &apos;sunt aut facere repellat provident occaecati excepturi optio reprehenderit&apos;, \n    body: &apos;quia et suscipit\\nsuscipit recusandae con sequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto&apos;\n  };\n  document.body.textContent = someHardcodedData.title;\n&lt;/script&gt;\n&lt;/body&gt;\n Run code snippetHide resultsExpand snippet\n\n\nThere&apos;s no one-size-fits-all way to obtain this data. The basic technique is to use BeautifulSoup to access the &lt;script&gt; tag text, then apply a regex or a parse to extract the object structure, JSON string, or whatever format the data might be in. Here&apos;s a proof-of-concept on the sample structure shown above:\nimport json\nimport re\nfrom bs4 import BeautifulSoup\n\n# pretend we&apos;ve already used requests to retrieve the data, \n# so we hardcode it for the purposes of this example\ntext = &quot;&quot;&quot;\n&lt;body&gt;\n&lt;script&gt;\n  var someHardcodedData = {\n    userId: 1,\n    id: 1,\n    title: &apos;sunt aut facere repellat provident occaecati excepturi optio reprehenderit&apos;, \n    body: &apos;quia et suscipit\\nsuscipit recusandae con sequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto&apos;\n  };\n  document.body.textContent = someHardcodedData.title;\n&lt;/script&gt;\n&lt;/body&gt;\n&quot;&quot;&quot;\nsoup = BeautifulSoup(text, &quot;lxml&quot;)\nscript_text = str(soup.select_one(&quot;script&quot;))\npattern = r&quot;title: &apos;(.*?)&apos;&quot;\nprint(re.search(pattern, script_text, re.S).group(1))\n\nCheck out these resources for parsing JS objects that aren&apos;t quite valid JSON:\n\nHow to convert raw javascript object to python dictionary?\nHow to Fix JSON Key Values without double-quotes?\n\nHere are some additional case studies/proofs-of-concept where scraping was bypassed using an API:\n\nHow can I scrape yelp reviews and star ratings into CSV using Python beautifulsoup\nBeautiful Soup returns None on existing element\nExtract data from  BeautifulSoup Python\nScraping Bandcamp fan collections via POST (uses a hybrid approach where an initial request was made to the website to extract a token from the markup using BeautifulSoup which was then used in a second request to a JSON endpoint)\n\nIf all else fails, try one of the many dynamic scraping libraries listed in this thread.\n    ","url":"/questions/[slug]#solution14","@type":"Answer","upvoteCount":0},{"text":"As mentioned, Selenium is a good choice for rendering the results of the JavaScript:\nfrom selenium.webdriver import Firefox\nfrom selenium.webdriver.firefox.options import Options\n\noptions = Options()\noptions.headless = True\nbrowser = Firefox(executable_path=&quot;/usr/local/bin/geckodriver&quot;, options=options)\n\nurl = &quot;https://www.example.com&quot;\nbrowser.get(url)\n\nAnd gazpacho is a really easy library to parse over the rendered html:\nfrom gazpacho import Soup\n\nsoup = Soup(browser.page_source)\nsoup.find(&quot;a&quot;).attrs[&apos;href&apos;]\n\n    ","url":"/questions/[slug]#solution15","@type":"Answer","upvoteCount":0},{"text":"I recently used requests_html library to solve this problem.\nTheir expanded documentation at readthedocs.io is pretty good (skip the annotated version at pypi.org). If your use case is basic, you are likely to have some success.\nfrom requests_html import HTMLSession\nsession = HTMLSession()\nresponse = session.request(method=&quot;get&quot;,url=&quot;www.google.com/&quot;)\nresponse.html.render()\n\nIf you are having trouble rendering the data you need with response.html.render(), you can pass some javascript to the render function to render the particular js object you need. This is copied from their docs, but it might be just what you need:\n\nIf script is specified, it will execute the provided JavaScript at\nruntime. Example:\n\nscript = &quot;&quot;&quot;\n    () =&gt; {\n        return {\n            width: document.documentElement.clientWidth,\n            height: document.documentElement.clientHeight,\n            deviceScaleFactor: window.devicePixelRatio,\n        }\n    } \n&quot;&quot;&quot;\n\n\nReturns the return value of the executed script, if any is provided:\n\n&gt;&gt;&gt; response.html.render(script=script)\n{&apos;width&apos;: 800, &apos;height&apos;: 600, &apos;deviceScaleFactor&apos;: 1}\n\nIn my case, the data I wanted were the arrays that populated a javascript plot but the data wasn&apos;t getting rendered as text anywhere in the html. Sometimes its not clear at all what the object names are of the data you want if the data is populated dynamically. If you can&apos;t track down the js objects directly from view source or inspect, you can type in &quot;window&quot; followed by ENTER in the debugger console in the browser (Chrome) to pull up a full list of objects rendered by the browser. If you make a few educated guesses about where the data is stored, you might have some luck finding it there. My graph data was under window.view.data in the console, so in the &quot;script&quot; variable passed to the .render() method quoted above, I used:\nreturn {\n    data: window.view.data\n}\n\n    ","url":"/questions/[slug]#solution16","@type":"Answer","upvoteCount":0},{"text":"Playwright-Python\nYet another option is playwright-python, a port of Microsoft&apos;s Playwright (itself a Puppeteer-influenced browser automation library) to Python.\nHere&apos;s the minimal example of selecting an element and grabbing its text:\nfrom playwright.sync_api import sync_playwright\n\nwith sync_playwright() as p:\n    browser = p.chromium.launch()\n    page = browser.new_page()\n    page.goto(&quot;http://whatsmyuseragent.org/&quot;)\n    ua = page.query_selector(&quot;.user-agent&quot;);\n    print(ua.text_content())\n    browser.close()\n\n    ","url":"/questions/[slug]#solution17","@type":"Answer","upvoteCount":0},{"text":"Easy and Quick Solution:\nI was dealing with same problem. I want to scrape some data which is build with JavaScript. If I scrape only text from this site with BeautifulSoup then I ended with  tags in text.\nI want to render this  tag and wills to grab information from this.\nAlso, I dont want to use heavy frameworks  like Scrapy and selenium.\nSo, I found that get method of requests module takes urls, and it actually renders the script tag.\nExample:\nimport requests\ncustom_User_agent = &quot;Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0&quot;\nurl = &quot;https://www.abc.xyz/your/url&quot;\nresponse = requests.get(url, headers={&quot;User-Agent&quot;: custom_User_agent})\nhtml_text = response.text\n\nThis will renders load site and renders  tags.\nHope this will help as quick and easy solution to render site which is loaded with script tags.\n    ","url":"/questions/[slug]#solution18","@type":"Answer","upvoteCount":0}],"@type":"Question"}}</script><meta name="next-head-count" content="16"/><link rel="preload" href="/_next/static/css/08bcc42a26fe5c92.css" as="style"/><link rel="stylesheet" href="/_next/static/css/08bcc42a26fe5c92.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-0d1b80a048d4787e.js"></script><script src="/_next/static/chunks/webpack-42cdea76c8170223.js" defer=""></script><script src="/_next/static/chunks/framework-4556c45dd113b893.js" defer=""></script><script src="/_next/static/chunks/main-ccfab947c79712f4.js" defer=""></script><script src="/_next/static/chunks/pages/_app-08d1a634dea6705e.js" defer=""></script><script src="/_next/static/chunks/29107295-fbcfe2172188e46f.js" defer=""></script><script src="/_next/static/chunks/150-b06815e21c943e0d.js" defer=""></script><script src="/_next/static/chunks/490-7f0418bb4354ac73.js" defer=""></script><script src="/_next/static/chunks/108-87de33c23337ff53.js" defer=""></script><script src="/_next/static/chunks/pages/questions/%5Bslug%5D-79a1437acf654019.js" defer=""></script><script src="/_next/static/Zo3C7AOWQzKM9qqyzx2hf/_buildManifest.js" defer=""></script><script src="/_next/static/Zo3C7AOWQzKM9qqyzx2hf/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="wrapper"><header><nav class="bg-white border-gray-200 px-4 lg:px-6 py-2.5 dark:bg-gray-800"><div class="flex flex-wrap justify-between items-center mx-auto max-w-screen-xl"><a class="flex items-center" href="/"><img src="/logo-second.png" class="mr-3 h-6 sm:h-9" alt="Solution Checker Logo"/><h4 class="self-center text-xl font-semibold whitespace-nowrap dark:text-white">Solution Checker</h4></a><div class="flex items-center lg:order-2"><button data-collapse-toggle="mobile-menu-2" type="button" class="inline-flex items-center p-2 ml-1 text-sm text-gray-500 rounded-lg lg:hidden hover:bg-gray-100 focus:outline-none focus:ring-2 focus:ring-gray-200 dark:text-gray-400 dark:hover:bg-gray-700 dark:focus:ring-gray-600" aria-controls="mobile-menu-2" aria-expanded="false"><span class="sr-only">Open main menu</span><svg class="w-6 h-6" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M3 5a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 10a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 15a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1z" clip-rule="evenodd"></path></svg><svg class="hidden w-6 h-6" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M4.293 4.293a1 1 0 011.414 0L10 8.586l4.293-4.293a1 1 0 111.414 1.414L11.414 10l4.293 4.293a1 1 0 01-1.414 1.414L10 11.414l-4.293 4.293a1 1 0 01-1.414-1.414L8.586 10 4.293 5.707a1 1 0 010-1.414z" clip-rule="evenodd"></path></svg></button></div><div class="hidden justify-between items-center w-full lg:flex lg:w-auto lg:order-1" id="mobile-menu-2"><ul class="flex flex-col mt-4 font-medium lg:flex-row lg:space-x-8 lg:mt-0"><li><a class="block py-2 pr-4 pl-3 text-gray-700 border-b border-gray-100 hover:bg-gray-50 lg:hover:bg-transparent lg:border-0 lg:hover:text-blue-700 lg:p-0 dark:text-gray-400 lg:dark:hover:text-white dark:hover:bg-gray-700 dark:hover:text-white lg:dark:hover:bg-transparent dark:border-gray-700" aria-current="page" href="/">Home</a></li><li><a class="block py-2 pr-4 pl-3 text-gray-700 border-b border-gray-100 hover:bg-gray-50 lg:hover:bg-transparent lg:border-0 lg:hover:text-blue-700 lg:p-0 dark:text-gray-400 lg:dark:hover:text-white dark:hover:bg-gray-700 dark:hover:text-white lg:dark:hover:bg-transparent dark:border-gray-700" href="/questions?tab=news">Questions</a></li><li><a class="block py-2 pr-4 pl-3 text-gray-700 border-b border-gray-100 hover:bg-gray-50 lg:hover:bg-transparent lg:border-0 lg:hover:text-blue-700 lg:p-0 dark:text-gray-400 lg:dark:hover:text-white dark:hover:bg-gray-700 dark:hover:text-white lg:dark:hover:bg-transparent dark:border-gray-700" href="/post?tab=news">Post</a></li><li><a class="block py-2 pr-4 pl-3 text-gray-700 border-b border-gray-100 hover:bg-gray-50 lg:hover:bg-transparent lg:border-0 lg:hover:text-blue-700 lg:p-0 dark:text-gray-400 lg:dark:hover:text-white dark:hover:bg-gray-700 dark:hover:text-white lg:dark:hover:bg-transparent dark:border-gray-700" href="/questions/web-scraping-javascript-page-with-python-1657388240875#">Coding</a></li></ul></div></div></nav></header><div class="main-content"><div class="question my-5"><div class="flex question-header items-center m-auto justify-center"><div class="rounded-xl w-full border p-5 shadow-md bg-white"><div class="flex w-full items-center justify-between border-b pb-3"><div class="flex items-center space-x-3"><div class="text-lg font-bold text-slate-700"><a href="/questions/web-scraping-javascript-page-with-python-1657388240875"><h1>Web-scraping JavaScript page with Python</h1></a></div></div><div class="flex flex-wrap h-auto justify-end items-center space-x-8"><a class="rounded-2xl border bg-neutral-100 px-3 py-1 text-sm font-semibold" href="/questions/tag/python-2.x">python-2.x</a></div></div><div class="question-content mt-5">
                
<p>I'm trying to develop a simple web scraper. I want to extract text without the HTML code. It works on plain HTML, but not in some pages where JavaScript code adds text.</p>
<p>For example, if some JavaScript code adds some text, I can't see it, because when I call:</p>
<pre class="default s-code-block"><code class="hljs language-ini"><span class="hljs-attr">response</span> = urllib2.urlopen(request)
</code></pre>
<p>I get the original text without the added one (because JavaScript is executed in the client).</p>
<p>So, I'm looking for some ideas to solve this problem.</p>
    </div></div></div><div class="solution-section"><nav class="flex pagination-solution flex-col justify-end"><ul class="inline-flex -space-x-px overflow-auto"><li class="pagination-solution-item"><span data-id="#solution1" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">1</span></li><li class="pagination-solution-item"><span data-id="#solution2" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">2</span></li><li class="pagination-solution-item"><span data-id="#solution3" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">3</span></li><li class="pagination-solution-item"><span data-id="#solution4" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">4</span></li><li class="pagination-solution-item"><span data-id="#solution5" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">5</span></li><li class="pagination-solution-item"><span data-id="#solution6" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">6</span></li><li class="pagination-solution-item"><span data-id="#solution7" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">7</span></li><li class="pagination-solution-item"><span data-id="#solution8" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">8</span></li><li class="pagination-solution-item"><span data-id="#solution9" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">9</span></li><li class="pagination-solution-item"><span data-id="#solution10" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">10</span></li><li class="pagination-solution-item"><span data-id="#solution11" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">11</span></li><li class="pagination-solution-item"><span data-id="#solution12" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">12</span></li><li class="pagination-solution-item"><span data-id="#solution13" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">13</span></li><li class="pagination-solution-item"><span data-id="#solution14" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">14</span></li><li class="pagination-solution-item"><span data-id="#solution15" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">15</span></li><li class="pagination-solution-item"><span data-id="#solution16" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">16</span></li><li class="pagination-solution-item"><span data-id="#solution17" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">17</span></li><li class="pagination-solution-item"><span data-id="#solution18" class="cursor-pointer py-2 px-3 leading-tight text-gray-500 bg-white border border-gray-300 hover:bg-gray-100 hover:text-gray-700 dark:bg-gray-800 dark:border-gray-700 dark:text-gray-400 dark:hover:bg-gray-700 dark:hover:text-white">18</span></li></ul></nav><div id="solution1" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h4 class="text-4xl font-semibold mb-5">Solution 1</h4><div class="tags-wrap h-max space-x-8"><div class="tags"><a class="rounded-2xl border bg-neutral-100 px-3 py-1 text-sm font-semibold whitespace-nowrap" href="/questions/tag/python-2.x">python-2.x</a></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>EDIT Sept 2021: <code>phantomjs</code> isn't maintained any more, either</p>
<p>EDIT 30/Dec/2017: This answer appears in top results of Google searches, so I decided to update it. The old answer is still at the end.</p>
<p>dryscape isn't maintained anymore and the library dryscape developers recommend is Python 2 only. I have found using Selenium's python library with Phantom JS as a web driver fast enough and easy to get the work done.</p>
<p>Once you have installed <a href="http://phantomjs.org/download.html" rel="noreferrer">Phantom JS</a>, make sure the <code>phantomjs</code> binary is available in the current path:</p>
<pre class="default s-code-block"><code class="hljs language-sql">phantomjs <span class="hljs-comment">--version</span>
# <span class="hljs-keyword">result</span>:
<span class="hljs-number">2.1</span><span class="hljs-number">.1</span>
</code></pre>
<p>#Example
To give an example, I created a sample page with following HTML code. (<a href="http://avi.im/stuff/js-or-no-js.html" rel="noreferrer">link</a>):</p>
<pre class="default s-code-block"><code class="hljs language-xml"><span class="hljs-meta">&lt;!DOCTYPE <span class="hljs-keyword">html</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-name">html</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-name">head</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">meta</span> <span class="hljs-attr">charset</span>=<span class="hljs-string">"utf-8"</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">title</span>&gt;</span>Javascript scraping test<span class="hljs-tag">&lt;/<span class="hljs-name">title</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">head</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-name">body</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">p</span> <span class="hljs-attr">id</span>=<span class="hljs-string">'intro-text'</span>&gt;</span>No javascript support<span class="hljs-tag">&lt;/<span class="hljs-name">p</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><span class="language-javascript">
     <span class="hljs-variable language_">document</span>.<span class="hljs-title function_">getElementById</span>(<span class="hljs-string">'intro-text'</span>).<span class="hljs-property">innerHTML</span> = <span class="hljs-string">'Yay! Supports javascript'</span>;
  </span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span> 
<span class="hljs-tag">&lt;/<span class="hljs-name">body</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">html</span>&gt;</span>
</code></pre>
<p>without javascript it says: <code>No javascript support</code> and with javascript: <code>Yay! Supports javascript</code></p>
<p>#Scraping without JS support:</p>
<pre class="default s-code-block"><code class="hljs language-haskell"><span class="hljs-keyword">import</span> requests
<span class="hljs-title">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup
<span class="hljs-title">response</span> = requests.get(my_url)
<span class="hljs-title">soup</span> = <span class="hljs-type">BeautifulSoup</span>(response.text)
<span class="hljs-title">soup</span>.find(id=<span class="hljs-string">"intro-text"</span>)
<span class="hljs-meta"># Result:</span>
&lt;p id=<span class="hljs-string">"intro-text"</span>&gt;<span class="hljs-type">No</span> javascript support&lt;/p&gt;
</code></pre>
<p>#Scraping with JS support:</p>
<pre class="default s-code-block"><code class="hljs language-coffeescript"><span class="hljs-keyword">from</span> selenium <span class="hljs-keyword">import</span> webdriver
driver = webdriver.PhantomJS()
driver.get(my_url)
p_element = driver.find_element_by_id(id_=<span class="hljs-string">'intro-text'</span>)
<span class="hljs-built_in">print</span>(p_element.text)
<span class="hljs-comment"># result:</span>
<span class="hljs-string">'Yay! Supports javascript'</span>
</code></pre>
<hr>
<p>You can also use Python library <a href="https://github.com/niklasb/dryscrape" rel="noreferrer">dryscrape</a> to scrape javascript driven websites.</p>
<p>#Scraping with JS support:</p>
<pre class="default s-code-block"><code class="hljs language-haskell"><span class="hljs-keyword">import</span> dryscrape
<span class="hljs-title">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup
<span class="hljs-title">session</span> = dryscrape.<span class="hljs-type">Session</span>()
<span class="hljs-title">session</span>.visit(my_url)
<span class="hljs-title">response</span> = session.body()
<span class="hljs-title">soup</span> = <span class="hljs-type">BeautifulSoup</span>(response)
<span class="hljs-title">soup</span>.find(id=<span class="hljs-string">"intro-text"</span>)
<span class="hljs-meta"># Result:</span>
&lt;p id=<span class="hljs-string">"intro-text"</span>&gt;<span class="hljs-type">Yay</span>! <span class="hljs-type">Supports</span> javascript&lt;/p&gt;
</code></pre>
    </div></div></div></div><div id="solution2" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h4 class="text-4xl font-semibold mb-5">Solution 2</h4><div class="tags-wrap h-max space-x-8"><div class="tags"><a class="rounded-2xl border bg-neutral-100 px-3 py-1 text-sm font-semibold whitespace-nowrap" href="/questions/tag/python-2.x">python-2.x</a></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>We are not getting the correct results because any javascript generated content needs to be rendered on the DOM. When we fetch an HTML page, we fetch the initial, unmodified by javascript, DOM.</p>

<p>Therefore we need to render the javascript content before we crawl the page.</p>

<p>As selenium is already mentioned many times in this thread (and how slow it gets sometimes was mentioned also), I will list two other possible solutions.</p>

<hr>

<p><strong>Solution 1:</strong> This is a very nice tutorial on <a href="http://www.scrapingauthority.com/scrapy-javascript" rel="noreferrer">how to use Scrapy to crawl javascript generated content</a> and we are going to follow just that.</p>

<p><strong>What we will need:</strong></p>

<ol>
<li><p><a href="https://www.docker.com/" rel="noreferrer">Docker</a> installed in our machine. This is a plus over other solutions until this point, as it utilizes an OS-independent platform.</p></li>
<li><p><a href="http://splash.readthedocs.io/en/latest/install.html" rel="noreferrer">Install Splash</a> following the instruction listed for our corresponding OS.<br>Quoting from splash documentation:</p>

<blockquote>
  <p>Splash is a javascript rendering service. Its a lightweight web browser with an HTTP API, implemented in Python 3 using Twisted and QT5. </p>
</blockquote>

<p>Essentially we are going to use Splash to render Javascript generated content.</p></li>
<li><p>Run the splash server: <code>sudo docker run -p 8050:8050 scrapinghub/splash</code>.</p></li>
<li><p>Install the <a href="https://github.com/scrapy-plugins/scrapy-splash#installation" rel="noreferrer">scrapy-splash</a> plugin: <code>pip install scrapy-splash</code></p></li>
<li><p>Assuming that we already have a Scrapy project created (if not, <a href="https://docs.scrapy.org/en/latest/intro/tutorial.html#creating-a-project" rel="noreferrer">let's make one</a>), we will follow the guide and update the <code>settings.py</code>:</p>

<blockquote>
  <p>Then go to your scrapy projects <code>settings.py</code> and set these middlewares:</p>

<pre class="default s-code-block"><code class="hljs language-bash">DOWNLOADER_MIDDLEWARES = {
      <span class="hljs-string">'scrapy_splash.SplashCookiesMiddleware'</span>: 723,
      <span class="hljs-string">'scrapy_splash.SplashMiddleware'</span>: 725,
      <span class="hljs-string">'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware'</span>: 810,
}
</code></pre>
  
  <p>The URL of the Splash server(if youre using Win or OSX this should be the URL of the docker machine: <a href="https://stackoverflow.com/questions/17157721/how-to-get-a-docker-containers-ip-address-from-the-host">How to get a Docker container's IP address from the host?</a>):</p>

<pre class="default s-code-block"><code class="hljs language-ini"><span class="hljs-attr">SPLASH_URL</span> = <span class="hljs-string">'http://localhost:8050'</span>
</code></pre>
  
  <p>And finally you need to set these values too:</p>

<pre class="default s-code-block"><code class="hljs language-ini"><span class="hljs-attr">DUPEFILTER_CLASS</span> = <span class="hljs-string">'scrapy_splash.SplashAwareDupeFilter'</span>
<span class="hljs-attr">HTTPCACHE_STORAGE</span> = <span class="hljs-string">'scrapy_splash.SplashAwareFSCacheStorage'</span>
</code></pre>
</blockquote></li>
<li><p>Finally, we can use a <a href="https://github.com/scrapy-plugins/scrapy-splash#usage" rel="noreferrer"><code>SplashRequest</code></a>:</p>

<blockquote>
  <p>In a normal spider you have Request objects which you can use to open URLs. If the page you want to open contains JS generated data you have to use SplashRequest(or SplashFormRequest) to render the page. Heres a simple example:</p>

<pre class="default s-code-block"><code class="hljs language-ruby"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MySpider</span>(scrapy.Spider):
    name = <span class="hljs-string">"jsscraper"</span>
    start_urls = [<span class="hljs-string">"http://quotes.toscrape.com/js/"</span>]

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">start_requests</span>(<span class="hljs-params"><span class="hljs-variable language_">self</span></span>):
        <span class="hljs-keyword">for</span> url <span class="hljs-keyword">in</span> <span class="hljs-variable language_">self</span>.<span class="hljs-symbol">start_urls:</span>
        <span class="hljs-keyword">yield</span> SplashRequest(
            url=url, callback=<span class="hljs-variable language_">self</span>.parse, endpoint=<span class="hljs-string">'render.html'</span>
        )

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">parse</span>(<span class="hljs-params"><span class="hljs-variable language_">self</span>, response</span>):
        <span class="hljs-keyword">for</span> q <span class="hljs-keyword">in</span> response.css(<span class="hljs-string">"div.quote"</span>):
        quote = QuoteItem()
        quote[<span class="hljs-string">"author"</span>] = q.css(<span class="hljs-string">".author::text"</span>).extract_first()
        quote[<span class="hljs-string">"quote"</span>] = q.css(<span class="hljs-string">".text::text"</span>).extract_first()
        <span class="hljs-keyword">yield</span> quote
</code></pre>
  
  <p>SplashRequest renders the URL as html and returns the response which you can use in the callback(parse) method.</p>
</blockquote></li>
</ol>

<hr>

<p><strong>Solution 2:</strong> Let's call this experimental at the moment (May 2018)...<br>
<strong>This solution is for Python's version 3.6</strong> only (at the moment).</p>

<p>Do you know the <a href="http://docs.python-requests.org/en/master/" rel="noreferrer">requests</a> module (well who doesn't)?<br>
Now it has a web crawling little sibling: <a href="https://github.com/psf/requests-html" rel="noreferrer">requests-HTML</a>:</p>

<blockquote>
  <p>This library intends to make parsing HTML (e.g. scraping the web) as simple and intuitive as possible.</p>
</blockquote>

<ol>
<li><p>Install requests-html: <code>pipenv install requests-html</code></p></li>
<li><p>Make a request to the page's url:</p>

<pre class="default s-code-block"><code class="hljs language-csharp"><span class="hljs-keyword">from</span> requests_html import HTMLSession

session = HTMLSession()
r = session.<span class="hljs-keyword">get</span>(a_page_url)
</code></pre></li>
<li><p>Render the response to get the Javascript generated bits:</p>

<pre class="default s-code-block"><code class="hljs language-scss">r<span class="hljs-selector-class">.html</span><span class="hljs-selector-class">.render</span>()
</code></pre></li>
</ol>

<p>Finally, the module seems to offer <a href="https://html.python-requests.org/#api-documentation" rel="noreferrer">scraping capabilities</a>.<br>
Alternatively, we can try the well-documented way <a href="https://www.dataquest.io/blog/web-scraping-beautifulsoup/" rel="noreferrer">of using BeautifulSoup</a> with the <code>r.html</code> object we just rendered.</p>
    </div></div></div></div><div id="solution3" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h4 class="text-4xl font-semibold mb-5">Solution 3</h4><div class="tags-wrap h-max space-x-8"><div class="tags"><a class="rounded-2xl border bg-neutral-100 px-3 py-1 text-sm font-semibold whitespace-nowrap" href="/questions/tag/python-2.x">python-2.x</a></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>Maybe <a href="http://www.seleniumhq.org/">selenium</a> can do it.</p>

<pre class="default s-code-block"><code class="hljs language-haskell"><span class="hljs-title">from</span> selenium <span class="hljs-keyword">import</span> webdriver
<span class="hljs-keyword">import</span> time

<span class="hljs-title">driver</span> = webdriver.<span class="hljs-type">Firefox</span>()
<span class="hljs-title">driver</span>.get(url)
<span class="hljs-title">time</span>.sleep(<span class="hljs-number">5</span>)
<span class="hljs-title">htmlSource</span> = driver.page_source
</code></pre>
    </div></div></div></div><div id="solution4" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h4 class="text-4xl font-semibold mb-5">Solution 4</h4><div class="tags-wrap h-max space-x-8"><div class="tags"><a class="rounded-2xl border bg-neutral-100 px-3 py-1 text-sm font-semibold whitespace-nowrap" href="/questions/tag/python-2.x">python-2.x</a></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>If you have ever used the <code>Requests</code> module for python before, I recently found out that the developer created a new module called <code>Requests-HTML</code> which now also has the ability to render JavaScript.</p>

<p>You can also visit <a href="https://html.python-requests.org/" rel="noreferrer">https://html.python-requests.org/</a> to learn more about this module, or if your only interested about rendering JavaScript then you can visit <a href="https://html.python-requests.org/?#javascript-support" rel="noreferrer">https://html.python-requests.org/?#javascript-support</a> to directly learn how to use the module to render JavaScript using Python.</p>

<p>Essentially, Once you correctly install the <code>Requests-HTML</code> module, the following example, which is <a href="https://html.python-requests.org/?#javascript-support" rel="noreferrer">shown on the above link</a>, shows how you can use this module to scrape a website and render JavaScript contained within the website:</p>

<pre class="default s-code-block"><code class="hljs language-csharp"><span class="hljs-keyword">from</span> requests_html import HTMLSession
session = HTMLSession()

r = session.<span class="hljs-keyword">get</span>(<span class="hljs-string">'http://python-requests.org/'</span>)

r.html.render()

r.html.search(<span class="hljs-string">'Python 2 will retire in only {months} months!'</span>)[<span class="hljs-string">'months'</span>]

<span class="hljs-string">'&lt;time&gt;25&lt;/time&gt;'</span> <span class="hljs-meta">#This is the result.</span>
</code></pre>

<p>I recently learnt about this from a YouTube video. <a href="https://www.youtube.com/watch?v=gKT_tg87H5Y" rel="noreferrer">Click Here!</a> to watch the YouTube video, which demonstrates how the module works.</p>
    </div></div></div></div><div id="solution5" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h4 class="text-4xl font-semibold mb-5">Solution 5</h4><div class="tags-wrap h-max space-x-8"><div class="tags"><a class="rounded-2xl border bg-neutral-100 px-3 py-1 text-sm font-semibold whitespace-nowrap" href="/questions/tag/python-2.x">python-2.x</a></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>It sounds like the data you're really looking for can be accessed via secondary URL called by some javascript on the primary page.</p>

<p>While you could try running javascript on the server to handle this, a simpler approach  to might be to load up the page using Firefox and use a tool like <a href="http://www.google.co.uk/url?sa=t&amp;rct=j&amp;q=charles&amp;source=web&amp;cd=1&amp;ved=0CC4QFjAA&amp;url=http://www.charlesproxy.com/&amp;ei=FBC5TpyZC9Ha4QSD7umcCA&amp;usg=AFQjCNG_O70VsRrfb_q7F66Nkb9ZK6MNMA" rel="noreferrer">Charles</a> or <a href="http://www.google.co.uk/url?sa=t&amp;rct=j&amp;q=firebug&amp;source=web&amp;cd=1&amp;ved=0CDEQFjAA&amp;url=http://getfirebug.com/&amp;ei=TBC5TuOPIbKQ4gTk7J3vBw&amp;usg=AFQjCNGT1rhhsYGPQx5Vr5A8RvhIgdSp9g" rel="noreferrer">Firebug</a> to identify exactly what that secondary URL is. Then you can just query that URL directly for the data you are interested in.</p>
    </div></div></div></div><div id="solution6" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h4 class="text-4xl font-semibold mb-5">Solution 6</h4><div class="tags-wrap h-max space-x-8"><div class="tags"><a class="rounded-2xl border bg-neutral-100 px-3 py-1 text-sm font-semibold whitespace-nowrap" href="/questions/tag/python-2.x">python-2.x</a></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>This seems to be a good solution also, taken from a <a href="https://impythonist.wordpress.com/2015/01/06/ultimate-guide-for-scraping-javascript-rendered-web-pages/" rel="noreferrer">great blog post</a></p>

<pre class="default s-code-block"><code class="hljs language-python"><span class="hljs-keyword">import</span> sys  
<span class="hljs-keyword">from</span> PyQt4.QtGui <span class="hljs-keyword">import</span> *  
<span class="hljs-keyword">from</span> PyQt4.QtCore <span class="hljs-keyword">import</span> *  
<span class="hljs-keyword">from</span> PyQt4.QtWebKit <span class="hljs-keyword">import</span> *  
<span class="hljs-keyword">from</span> lxml <span class="hljs-keyword">import</span> html 

<span class="hljs-comment">#Take this class for granted.Just use result of rendering.</span>
<span class="hljs-keyword">class</span> <span class="hljs-title class_">Render</span>(<span class="hljs-title class_ inherited__">QWebPage</span>):  
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, url</span>):  
    self.app = QApplication(sys.argv)  
    QWebPage.__init__(self)  
    self.loadFinished.connect(self._loadFinished)  
    self.mainFrame().load(QUrl(url))  
    self.app.exec_()  

  <span class="hljs-keyword">def</span> <span class="hljs-title function_">_loadFinished</span>(<span class="hljs-params">self, result</span>):  
    self.frame = self.mainFrame()  
    self.app.quit()  

url = <span class="hljs-string">'http://pycoders.com/archive/'</span>  
r = Render(url)  
result = r.frame.toHtml()
<span class="hljs-comment"># This step is important.Converting QString to Ascii for lxml to process</span>

<span class="hljs-comment"># The following returns an lxml element tree</span>
archive_links = html.fromstring(<span class="hljs-built_in">str</span>(result.toAscii()))
<span class="hljs-built_in">print</span> archive_links

<span class="hljs-comment"># The following returns an array containing the URLs</span>
raw_links = archive_links.xpath(<span class="hljs-string">'//div[@class="campaign"]/a/@href'</span>)
<span class="hljs-built_in">print</span> raw_links
</code></pre>
    </div></div></div></div><div id="solution7" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h4 class="text-4xl font-semibold mb-5">Solution 7</h4><div class="tags-wrap h-max space-x-8"><div class="tags"><a class="rounded-2xl border bg-neutral-100 px-3 py-1 text-sm font-semibold whitespace-nowrap" href="/questions/tag/python-2.x">python-2.x</a></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>Selenium is the best for scraping JS and Ajax content.</p>

<p>Check this article for <a href="https://likegeeks.com/python-web-scraping/" rel="noreferrer">extracting data from the web using Python</a></p>

<pre class="default s-code-block"><code class="hljs language-ruby"><span class="hljs-variable">$ </span>pip install selenium
</code></pre>

<p>Then download Chrome webdriver.</p>

<pre class="default s-code-block"><code class="hljs language-coffeescript"><span class="hljs-keyword">from</span> selenium <span class="hljs-keyword">import</span> webdriver

browser = webdriver.Chrome()

browser.get(<span class="hljs-string">"https://www.python.org/"</span>)

nav = browser.find_element_by_id(<span class="hljs-string">"mainnav"</span>)

<span class="hljs-built_in">print</span>(nav.text)
</code></pre>

<p>Easy, right?</p>
    </div></div></div></div><div id="solution8" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h4 class="text-4xl font-semibold mb-5">Solution 8</h4><div class="tags-wrap h-max space-x-8"><div class="tags"><a class="rounded-2xl border bg-neutral-100 px-3 py-1 text-sm font-semibold whitespace-nowrap" href="/questions/tag/python-2.x">python-2.x</a></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>You can also execute javascript using webdriver.</p>
<pre class="default s-code-block"><code class="hljs language-csharp"><span class="hljs-keyword">from</span> selenium import webdriver

driver = webdriver.Firefox()
driver.<span class="hljs-keyword">get</span>(url)
driver.execute_script(<span class="hljs-string">'document.title'</span>)
</code></pre>
<p>or store the value in a variable</p>
<pre class="default s-code-block"><code class="hljs language-vhdl">result = driver.execute_script(<span class="hljs-symbol">'var</span> <span class="hljs-literal">text</span> = document.title ; <span class="hljs-keyword">return</span> <span class="hljs-literal">text</span>')
</code></pre>
    </div></div></div></div><div id="solution9" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h4 class="text-4xl font-semibold mb-5">Solution 9</h4><div class="tags-wrap h-max space-x-8"><div class="tags"><a class="rounded-2xl border bg-neutral-100 px-3 py-1 text-sm font-semibold whitespace-nowrap" href="/questions/tag/python-2.x">python-2.x</a></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>I personally prefer using scrapy and selenium and dockerizing both in separate containers. This way you can install both with minimal hassle and crawl modern websites that almost all contain javascript in one form or another. Here's an example:</p>

<p>Use the <code>scrapy startproject</code> to create your scraper and write your spider, the skeleton can be as simple as this:</p>

<pre class="default s-code-block"><code class="hljs language-ruby">import scrapy


<span class="hljs-keyword">class</span> <span class="hljs-title class_">MySpider</span>(scrapy.Spider):
    name = <span class="hljs-string">'my_spider'</span>
    start_urls = [<span class="hljs-string">'https://somewhere.com'</span>]

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">start_requests</span>(<span class="hljs-params"><span class="hljs-variable language_">self</span></span>):
        <span class="hljs-keyword">yield</span> scrapy.Request(url=<span class="hljs-variable language_">self</span>.start_urls[<span class="hljs-number">0</span>])


    <span class="hljs-keyword">def</span> <span class="hljs-title function_">parse</span>(<span class="hljs-params"><span class="hljs-variable language_">self</span>, response</span>):

        <span class="hljs-comment"># do stuff with results, scrape items etc.</span>
        <span class="hljs-comment"># now were just checking everything worked</span>

        print(response.body)
</code></pre>

<p>The real magic happens in the middlewares.py. Overwrite two methods in the downloader middleware,  <code>__init__</code> and  <code>process_request</code>, in the following way:</p>

<pre class="default s-code-block"><code class="hljs language-python"><span class="hljs-comment"># import some additional modules that we need</span>
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">from</span> copy <span class="hljs-keyword">import</span> deepcopy
<span class="hljs-keyword">from</span> time <span class="hljs-keyword">import</span> sleep

<span class="hljs-keyword">from</span> scrapy <span class="hljs-keyword">import</span> signals
<span class="hljs-keyword">from</span> scrapy.http <span class="hljs-keyword">import</span> HtmlResponse
<span class="hljs-keyword">from</span> selenium <span class="hljs-keyword">import</span> webdriver

<span class="hljs-keyword">class</span> <span class="hljs-title class_">SampleProjectDownloaderMiddleware</span>(<span class="hljs-title class_ inherited__">object</span>):

<span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):
    SELENIUM_LOCATION = os.environ.get(<span class="hljs-string">'SELENIUM_LOCATION'</span>, <span class="hljs-string">'NOT_HERE'</span>)
    SELENIUM_URL = <span class="hljs-string">f'http://<span class="hljs-subst">{SELENIUM_LOCATION}</span>:4444/wd/hub'</span>
    chrome_options = webdriver.ChromeOptions()

    <span class="hljs-comment"># chrome_options.add_experimental_option("mobileEmulation", mobile_emulation)</span>
    self.driver = webdriver.Remote(command_executor=SELENIUM_URL,
                                   desired_capabilities=chrome_options.to_capabilities())


<span class="hljs-keyword">def</span> <span class="hljs-title function_">process_request</span>(<span class="hljs-params">self, request, spider</span>):

    self.driver.get(request.url)

    <span class="hljs-comment"># sleep a bit so the page has time to load</span>
    <span class="hljs-comment"># or monitor items on page to continue as soon as page ready</span>
    sleep(<span class="hljs-number">4</span>)

    <span class="hljs-comment"># if you need to manipulate the page content like clicking and scrolling, you do it here</span>
    <span class="hljs-comment"># self.driver.find_element_by_css_selector('.my-class').click()</span>

    <span class="hljs-comment"># you only need the now properly and completely rendered html from your page to get results</span>
    body = deepcopy(self.driver.page_source)

    <span class="hljs-comment"># copy the current url in case of redirects</span>
    url = deepcopy(self.driver.current_url)

    <span class="hljs-keyword">return</span> HtmlResponse(url, body=body, encoding=<span class="hljs-string">'utf-8'</span>, request=request)
</code></pre>

<p>Dont forget to enable this middlware by uncommenting the next lines in the settings.py file:</p>

<pre class="default s-code-block"><code class="hljs language-makefile">DOWNLOADER_MIDDLEWARES = {
<span class="hljs-section">'sample_project.middlewares.SampleProjectDownloaderMiddleware': 543,}</span>
</code></pre>

<p>Next for dockerization. Create your <code>Dockerfile</code> from a lightweight image (I'm using python Alpine here), copy your project directory to it, install requirements:</p>

<pre class="default s-code-block"><code class="hljs language-bash"><span class="hljs-comment"># Use an official Python runtime as a parent image</span>
FROM python:3.6-alpine

<span class="hljs-comment"># install some packages necessary to scrapy and then curl because it's  handy for debugging</span>
RUN apk --update add linux-headers libffi-dev openssl-dev build-base libxslt-dev libxml2-dev curl python-dev

WORKDIR /my_scraper

ADD requirements.txt /my_scraper/

RUN pip install -r requirements.txt

ADD . /scrapers
</code></pre>

<p>And finally bring it all together in <code>docker-compose.yaml</code>:</p>

<pre class="default s-code-block"><code class="hljs language-yaml"><span class="hljs-attr">version:</span> <span class="hljs-string">'2'</span>
<span class="hljs-attr">services:</span>
  <span class="hljs-attr">selenium:</span>
    <span class="hljs-attr">image:</span> <span class="hljs-string">selenium/standalone-chrome</span>
    <span class="hljs-attr">ports:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">"4444:4444"</span>
    <span class="hljs-attr">shm_size:</span> <span class="hljs-string">1G</span>

  <span class="hljs-attr">my_scraper:</span>
    <span class="hljs-attr">build:</span> <span class="hljs-string">.</span>
    <span class="hljs-attr">depends_on:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">"selenium"</span>
    <span class="hljs-attr">environment:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">SELENIUM_LOCATION=samplecrawler_selenium_1</span>
    <span class="hljs-attr">volumes:</span>
      <span class="hljs-bullet">-</span> <span class="hljs-string">.:/my_scraper</span>
    <span class="hljs-comment"># use this command to keep the container running</span>
    <span class="hljs-attr">command:</span> <span class="hljs-string">tail</span> <span class="hljs-string">-f</span> <span class="hljs-string">/dev/null</span>
</code></pre>

<p>Run <code>docker-compose up -d</code>. If you're doing this the first time it will take a while for it to fetch the latest selenium/standalone-chrome and the build your scraper image as well. </p>

<p>Once it's done, you can check that your containers are running with <code>docker ps</code> and also check that the name of the selenium container matches that of the environment variable that we passed to our scraper container (here, it was <code>SELENIUM_LOCATION=samplecrawler_selenium_1</code>). </p>

<p>Enter your scraper container with <code>docker exec -ti YOUR_CONTAINER_NAME sh</code> , the command for me was <code>docker exec -ti samplecrawler_my_scraper_1 sh</code>, cd into the right directory and run your scraper with <code>scrapy crawl my_spider</code>.</p>

<p>The entire thing is on my github page and you can get it from <a href="https://github.com/tarikki/sample_crawler" rel="noreferrer">here</a></p>
    </div></div></div></div><div id="solution10" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h4 class="text-4xl font-semibold mb-5">Solution 10</h4><div class="tags-wrap h-max space-x-8"><div class="tags"><a class="rounded-2xl border bg-neutral-100 px-3 py-1 text-sm font-semibold whitespace-nowrap" href="/questions/tag/python-2.x">python-2.x</a></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>A mix of BeautifulSoup and Selenium works very well for me.</p>

<pre class="default s-code-block"><code class="hljs language-coffeescript"><span class="hljs-keyword">from</span> selenium <span class="hljs-keyword">import</span> webdriver
<span class="hljs-keyword">from</span> selenium.webdriver.common.<span class="hljs-keyword">by</span> <span class="hljs-keyword">import</span> By
<span class="hljs-keyword">from</span> selenium.webdriver.support.ui <span class="hljs-keyword">import</span> WebDriverWait
<span class="hljs-keyword">from</span> selenium.webdriver.support <span class="hljs-keyword">import</span> expected_conditions <span class="hljs-keyword">as</span> EC
<span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup <span class="hljs-keyword">as</span> bs

driver = webdriver.Firefox()
driver.get(<span class="hljs-string">"http://somedomain/url_that_delays_loading"</span>)
    try:
        element = WebDriverWait(driver, <span class="hljs-number">10</span>).<span class="hljs-keyword">until</span>(
        EC.presence_of_element_located((By.ID, <span class="hljs-string">"myDynamicElement"</span>))) <span class="hljs-comment">#waits 10 seconds until element is located. Can have other wait conditions  such as visibility_of_element_located or text_to_be_present_in_element</span>

        html = driver.page_source
        soup = bs(html, <span class="hljs-string">"lxml"</span>)
        dynamic_text = soup.find_all(<span class="hljs-string">"p"</span>, {<span class="hljs-string">"class"</span>:<span class="hljs-string">"class_name"</span>}) <span class="hljs-comment">#or other attributes, optional</span>
    else:
        <span class="hljs-built_in">print</span>(<span class="hljs-string">"Couldnt locate element"</span>)
</code></pre>

<p>P.S. You can find more wait conditions <a href="http://selenium-python.readthedocs.io/waits.html" rel="noreferrer">here</a></p>
    </div></div></div></div><div id="solution11" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h4 class="text-4xl font-semibold mb-5">Solution 11</h4><div class="tags-wrap h-max space-x-8"><div class="tags"><a class="rounded-2xl border bg-neutral-100 px-3 py-1 text-sm font-semibold whitespace-nowrap" href="/questions/tag/python-2.x">python-2.x</a></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p><strong>Using PyQt5</strong></p>

<pre class="default s-code-block"><code class="hljs language-python"><span class="hljs-keyword">from</span> PyQt5.QtWidgets <span class="hljs-keyword">import</span> QApplication
<span class="hljs-keyword">from</span> PyQt5.QtCore <span class="hljs-keyword">import</span> QUrl
<span class="hljs-keyword">from</span> PyQt5.QtWebEngineWidgets <span class="hljs-keyword">import</span> QWebEnginePage
<span class="hljs-keyword">import</span> sys
<span class="hljs-keyword">import</span> bs4 <span class="hljs-keyword">as</span> bs
<span class="hljs-keyword">import</span> urllib.request


<span class="hljs-keyword">class</span> <span class="hljs-title class_">Client</span>(<span class="hljs-title class_ inherited__">QWebEnginePage</span>):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self,url</span>):
        <span class="hljs-keyword">global</span> app
        self.app = QApplication(sys.argv)
        QWebEnginePage.__init__(self)
        self.html = <span class="hljs-string">""</span>
        self.loadFinished.connect(self.on_load_finished)
        self.load(QUrl(url))
        self.app.exec_()

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">on_load_finished</span>(<span class="hljs-params">self</span>):
        self.html = self.toHtml(self.<span class="hljs-type">Callable</span>)
        <span class="hljs-built_in">print</span>(<span class="hljs-string">"Load Finished"</span>)

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">Callable</span>(<span class="hljs-params">self,data</span>):
        self.html = data
        self.app.quit()

<span class="hljs-comment"># url = ""</span>
<span class="hljs-comment"># client_response = Client(url)</span>
<span class="hljs-comment"># print(client_response.html)</span>
</code></pre>
    </div></div></div></div><div id="solution12" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h4 class="text-4xl font-semibold mb-5">Solution 12</h4><div class="tags-wrap h-max space-x-8"><div class="tags"><a class="rounded-2xl border bg-neutral-100 px-3 py-1 text-sm font-semibold whitespace-nowrap" href="/questions/tag/python-2.x">python-2.x</a></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>You'll want to use urllib, requests, beautifulSoup and selenium web driver in your script for different parts of the page, (to name a few).<br>
Sometimes you'll get what you need with just one of these modules.<br>
Sometimes you'll need two, three, or all of these modules.<br>
Sometimes you'll need to switch off the js on your browser.<br>
Sometimes you'll need header info in your script.<br>
No websites can be scraped the same way and no website can be scraped in the same way forever without having to modify your crawler, usually after a few months. But they can all be scraped! Where there's a will there's a way for sure.<br>
If you need scraped data continuously into the future just scrape everything you need and store it in .dat files with pickle.<br>
Just keep searching how to try what with these modules and copying and pasting your errors into the Google.</p>
    </div></div></div></div><div id="solution13" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h4 class="text-4xl font-semibold mb-5">Solution 13</h4><div class="tags-wrap h-max space-x-8"><div class="tags"><a class="rounded-2xl border bg-neutral-100 px-3 py-1 text-sm font-semibold whitespace-nowrap" href="/questions/tag/python-2.x">python-2.x</a></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<h2>Pyppeteer</h2>
<p>You might consider <a href="https://github.com/pyppeteer/pyppeteer" rel="nofollow noreferrer">Pyppeteer</a>, a Python port of the Chrome/Chromium driver front-end <a href="https://github.com/puppeteer/puppeteer/" rel="nofollow noreferrer">Puppeteer</a>.</p>
<p>Here's a simple example to show how you can use Pyppeteer to access data that was injected into the page dynamically:</p>
<pre class="default s-code-block"><code class="hljs language-python"><span class="hljs-keyword">import</span> asyncio
<span class="hljs-keyword">from</span> pyppeteer <span class="hljs-keyword">import</span> launch

<span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():
    browser = <span class="hljs-keyword">await</span> launch({<span class="hljs-string">"headless"</span>: <span class="hljs-literal">True</span>})
    [page] = <span class="hljs-keyword">await</span> browser.pages()

    <span class="hljs-comment"># normally, you go to a live site...</span>
    <span class="hljs-comment">#await page.goto("http://www.example.com")</span>
    <span class="hljs-comment"># but for this example, just set the HTML directly:</span>
    <span class="hljs-keyword">await</span> page.setContent(<span class="hljs-string">"""
    &lt;body&gt;
    &lt;script&gt;
    // inject content dynamically with JS, not part of the static HTML!
    document.body.innerHTML = `&lt;p&gt;hello world&lt;/p&gt;`; 
    &lt;/script&gt;
    &lt;/body&gt;
    """</span>)
    <span class="hljs-built_in">print</span>(<span class="hljs-keyword">await</span> page.content()) <span class="hljs-comment"># shows that the `&lt;p&gt;` was inserted</span>

    <span class="hljs-comment"># evaluate a JS expression in browser context and scrape the data</span>
    expr = <span class="hljs-string">"document.querySelector('p').textContent"</span>
    <span class="hljs-built_in">print</span>(<span class="hljs-keyword">await</span> page.evaluate(expr, force_expr=<span class="hljs-literal">True</span>)) <span class="hljs-comment"># =&gt; hello world</span>

    <span class="hljs-keyword">await</span> browser.close()

asyncio.get_event_loop().run_until_complete(main())
</code></pre>
<p>See <a href="https://pyppeteer.github.io/pyppeteer/reference.html" rel="nofollow noreferrer">Pyppeteer's reference docs</a>.</p>
    </div></div></div></div><div id="solution14" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h4 class="text-4xl font-semibold mb-5">Solution 14</h4><div class="tags-wrap h-max space-x-8"><div class="tags"><a class="rounded-2xl border bg-neutral-100 px-3 py-1 text-sm font-semibold whitespace-nowrap" href="/questions/tag/python-2.x">python-2.x</a></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<h2>Try accessing the API directly</h2>
<p>A common scenario you'll see in scraping is that the data is being requested asynchronously from an API endpoint by the webpage. A minimal example of this would be the following site:</p>
<p></p><div class="snippet" data-lang="js" data-hide="false" data-console="true" data-babel="false">
<div class="snippet-code">
<pre class="snippet-code-html lang-html s-code-block"><code class="hljs language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">body</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><span class="language-javascript">
<span class="hljs-title function_">fetch</span>(<span class="hljs-string">"https://jsonplaceholder.typicode.com/posts/1"</span>)
  .<span class="hljs-title function_">then</span>(<span class="hljs-function"><span class="hljs-params">res</span> =&gt;</span> {
    <span class="hljs-keyword">if</span> (!res.<span class="hljs-property">ok</span>) <span class="hljs-keyword">throw</span> <span class="hljs-title class_">Error</span>(res.<span class="hljs-property">status</span>);
    
    <span class="hljs-keyword">return</span> res.<span class="hljs-title function_">json</span>();
  })
  .<span class="hljs-title function_">then</span>(<span class="hljs-function"><span class="hljs-params">data</span> =&gt;</span> {
    <span class="hljs-comment">// inject data dynamically via JS after page load</span>
    <span class="hljs-variable language_">document</span>.<span class="hljs-property">body</span>.<span class="hljs-property">innerText</span> = data.<span class="hljs-property">title</span>;
  })
  .<span class="hljs-title function_">catch</span>(<span class="hljs-function"><span class="hljs-params">err</span> =&gt;</span> <span class="hljs-variable language_">console</span>.<span class="hljs-title function_">error</span>(err))
;
</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">body</span>&gt;</span></code></pre>
<div class="snippet-result"><div class="snippet-ctas"><button type="button" class="s-btn s-btn__primary"><span class="icon-play-white _hover"></span><span> Run code snippet</span></button><input class="copySnippet s-btn s-btn__filled" type="button" value="Copy snippet to answer" style="display: none;"><button type="button" class="s-btn hideResults" style="display: none;">Hide results</button><div class="popout-code"><a class="snippet-expand-link">Expand snippet</a></div></div><div class="snippet-result-code" style="display: none;"><iframe name="sif1" sandbox="allow-forms allow-modals allow-scripts" class="snippet-box-edit snippet-box-result" frameborder="0"></iframe></div></div></div>
</div>
<p></p>
<p>In many cases, the API will be protected by CORS or an access token or prohibitively rate limited, but in other cases it's publicly-accessible and you can bypass the website entirely. For CORS issues, you might try <a href="https://stackoverflow.com/questions/29670703/how-to-use-cors-anywhere-to-reverse-proxy-and-add-cors-headers">cors-anywhere</a>.</p>
<p>The general procedure is to use your browser's developer tools' network tab to search the requests made by the page for keywords/substrings of the data you want to scrape. Often, you'll see an unprotected API request endpoint with a JSON payload that you can access directly with <code>urllib</code> or <code>requests</code> modules. That's the case with the above runnable snippet which you can use to practice. After clicking "run snippet", here's how I found the endpoint in my network tab:</p>
<p><a href="https://i.stack.imgur.com/EOxkc.png" rel="nofollow noreferrer"><img src="https://i.stack.imgur.com/EOxkc.png" alt="example network tab showing remote URL endpoint found with a search"></a></p>
<p>This example is contrived; the endpoint URL will likely be non-obvious from looking at the static markup because it could be dynamically assembled, minified and buried under dozens of other requests and endpoints. The network request will also show any relevant request payload details like access token you may need.</p>
<p>After obtaining the endpoint URL and relevant details, build a request in Python using a standard HTTP library and request the data:</p>
<pre class="default s-code-block"><code class="hljs language-python"><span class="hljs-meta">&gt;&gt;&gt; </span><span class="hljs-keyword">import</span> requests
<span class="hljs-meta">&gt;&gt;&gt; </span>res = requests.get(<span class="hljs-string">"https://jsonplaceholder.typicode.com/posts/1"</span>)
<span class="hljs-meta">&gt;&gt;&gt; </span>data = res.json()
<span class="hljs-meta">&gt;&gt;&gt; </span>data[<span class="hljs-string">"title"</span>]
<span class="hljs-string">'sunt aut facere repellat provident occaecati excepturi optio reprehenderit'</span>
</code></pre>
<p>When you can get away with it, this tends to be much easier, faster and more reliable than scraping the page with Selenium, Pyppeteer, Scrapy or whatever the popular scraping libraries are at the time you're reading this post.</p>
<p>If you're unlucky and the data hasn't arrived via an API request that returns the data in a nice format, it could be part of the original browser's payload in a <code>&lt;script&gt;</code> tag, either as a JSON string or (more likely) a JS object. For example:</p>
<p></p><div class="snippet" data-lang="js" data-hide="false" data-console="true" data-babel="false">
<div class="snippet-code">
<pre class="snippet-code-html lang-html s-code-block"><code class="hljs language-xml"><span class="hljs-tag">&lt;<span class="hljs-name">body</span>&gt;</span>
<span class="hljs-tag">&lt;<span class="hljs-name">script</span>&gt;</span><span class="language-javascript">
  <span class="hljs-keyword">var</span> someHardcodedData = {
    <span class="hljs-attr">userId</span>: <span class="hljs-number">1</span>,
    <span class="hljs-attr">id</span>: <span class="hljs-number">1</span>,
    <span class="hljs-attr">title</span>: <span class="hljs-string">'sunt aut facere repellat provident occaecati excepturi optio reprehenderit'</span>, 
    <span class="hljs-attr">body</span>: <span class="hljs-string">'quia et suscipit\nsuscipit recusandae con sequuntur expedita et cum\nreprehenderit molestiae ut ut quas totam\nnostrum rerum est autem sunt rem eveniet architecto'</span>
  };
  <span class="hljs-variable language_">document</span>.<span class="hljs-property">body</span>.<span class="hljs-property">textContent</span> = someHardcodedData.<span class="hljs-property">title</span>;
</span><span class="hljs-tag">&lt;/<span class="hljs-name">script</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">body</span>&gt;</span></code></pre>
<div class="snippet-result"><div class="snippet-ctas"><button type="button" class="s-btn s-btn__primary"><span class="icon-play-white _hover"></span><span> Run code snippet</span></button><input class="copySnippet s-btn s-btn__filled" type="button" value="Copy snippet to answer" style="display: none;"><button type="button" class="s-btn hideResults" style="display: none;">Hide results</button><div class="popout-code"><a class="snippet-expand-link">Expand snippet</a></div></div><div class="snippet-result-code" style="display: none;"><iframe name="sif2" sandbox="allow-forms allow-modals allow-scripts" class="snippet-box-edit snippet-box-result" frameborder="0"></iframe></div></div></div>
</div>
<p></p>
<p>There's no one-size-fits-all way to obtain this data. The basic technique is to use BeautifulSoup to access the <code>&lt;script&gt;</code> tag text, then apply a regex or a parse to extract the object structure, JSON string, or whatever format the data might be in. Here's a proof-of-concept on the sample structure shown above:</p>
<pre class="lang-py s-code-block"><code class="hljs language-python"><span class="hljs-keyword">import</span> json
<span class="hljs-keyword">import</span> re
<span class="hljs-keyword">from</span> bs4 <span class="hljs-keyword">import</span> BeautifulSoup

<span class="hljs-comment"># pretend we've already used requests to retrieve the data, </span>
<span class="hljs-comment"># so we hardcode it for the purposes of this example</span>
text = <span class="hljs-string">"""
&lt;body&gt;
&lt;script&gt;
  var someHardcodedData = {
    userId: 1,
    id: 1,
    title: 'sunt aut facere repellat provident occaecati excepturi optio reprehenderit', 
    body: 'quia et suscipit\nsuscipit recusandae con sequuntur expedita et cum\nreprehenderit molestiae ut ut quas totam\nnostrum rerum est autem sunt rem eveniet architecto'
  };
  document.body.textContent = someHardcodedData.title;
&lt;/script&gt;
&lt;/body&gt;
"""</span>
soup = BeautifulSoup(text, <span class="hljs-string">"lxml"</span>)
script_text = <span class="hljs-built_in">str</span>(soup.select_one(<span class="hljs-string">"script"</span>))
pattern = <span class="hljs-string">r"title: '(.*?)'"</span>
<span class="hljs-built_in">print</span>(re.search(pattern, script_text, re.S).group(<span class="hljs-number">1</span>))
</code></pre>
<p>Check out these resources for parsing JS objects that aren't quite valid JSON:</p>
<ul>
<li><a href="https://stackoverflow.com/questions/24027589/how-to-convert-raw-javascript-object-to-python-dictionary">How to convert raw javascript object to python dictionary?</a></li>
<li><a href="https://stackoverflow.com/questions/50947760/how-to-fix-json-key-values-without-double-quotes">How to Fix JSON Key Values without double-quotes?</a></li>
</ul>
<p>Here are some additional case studies/proofs-of-concept where scraping was bypassed using an API:</p>
<ul>
<li><a href="https://stackoverflow.com/questions/69801378/how-can-i-scrape-yelp-reviews-and-star-ratings-into-csv-using-python-beautifulso?noredirect=1#comment123391238_69801378">How can I scrape yelp reviews and star ratings into CSV using Python beautifulsoup</a></li>
<li><a href="https://stackoverflow.com/a/59378253/6243352">Beautiful Soup returns None on existing element</a></li>
<li><a href="https://stackoverflow.com/a/65905956/6243352">Extract data from  BeautifulSoup Python</a></li>
<li><a href="https://stackoverflow.com/a/64419449/6243352">Scraping Bandcamp fan collections via POST</a> (uses a hybrid approach where an initial request was made to the website to extract a token from the markup using BeautifulSoup which was then used in a second request to a JSON endpoint)</li>
</ul>
<p>If all else fails, try one of the many dynamic scraping libraries listed in this thread.</p>
    </div></div></div></div><div id="solution15" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h4 class="text-4xl font-semibold mb-5">Solution 15</h4><div class="tags-wrap h-max space-x-8"><div class="tags"><a class="rounded-2xl border bg-neutral-100 px-3 py-1 text-sm font-semibold whitespace-nowrap" href="/questions/tag/python-2.x">python-2.x</a></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>As mentioned, Selenium is a good choice for rendering the results of the JavaScript:</p>
<pre class="lang-py s-code-block"><code class="hljs language-python"><span class="hljs-keyword">from</span> selenium.webdriver <span class="hljs-keyword">import</span> Firefox
<span class="hljs-keyword">from</span> selenium.webdriver.firefox.options <span class="hljs-keyword">import</span> Options

options = Options()
options.headless = <span class="hljs-literal">True</span>
browser = Firefox(executable_path=<span class="hljs-string">"/usr/local/bin/geckodriver"</span>, options=options)

url = <span class="hljs-string">"https://www.example.com"</span>
browser.get(url)
</code></pre>
<p>And <a href="https://github.com/maxhumber/gazpacho" rel="nofollow noreferrer">gazpacho</a> is a really easy library to parse over the rendered html:</p>
<pre class="lang-py s-code-block"><code class="hljs language-python"><span class="hljs-keyword">from</span> gazpacho <span class="hljs-keyword">import</span> Soup

soup = Soup(browser.page_source)
soup.find(<span class="hljs-string">"a"</span>).attrs[<span class="hljs-string">'href'</span>]
</code></pre>
    </div></div></div></div><div id="solution16" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h4 class="text-4xl font-semibold mb-5">Solution 16</h4><div class="tags-wrap h-max space-x-8"><div class="tags"><a class="rounded-2xl border bg-neutral-100 px-3 py-1 text-sm font-semibold whitespace-nowrap" href="/questions/tag/python-2.x">python-2.x</a></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>I recently used requests_html library to solve this problem.</p>
<p>Their <a href="https://requests.readthedocs.io/projects/requests-html/en/latest/" rel="nofollow noreferrer">expanded documentation</a> at readthedocs.io is pretty good (skip the annotated version at pypi.org). If your use case is basic, you are likely to have some success.</p>
<pre class="default s-code-block"><code class="hljs language-coffeescript"><span class="hljs-keyword">from</span> requests_html <span class="hljs-keyword">import</span> HTMLSession
session = HTMLSession()
response = session.request(method=<span class="hljs-string">"get"</span>,url=<span class="hljs-string">"www.google.com/"</span>)
response.html.render()
</code></pre>
<p>If you are having trouble rendering the data you need with response.html.render(), you can pass some javascript to the render function to render the particular js object you need. This is copied from their docs, but it might be just what you need:</p>
<blockquote>
<p>If script is specified, it will execute the provided JavaScript at
runtime. Example:</p>
</blockquote>
<pre class="default s-code-block"><code class="hljs language-ini"><span class="hljs-attr">script</span> = <span class="hljs-string">"""
    () =&gt; {
        return {
            width: document.documentElement.clientWidth,
            height: document.documentElement.clientHeight,
            deviceScaleFactor: window.devicePixelRatio,
        }
    } 
"""</span>
</code></pre>
<blockquote>
<p>Returns the return value of the executed script, if any is provided:</p>
</blockquote>
<pre class="default s-code-block"><code class="hljs language-javascript">&gt;&gt;&gt; response.<span class="hljs-property">html</span>.<span class="hljs-title function_">render</span>(<span class="hljs-params">script=script</span>)
{<span class="hljs-string">'width'</span>: <span class="hljs-number">800</span>, <span class="hljs-string">'height'</span>: <span class="hljs-number">600</span>, <span class="hljs-string">'deviceScaleFactor'</span>: <span class="hljs-number">1</span>}
</code></pre>
<p>In my case, the data I wanted were the arrays that populated a javascript plot but the data wasn't getting rendered as text anywhere in the html. Sometimes its not clear at all what the object names are of the data you want if the data is populated dynamically. If you can't track down the js objects directly from view source or inspect, you can type in "window" followed by ENTER in the debugger console in the browser (Chrome) to pull up a full list of objects rendered by the browser. If you make a few educated guesses about where the data is stored, you might have some luck finding it there. My graph data was under window.view.data in the console, so in the "script" variable passed to the .render() method quoted above, I used:</p>
<pre class="default s-code-block"><code class="hljs language-kotlin"><span class="hljs-keyword">return</span> {
    <span class="hljs-keyword">data</span>: window.view.<span class="hljs-keyword">data</span>
}
</code></pre>
    </div></div></div></div><div id="solution17" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h4 class="text-4xl font-semibold mb-5">Solution 17</h4><div class="tags-wrap h-max space-x-8"><div class="tags"><a class="rounded-2xl border bg-neutral-100 px-3 py-1 text-sm font-semibold whitespace-nowrap" href="/questions/tag/python-2.x">python-2.x</a></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<h2>Playwright-Python</h2>
<p>Yet another option is <a href="https://github.com/microsoft/playwright-python" rel="nofollow noreferrer"><code>playwright-python</code></a>, a port of Microsoft's Playwright (itself a Puppeteer-influenced browser automation library) to Python.</p>
<p>Here's the minimal example of selecting an element and grabbing its text:</p>
<pre class="default s-code-block"><code class="hljs language-css"><span class="hljs-selector-tag">from</span> playwright<span class="hljs-selector-class">.sync_api</span> import sync_playwright

with sync_playwright() as <span class="hljs-selector-tag">p</span>:
    browser = p.chromium.<span class="hljs-built_in">launch</span>()
    page = browser.<span class="hljs-built_in">new_page</span>()
    page.<span class="hljs-built_in">goto</span>(<span class="hljs-string">"http://whatsmyuseragent.org/"</span>)
    ua = page.<span class="hljs-built_in">query_selector</span>(<span class="hljs-string">".user-agent"</span>);
    print(ua<span class="hljs-selector-class">.text_content</span>())
    browser<span class="hljs-selector-class">.close</span>()
</code></pre>
    </div></div></div></div><div id="solution18" class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl solution-inner border md:px-10 md:py-10 px-2 py-10 shadow-md bg-white"><div style="display:flex;justify-content:space-between"><h4 class="text-4xl font-semibold mb-5">Solution 18</h4><div class="tags-wrap h-max space-x-8"><div class="tags"><a class="rounded-2xl border bg-neutral-100 px-3 py-1 text-sm font-semibold whitespace-nowrap" href="/questions/tag/python-2.x">python-2.x</a></div></div></div><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p><strong>Easy and Quick Solution:</strong></p>
<p>I was dealing with same problem. I want to scrape some data which is build with JavaScript. If I scrape only text from this site with BeautifulSoup then I ended with  tags in text.
I want to render this  tag and wills to grab information from this.
Also, I dont want to use heavy frameworks  like Scrapy and selenium.</p>
<p>So, I found that <strong>get</strong> method of requests <strong>module</strong> takes urls, and it actually renders the script tag.</p>
<p>Example:</p>
<pre class="default s-code-block"><code class="hljs language-makefile">import requests
custom_User_agent = <span class="hljs-string">"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0"</span>
url = <span class="hljs-string">"https://www.abc.xyz/your/url"</span>
response = requests.get(url, headers={<span class="hljs-string">"User-Agent"</span>: custom_User_agent})
html_text = response.text
</code></pre>
<p>This will renders load site and renders  tags.</p>
<p>Hope this will help as quick and easy solution to render site which is loaded with script tags.</p>
    </div></div></div></div></div></div><div class="widget"><a href="/questions/how-to-filter-pandas-dataframe-using-&#x27;in&#x27;-and-&#x27;not-in&#x27;-like-in-sql-1657387371355">How to filter Pandas dataframe using &#x27;in&#x27; and &#x27;not in&#x27; like in SQL</a><a href="/questions/remove-duplicate-values-from-js-array-duplicate-1657387801931">Remove duplicate values from JS array [duplicate]</a><a href="/questions/what-is-the-difference-between-json-and-object-literal-notation-1657387515710">What is the difference between JSON and Object Literal Notation?</a><a href="/questions/how-do-i-set-clear-and-toggle-a-single-bit-1657388227052">How do I set, clear, and toggle a single bit?</a><a href="/questions/what-does-enctype&#x27;multipartform-data&#x27;-mean-1657388229352">What does enctype=&#x27;multipart/form-data&#x27; mean?</a><a href="/questions/how-to-access-the-correct-this-inside-a-callback-1657384283261">How to access the correct `this` inside a callback</a><a href="/questions/how-can-i-convert-ereg-expressions-to-preg-in-php-1657387652855">How can I convert ereg expressions to preg in PHP?</a><a href="/questions/reference:-mod_rewrite-url-rewriting-and-%22pretty-links%22-explained-1657384905504">Reference: mod_rewrite, URL rewriting and &quot;pretty links&quot; explained</a><a href="/questions/is-it-possible-to-escape-regex-metacharacters-reliably-with-sed-1657388428795">Is it possible to escape regex metacharacters reliably with sed</a><a href="/questions/how-to-reshape-data-from-long-to-wide-format-1657384486421">How to reshape data from long to wide format</a><a href="/questions/how-do-i-clone-a-list-so-that-it-doesn&#x27;t-change-unexpectedly-after-assignment-1657384423195">How do I clone a list so that it doesn&#x27;t change unexpectedly after assignment?</a><a href="/questions/iterator-invalidation-rules-for-c++-containers-1657387561090">Iterator invalidation rules for C++ containers</a><a href="/questions/calling-a-function-of-a-module-by-using-its-name-(a-string)-1657388565656">Calling a function of a module by using its name (a string)</a><a href="/questions/why-does-my-recursive-function-return-none-1657387792894">Why does my recursive function return None?</a><a href="/questions/captured-variable-in-a-loop-in-c-1657387696779">Captured variable in a loop in C#</a><a href="/questions/how-do-you-access-the-matched-groups-in-a-javascript-regular-expression-1657388233817">How do you access the matched groups in a JavaScript regular expression?</a><a href="/questions/does-python-have-a-ternary-conditional-operator-1657387555448">Does Python have a ternary conditional operator?</a><a href="/questions/dynamic-tabs-with-user-click-chosen-components-1657388465232">Dynamic tabs with user-click chosen components</a><a href="/questions/what-is-the-difference-between-const-int*-const-int-*-const-and-int-const-*-1657388184604">What is the difference between const int*, const int * const, and int const *?</a><a href="/questions/make-container-shrink-to-fit-child-elements-as-they-wrap-1657388134549">Make container shrink-to-fit child elements as they wrap</a></div></div><span class="cursor-pointer text-lg p-2" style="position:fixed;bottom:20px;left:20px;background:#000;z-index:2000;color:white">Go go top</span></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"data":{"answer":["\n\u0026lt;p\u0026gt;EDIT Sept 2021: \u0026lt;code\u0026gt;phantomjs\u0026lt;/code\u0026gt; isn\u0026apos;t maintained any more, either\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;EDIT 30/Dec/2017: This answer appears in top results of Google searches, so I decided to update it. The old answer is still at the end.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;dryscape isn\u0026apos;t maintained anymore and the library dryscape developers recommend is Python 2 only. I have found using Selenium\u0026apos;s python library with Phantom JS as a web driver fast enough and easy to get the work done.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;Once you have installed \u0026lt;a href=\u0026quot;http://phantomjs.org/download.html\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;Phantom JS\u0026lt;/a\u0026gt;, make sure the \u0026lt;code\u0026gt;phantomjs\u0026lt;/code\u0026gt; binary is available in the current path:\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-sql\u0026quot;\u0026gt;phantomjs \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;--version\u0026lt;/span\u0026gt;\n# \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;result\u0026lt;/span\u0026gt;:\n\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;2.1\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;.1\u0026lt;/span\u0026gt;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;#Example\nTo give an example, I created a sample page with following HTML code. (\u0026lt;a href=\u0026quot;http://avi.im/stuff/js-or-no-js.html\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;link\u0026lt;/a\u0026gt;):\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-xml\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;\u0026amp;lt;!DOCTYPE \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;html\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-tag\u0026quot;\u0026gt;\u0026amp;lt;\u0026lt;span class=\u0026quot;hljs-name\u0026quot;\u0026gt;html\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-tag\u0026quot;\u0026gt;\u0026amp;lt;\u0026lt;span class=\u0026quot;hljs-name\u0026quot;\u0026gt;head\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\n  \u0026lt;span class=\u0026quot;hljs-tag\u0026quot;\u0026gt;\u0026amp;lt;\u0026lt;span class=\u0026quot;hljs-name\u0026quot;\u0026gt;meta\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-attr\u0026quot;\u0026gt;charset\u0026lt;/span\u0026gt;=\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;utf-8\u0026quot;\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\n  \u0026lt;span class=\u0026quot;hljs-tag\u0026quot;\u0026gt;\u0026amp;lt;\u0026lt;span class=\u0026quot;hljs-name\u0026quot;\u0026gt;title\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;Javascript scraping test\u0026lt;span class=\u0026quot;hljs-tag\u0026quot;\u0026gt;\u0026amp;lt;/\u0026lt;span class=\u0026quot;hljs-name\u0026quot;\u0026gt;title\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-tag\u0026quot;\u0026gt;\u0026amp;lt;/\u0026lt;span class=\u0026quot;hljs-name\u0026quot;\u0026gt;head\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-tag\u0026quot;\u0026gt;\u0026amp;lt;\u0026lt;span class=\u0026quot;hljs-name\u0026quot;\u0026gt;body\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\n  \u0026lt;span class=\u0026quot;hljs-tag\u0026quot;\u0026gt;\u0026amp;lt;\u0026lt;span class=\u0026quot;hljs-name\u0026quot;\u0026gt;p\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-attr\u0026quot;\u0026gt;id\u0026lt;/span\u0026gt;=\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;intro-text\u0026apos;\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;No javascript support\u0026lt;span class=\u0026quot;hljs-tag\u0026quot;\u0026gt;\u0026amp;lt;/\u0026lt;span class=\u0026quot;hljs-name\u0026quot;\u0026gt;p\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\n  \u0026lt;span class=\u0026quot;hljs-tag\u0026quot;\u0026gt;\u0026amp;lt;\u0026lt;span class=\u0026quot;hljs-name\u0026quot;\u0026gt;script\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;language-javascript\u0026quot;\u0026gt;\n     \u0026lt;span class=\u0026quot;hljs-variable language_\u0026quot;\u0026gt;document\u0026lt;/span\u0026gt;.\u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;getElementById\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;intro-text\u0026apos;\u0026lt;/span\u0026gt;).\u0026lt;span class=\u0026quot;hljs-property\u0026quot;\u0026gt;innerHTML\u0026lt;/span\u0026gt; = \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;Yay! Supports javascript\u0026apos;\u0026lt;/span\u0026gt;;\n  \u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;hljs-tag\u0026quot;\u0026gt;\u0026amp;lt;/\u0026lt;span class=\u0026quot;hljs-name\u0026quot;\u0026gt;script\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt; \n\u0026lt;span class=\u0026quot;hljs-tag\u0026quot;\u0026gt;\u0026amp;lt;/\u0026lt;span class=\u0026quot;hljs-name\u0026quot;\u0026gt;body\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-tag\u0026quot;\u0026gt;\u0026amp;lt;/\u0026lt;span class=\u0026quot;hljs-name\u0026quot;\u0026gt;html\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;without javascript it says: \u0026lt;code\u0026gt;No javascript support\u0026lt;/code\u0026gt; and with javascript: \u0026lt;code\u0026gt;Yay! Supports javascript\u0026lt;/code\u0026gt;\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;#Scraping without JS support:\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-haskell\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; requests\n\u0026lt;span class=\u0026quot;hljs-title\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; bs4 \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; BeautifulSoup\n\u0026lt;span class=\u0026quot;hljs-title\u0026quot;\u0026gt;response\u0026lt;/span\u0026gt; = requests.get(my_url)\n\u0026lt;span class=\u0026quot;hljs-title\u0026quot;\u0026gt;soup\u0026lt;/span\u0026gt; = \u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;BeautifulSoup\u0026lt;/span\u0026gt;(response.text)\n\u0026lt;span class=\u0026quot;hljs-title\u0026quot;\u0026gt;soup\u0026lt;/span\u0026gt;.find(id=\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;intro-text\u0026quot;\u0026lt;/span\u0026gt;)\n\u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;# Result:\u0026lt;/span\u0026gt;\n\u0026amp;lt;p id=\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;intro-text\u0026quot;\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;No\u0026lt;/span\u0026gt; javascript support\u0026amp;lt;/p\u0026amp;gt;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;#Scraping with JS support:\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-coffeescript\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; selenium \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; webdriver\ndriver = webdriver.PhantomJS()\ndriver.get(my_url)\np_element = driver.find_element_by_id(id_=\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;intro-text\u0026apos;\u0026lt;/span\u0026gt;)\n\u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;print\u0026lt;/span\u0026gt;(p_element.text)\n\u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# result:\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;Yay! Supports javascript\u0026apos;\u0026lt;/span\u0026gt;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;hr\u0026gt;\n\u0026lt;p\u0026gt;You can also use Python library \u0026lt;a href=\u0026quot;https://github.com/niklasb/dryscrape\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;dryscrape\u0026lt;/a\u0026gt; to scrape javascript driven websites.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;#Scraping with JS support:\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-haskell\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; dryscrape\n\u0026lt;span class=\u0026quot;hljs-title\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; bs4 \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; BeautifulSoup\n\u0026lt;span class=\u0026quot;hljs-title\u0026quot;\u0026gt;session\u0026lt;/span\u0026gt; = dryscrape.\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;Session\u0026lt;/span\u0026gt;()\n\u0026lt;span class=\u0026quot;hljs-title\u0026quot;\u0026gt;session\u0026lt;/span\u0026gt;.visit(my_url)\n\u0026lt;span class=\u0026quot;hljs-title\u0026quot;\u0026gt;response\u0026lt;/span\u0026gt; = session.body()\n\u0026lt;span class=\u0026quot;hljs-title\u0026quot;\u0026gt;soup\u0026lt;/span\u0026gt; = \u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;BeautifulSoup\u0026lt;/span\u0026gt;(response)\n\u0026lt;span class=\u0026quot;hljs-title\u0026quot;\u0026gt;soup\u0026lt;/span\u0026gt;.find(id=\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;intro-text\u0026quot;\u0026lt;/span\u0026gt;)\n\u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;# Result:\u0026lt;/span\u0026gt;\n\u0026amp;lt;p id=\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;intro-text\u0026quot;\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;Yay\u0026lt;/span\u0026gt;! \u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;Supports\u0026lt;/span\u0026gt; javascript\u0026amp;lt;/p\u0026amp;gt;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n    ","\n\u0026lt;p\u0026gt;We are not getting the correct results because any javascript generated content needs to be rendered on the DOM. When we fetch an HTML page, we fetch the initial, unmodified by javascript, DOM.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;Therefore we need to render the javascript content before we crawl the page.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;As selenium is already mentioned many times in this thread (and how slow it gets sometimes was mentioned also), I will list two other possible solutions.\u0026lt;/p\u0026gt;\n\n\u0026lt;hr\u0026gt;\n\n\u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;Solution 1:\u0026lt;/strong\u0026gt; This is a very nice tutorial on \u0026lt;a href=\u0026quot;http://www.scrapingauthority.com/scrapy-javascript\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;how to use Scrapy to crawl javascript generated content\u0026lt;/a\u0026gt; and we are going to follow just that.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;What we will need:\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt;\n\n\u0026lt;ol\u0026gt;\n\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026quot;https://www.docker.com/\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;Docker\u0026lt;/a\u0026gt; installed in our machine. This is a plus over other solutions until this point, as it utilizes an OS-independent platform.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;\u0026lt;a href=\u0026quot;http://splash.readthedocs.io/en/latest/install.html\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;Install Splash\u0026lt;/a\u0026gt; following the instruction listed for our corresponding OS.\u0026lt;br\u0026gt;Quoting from splash documentation:\u0026lt;/p\u0026gt;\n\n\u0026lt;blockquote\u0026gt;\n  \u0026lt;p\u0026gt;Splash is a javascript rendering service. Its a lightweight web browser with an HTTP API, implemented in Python 3 using Twisted and QT5. \u0026lt;/p\u0026gt;\n\u0026lt;/blockquote\u0026gt;\n\n\u0026lt;p\u0026gt;Essentially we are going to use Splash to render Javascript generated content.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Run the splash server: \u0026lt;code\u0026gt;sudo docker run -p 8050:8050 scrapinghub/splash\u0026lt;/code\u0026gt;.\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Install the \u0026lt;a href=\u0026quot;https://github.com/scrapy-plugins/scrapy-splash#installation\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;scrapy-splash\u0026lt;/a\u0026gt; plugin: \u0026lt;code\u0026gt;pip install scrapy-splash\u0026lt;/code\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Assuming that we already have a Scrapy project created (if not, \u0026lt;a href=\u0026quot;https://docs.scrapy.org/en/latest/intro/tutorial.html#creating-a-project\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;let\u0026apos;s make one\u0026lt;/a\u0026gt;), we will follow the guide and update the \u0026lt;code\u0026gt;settings.py\u0026lt;/code\u0026gt;:\u0026lt;/p\u0026gt;\n\n\u0026lt;blockquote\u0026gt;\n  \u0026lt;p\u0026gt;Then go to your scrapy projects \u0026lt;code\u0026gt;settings.py\u0026lt;/code\u0026gt; and set these middlewares:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-bash\u0026quot;\u0026gt;DOWNLOADER_MIDDLEWARES = {\n      \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;scrapy_splash.SplashCookiesMiddleware\u0026apos;\u0026lt;/span\u0026gt;: 723,\n      \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;scrapy_splash.SplashMiddleware\u0026apos;\u0026lt;/span\u0026gt;: 725,\n      \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware\u0026apos;\u0026lt;/span\u0026gt;: 810,\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n  \n  \u0026lt;p\u0026gt;The URL of the Splash server(if youre using Win or OSX this should be the URL of the docker machine: \u0026lt;a href=\u0026quot;https://stackoverflow.com/questions/17157721/how-to-get-a-docker-containers-ip-address-from-the-host\u0026quot;\u0026gt;How to get a Docker container\u0026apos;s IP address from the host?\u0026lt;/a\u0026gt;):\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-ini\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-attr\u0026quot;\u0026gt;SPLASH_URL\u0026lt;/span\u0026gt; = \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;http://localhost:8050\u0026apos;\u0026lt;/span\u0026gt;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n  \n  \u0026lt;p\u0026gt;And finally you need to set these values too:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-ini\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-attr\u0026quot;\u0026gt;DUPEFILTER_CLASS\u0026lt;/span\u0026gt; = \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;scrapy_splash.SplashAwareDupeFilter\u0026apos;\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-attr\u0026quot;\u0026gt;HTTPCACHE_STORAGE\u0026lt;/span\u0026gt; = \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;scrapy_splash.SplashAwareFSCacheStorage\u0026apos;\u0026lt;/span\u0026gt;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;/blockquote\u0026gt;\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Finally, we can use a \u0026lt;a href=\u0026quot;https://github.com/scrapy-plugins/scrapy-splash#usage\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;\u0026lt;code\u0026gt;SplashRequest\u0026lt;/code\u0026gt;\u0026lt;/a\u0026gt;:\u0026lt;/p\u0026gt;\n\n\u0026lt;blockquote\u0026gt;\n  \u0026lt;p\u0026gt;In a normal spider you have Request objects which you can use to open URLs. If the page you want to open contains JS generated data you have to use SplashRequest(or SplashFormRequest) to render the page. Heres a simple example:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-ruby\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;class\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title class_\u0026quot;\u0026gt;MySpider\u0026lt;/span\u0026gt;(scrapy.Spider):\n    name = \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;jsscraper\u0026quot;\u0026lt;/span\u0026gt;\n    start_urls = [\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;http://quotes.toscrape.com/js/\u0026quot;\u0026lt;/span\u0026gt;]\n\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;start_requests\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-variable language_\u0026quot;\u0026gt;self\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;):\n        \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;for\u0026lt;/span\u0026gt; url \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;in\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-variable language_\u0026quot;\u0026gt;self\u0026lt;/span\u0026gt;.\u0026lt;span class=\u0026quot;hljs-symbol\u0026quot;\u0026gt;start_urls:\u0026lt;/span\u0026gt;\n        \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;yield\u0026lt;/span\u0026gt; SplashRequest(\n            url=url, callback=\u0026lt;span class=\u0026quot;hljs-variable language_\u0026quot;\u0026gt;self\u0026lt;/span\u0026gt;.parse, endpoint=\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;render.html\u0026apos;\u0026lt;/span\u0026gt;\n        )\n\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;parse\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-variable language_\u0026quot;\u0026gt;self\u0026lt;/span\u0026gt;, response\u0026lt;/span\u0026gt;):\n        \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;for\u0026lt;/span\u0026gt; q \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;in\u0026lt;/span\u0026gt; response.css(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;div.quote\u0026quot;\u0026lt;/span\u0026gt;):\n        quote = QuoteItem()\n        quote[\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;author\u0026quot;\u0026lt;/span\u0026gt;] = q.css(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;.author::text\u0026quot;\u0026lt;/span\u0026gt;).extract_first()\n        quote[\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;quote\u0026quot;\u0026lt;/span\u0026gt;] = q.css(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;.text::text\u0026quot;\u0026lt;/span\u0026gt;).extract_first()\n        \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;yield\u0026lt;/span\u0026gt; quote\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n  \n  \u0026lt;p\u0026gt;SplashRequest renders the URL as html and returns the response which you can use in the callback(parse) method.\u0026lt;/p\u0026gt;\n\u0026lt;/blockquote\u0026gt;\u0026lt;/li\u0026gt;\n\u0026lt;/ol\u0026gt;\n\n\u0026lt;hr\u0026gt;\n\n\u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;Solution 2:\u0026lt;/strong\u0026gt; Let\u0026apos;s call this experimental at the moment (May 2018)...\u0026lt;br\u0026gt;\n\u0026lt;strong\u0026gt;This solution is for Python\u0026apos;s version 3.6\u0026lt;/strong\u0026gt; only (at the moment).\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;Do you know the \u0026lt;a href=\u0026quot;http://docs.python-requests.org/en/master/\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;requests\u0026lt;/a\u0026gt; module (well who doesn\u0026apos;t)?\u0026lt;br\u0026gt;\nNow it has a web crawling little sibling: \u0026lt;a href=\u0026quot;https://github.com/psf/requests-html\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;requests-HTML\u0026lt;/a\u0026gt;:\u0026lt;/p\u0026gt;\n\n\u0026lt;blockquote\u0026gt;\n  \u0026lt;p\u0026gt;This library intends to make parsing HTML (e.g. scraping the web) as simple and intuitive as possible.\u0026lt;/p\u0026gt;\n\u0026lt;/blockquote\u0026gt;\n\n\u0026lt;ol\u0026gt;\n\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Install requests-html: \u0026lt;code\u0026gt;pipenv install requests-html\u0026lt;/code\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Make a request to the page\u0026apos;s url:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-csharp\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; requests_html import HTMLSession\n\nsession = HTMLSession()\nr = session.\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;get\u0026lt;/span\u0026gt;(a_page_url)\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;\u0026lt;p\u0026gt;Render the response to get the Javascript generated bits:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-scss\u0026quot;\u0026gt;r\u0026lt;span class=\u0026quot;hljs-selector-class\u0026quot;\u0026gt;.html\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;hljs-selector-class\u0026quot;\u0026gt;.render\u0026lt;/span\u0026gt;()\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\u0026lt;/li\u0026gt;\n\u0026lt;/ol\u0026gt;\n\n\u0026lt;p\u0026gt;Finally, the module seems to offer \u0026lt;a href=\u0026quot;https://html.python-requests.org/#api-documentation\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;scraping capabilities\u0026lt;/a\u0026gt;.\u0026lt;br\u0026gt;\nAlternatively, we can try the well-documented way \u0026lt;a href=\u0026quot;https://www.dataquest.io/blog/web-scraping-beautifulsoup/\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;of using BeautifulSoup\u0026lt;/a\u0026gt; with the \u0026lt;code\u0026gt;r.html\u0026lt;/code\u0026gt; object we just rendered.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;Maybe \u0026lt;a href=\u0026quot;http://www.seleniumhq.org/\u0026quot;\u0026gt;selenium\u0026lt;/a\u0026gt; can do it.\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-haskell\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-title\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; selenium \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; webdriver\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; time\n\n\u0026lt;span class=\u0026quot;hljs-title\u0026quot;\u0026gt;driver\u0026lt;/span\u0026gt; = webdriver.\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;Firefox\u0026lt;/span\u0026gt;()\n\u0026lt;span class=\u0026quot;hljs-title\u0026quot;\u0026gt;driver\u0026lt;/span\u0026gt;.get(url)\n\u0026lt;span class=\u0026quot;hljs-title\u0026quot;\u0026gt;time\u0026lt;/span\u0026gt;.sleep(\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;5\u0026lt;/span\u0026gt;)\n\u0026lt;span class=\u0026quot;hljs-title\u0026quot;\u0026gt;htmlSource\u0026lt;/span\u0026gt; = driver.page_source\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n    ","\n\u0026lt;p\u0026gt;If you have ever used the \u0026lt;code\u0026gt;Requests\u0026lt;/code\u0026gt; module for python before, I recently found out that the developer created a new module called \u0026lt;code\u0026gt;Requests-HTML\u0026lt;/code\u0026gt; which now also has the ability to render JavaScript.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;You can also visit \u0026lt;a href=\u0026quot;https://html.python-requests.org/\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;https://html.python-requests.org/\u0026lt;/a\u0026gt; to learn more about this module, or if your only interested about rendering JavaScript then you can visit \u0026lt;a href=\u0026quot;https://html.python-requests.org/?#javascript-support\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;https://html.python-requests.org/?#javascript-support\u0026lt;/a\u0026gt; to directly learn how to use the module to render JavaScript using Python.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;Essentially, Once you correctly install the \u0026lt;code\u0026gt;Requests-HTML\u0026lt;/code\u0026gt; module, the following example, which is \u0026lt;a href=\u0026quot;https://html.python-requests.org/?#javascript-support\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;shown on the above link\u0026lt;/a\u0026gt;, shows how you can use this module to scrape a website and render JavaScript contained within the website:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-csharp\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; requests_html import HTMLSession\nsession = HTMLSession()\n\nr = session.\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;get\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;http://python-requests.org/\u0026apos;\u0026lt;/span\u0026gt;)\n\nr.html.render()\n\nr.html.search(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;Python 2 will retire in only {months} months!\u0026apos;\u0026lt;/span\u0026gt;)[\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;months\u0026apos;\u0026lt;/span\u0026gt;]\n\n\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;\u0026amp;lt;time\u0026amp;gt;25\u0026amp;lt;/time\u0026amp;gt;\u0026apos;\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;#This is the result.\u0026lt;/span\u0026gt;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;I recently learnt about this from a YouTube video. \u0026lt;a href=\u0026quot;https://www.youtube.com/watch?v=gKT_tg87H5Y\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;Click Here!\u0026lt;/a\u0026gt; to watch the YouTube video, which demonstrates how the module works.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;It sounds like the data you\u0026apos;re really looking for can be accessed via secondary URL called by some javascript on the primary page.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;While you could try running javascript on the server to handle this, a simpler approach  to might be to load up the page using Firefox and use a tool like \u0026lt;a href=\u0026quot;http://www.google.co.uk/url?sa=t\u0026amp;amp;rct=j\u0026amp;amp;q=charles\u0026amp;amp;source=web\u0026amp;amp;cd=1\u0026amp;amp;ved=0CC4QFjAA\u0026amp;amp;url=http://www.charlesproxy.com/\u0026amp;amp;ei=FBC5TpyZC9Ha4QSD7umcCA\u0026amp;amp;usg=AFQjCNG_O70VsRrfb_q7F66Nkb9ZK6MNMA\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;Charles\u0026lt;/a\u0026gt; or \u0026lt;a href=\u0026quot;http://www.google.co.uk/url?sa=t\u0026amp;amp;rct=j\u0026amp;amp;q=firebug\u0026amp;amp;source=web\u0026amp;amp;cd=1\u0026amp;amp;ved=0CDEQFjAA\u0026amp;amp;url=http://getfirebug.com/\u0026amp;amp;ei=TBC5TuOPIbKQ4gTk7J3vBw\u0026amp;amp;usg=AFQjCNGT1rhhsYGPQx5Vr5A8RvhIgdSp9g\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;Firebug\u0026lt;/a\u0026gt; to identify exactly what that secondary URL is. Then you can just query that URL directly for the data you are interested in.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;This seems to be a good solution also, taken from a \u0026lt;a href=\u0026quot;https://impythonist.wordpress.com/2015/01/06/ultimate-guide-for-scraping-javascript-rendered-web-pages/\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;great blog post\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; sys  \n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; PyQt4.QtGui \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; *  \n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; PyQt4.QtCore \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; *  \n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; PyQt4.QtWebKit \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; *  \n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; lxml \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; html \n\n\u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;#Take this class for granted.Just use result of rendering.\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;class\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title class_\u0026quot;\u0026gt;Render\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-title class_ inherited__\u0026quot;\u0026gt;QWebPage\u0026lt;/span\u0026gt;):  \n  \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;__init__\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;self, url\u0026lt;/span\u0026gt;):  \n    self.app = QApplication(sys.argv)  \n    QWebPage.__init__(self)  \n    self.loadFinished.connect(self._loadFinished)  \n    self.mainFrame().load(QUrl(url))  \n    self.app.exec_()  \n\n  \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;_loadFinished\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;self, result\u0026lt;/span\u0026gt;):  \n    self.frame = self.mainFrame()  \n    self.app.quit()  \n\nurl = \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;http://pycoders.com/archive/\u0026apos;\u0026lt;/span\u0026gt;  \nr = Render(url)  \nresult = r.frame.toHtml()\n\u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# This step is important.Converting QString to Ascii for lxml to process\u0026lt;/span\u0026gt;\n\n\u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# The following returns an lxml element tree\u0026lt;/span\u0026gt;\narchive_links = html.fromstring(\u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;str\u0026lt;/span\u0026gt;(result.toAscii()))\n\u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;print\u0026lt;/span\u0026gt; archive_links\n\n\u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# The following returns an array containing the URLs\u0026lt;/span\u0026gt;\nraw_links = archive_links.xpath(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;//div[@class=\u0026quot;campaign\u0026quot;]/a/@href\u0026apos;\u0026lt;/span\u0026gt;)\n\u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;print\u0026lt;/span\u0026gt; raw_links\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n    ","\n\u0026lt;p\u0026gt;Selenium is the best for scraping JS and Ajax content.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;Check this article for \u0026lt;a href=\u0026quot;https://likegeeks.com/python-web-scraping/\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;extracting data from the web using Python\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-ruby\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-variable\u0026quot;\u0026gt;$ \u0026lt;/span\u0026gt;pip install selenium\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Then download Chrome webdriver.\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-coffeescript\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; selenium \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; webdriver\n\nbrowser = webdriver.Chrome()\n\nbrowser.get(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;https://www.python.org/\u0026quot;\u0026lt;/span\u0026gt;)\n\nnav = browser.find_element_by_id(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;mainnav\u0026quot;\u0026lt;/span\u0026gt;)\n\n\u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;print\u0026lt;/span\u0026gt;(nav.text)\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Easy, right?\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;You can also execute javascript using webdriver.\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-csharp\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; selenium import webdriver\n\ndriver = webdriver.Firefox()\ndriver.\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;get\u0026lt;/span\u0026gt;(url)\ndriver.execute_script(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;document.title\u0026apos;\u0026lt;/span\u0026gt;)\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;or store the value in a variable\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-vhdl\u0026quot;\u0026gt;result = driver.execute_script(\u0026lt;span class=\u0026quot;hljs-symbol\u0026quot;\u0026gt;\u0026apos;var\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-literal\u0026quot;\u0026gt;text\u0026lt;/span\u0026gt; = document.title ; \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;return\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-literal\u0026quot;\u0026gt;text\u0026lt;/span\u0026gt;\u0026apos;)\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n    ","\n\u0026lt;p\u0026gt;I personally prefer using scrapy and selenium and dockerizing both in separate containers. This way you can install both with minimal hassle and crawl modern websites that almost all contain javascript in one form or another. Here\u0026apos;s an example:\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;Use the \u0026lt;code\u0026gt;scrapy startproject\u0026lt;/code\u0026gt; to create your scraper and write your spider, the skeleton can be as simple as this:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-ruby\u0026quot;\u0026gt;import scrapy\n\n\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;class\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title class_\u0026quot;\u0026gt;MySpider\u0026lt;/span\u0026gt;(scrapy.Spider):\n    name = \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;my_spider\u0026apos;\u0026lt;/span\u0026gt;\n    start_urls = [\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;https://somewhere.com\u0026apos;\u0026lt;/span\u0026gt;]\n\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;start_requests\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-variable language_\u0026quot;\u0026gt;self\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;):\n        \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;yield\u0026lt;/span\u0026gt; scrapy.Request(url=\u0026lt;span class=\u0026quot;hljs-variable language_\u0026quot;\u0026gt;self\u0026lt;/span\u0026gt;.start_urls[\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0\u0026lt;/span\u0026gt;])\n\n\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;parse\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-variable language_\u0026quot;\u0026gt;self\u0026lt;/span\u0026gt;, response\u0026lt;/span\u0026gt;):\n\n        \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# do stuff with results, scrape items etc.\u0026lt;/span\u0026gt;\n        \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# now were just checking everything worked\u0026lt;/span\u0026gt;\n\n        print(response.body)\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;The real magic happens in the middlewares.py. Overwrite two methods in the downloader middleware,  \u0026lt;code\u0026gt;__init__\u0026lt;/code\u0026gt; and  \u0026lt;code\u0026gt;process_request\u0026lt;/code\u0026gt;, in the following way:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# import some additional modules that we need\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; os\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; copy \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; deepcopy\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; time \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; sleep\n\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; scrapy \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; signals\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; scrapy.http \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; HtmlResponse\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; selenium \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; webdriver\n\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;class\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title class_\u0026quot;\u0026gt;SampleProjectDownloaderMiddleware\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-title class_ inherited__\u0026quot;\u0026gt;object\u0026lt;/span\u0026gt;):\n\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;__init__\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;self\u0026lt;/span\u0026gt;):\n    SELENIUM_LOCATION = os.environ.get(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;SELENIUM_LOCATION\u0026apos;\u0026lt;/span\u0026gt;, \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;NOT_HERE\u0026apos;\u0026lt;/span\u0026gt;)\n    SELENIUM_URL = \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;f\u0026apos;http://\u0026lt;span class=\u0026quot;hljs-subst\u0026quot;\u0026gt;{SELENIUM_LOCATION}\u0026lt;/span\u0026gt;:4444/wd/hub\u0026apos;\u0026lt;/span\u0026gt;\n    chrome_options = webdriver.ChromeOptions()\n\n    \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# chrome_options.add_experimental_option(\u0026quot;mobileEmulation\u0026quot;, mobile_emulation)\u0026lt;/span\u0026gt;\n    self.driver = webdriver.Remote(command_executor=SELENIUM_URL,\n                                   desired_capabilities=chrome_options.to_capabilities())\n\n\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;process_request\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;self, request, spider\u0026lt;/span\u0026gt;):\n\n    self.driver.get(request.url)\n\n    \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# sleep a bit so the page has time to load\u0026lt;/span\u0026gt;\n    \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# or monitor items on page to continue as soon as page ready\u0026lt;/span\u0026gt;\n    sleep(\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;4\u0026lt;/span\u0026gt;)\n\n    \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# if you need to manipulate the page content like clicking and scrolling, you do it here\u0026lt;/span\u0026gt;\n    \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# self.driver.find_element_by_css_selector(\u0026apos;.my-class\u0026apos;).click()\u0026lt;/span\u0026gt;\n\n    \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# you only need the now properly and completely rendered html from your page to get results\u0026lt;/span\u0026gt;\n    body = deepcopy(self.driver.page_source)\n\n    \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# copy the current url in case of redirects\u0026lt;/span\u0026gt;\n    url = deepcopy(self.driver.current_url)\n\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;return\u0026lt;/span\u0026gt; HtmlResponse(url, body=body, encoding=\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;utf-8\u0026apos;\u0026lt;/span\u0026gt;, request=request)\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Dont forget to enable this middlware by uncommenting the next lines in the settings.py file:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-makefile\u0026quot;\u0026gt;DOWNLOADER_MIDDLEWARES = {\n\u0026lt;span class=\u0026quot;hljs-section\u0026quot;\u0026gt;\u0026apos;sample_project.middlewares.SampleProjectDownloaderMiddleware\u0026apos;: 543,}\u0026lt;/span\u0026gt;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Next for dockerization. Create your \u0026lt;code\u0026gt;Dockerfile\u0026lt;/code\u0026gt; from a lightweight image (I\u0026apos;m using python Alpine here), copy your project directory to it, install requirements:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-bash\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# Use an official Python runtime as a parent image\u0026lt;/span\u0026gt;\nFROM python:3.6-alpine\n\n\u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# install some packages necessary to scrapy and then curl because it\u0026apos;s  handy for debugging\u0026lt;/span\u0026gt;\nRUN apk --update add linux-headers libffi-dev openssl-dev build-base libxslt-dev libxml2-dev curl python-dev\n\nWORKDIR /my_scraper\n\nADD requirements.txt /my_scraper/\n\nRUN pip install -r requirements.txt\n\nADD . /scrapers\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;And finally bring it all together in \u0026lt;code\u0026gt;docker-compose.yaml\u0026lt;/code\u0026gt;:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-yaml\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-attr\u0026quot;\u0026gt;version:\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;2\u0026apos;\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-attr\u0026quot;\u0026gt;services:\u0026lt;/span\u0026gt;\n  \u0026lt;span class=\u0026quot;hljs-attr\u0026quot;\u0026gt;selenium:\u0026lt;/span\u0026gt;\n    \u0026lt;span class=\u0026quot;hljs-attr\u0026quot;\u0026gt;image:\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;selenium/standalone-chrome\u0026lt;/span\u0026gt;\n    \u0026lt;span class=\u0026quot;hljs-attr\u0026quot;\u0026gt;ports:\u0026lt;/span\u0026gt;\n      \u0026lt;span class=\u0026quot;hljs-bullet\u0026quot;\u0026gt;-\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;4444:4444\u0026quot;\u0026lt;/span\u0026gt;\n    \u0026lt;span class=\u0026quot;hljs-attr\u0026quot;\u0026gt;shm_size:\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;1G\u0026lt;/span\u0026gt;\n\n  \u0026lt;span class=\u0026quot;hljs-attr\u0026quot;\u0026gt;my_scraper:\u0026lt;/span\u0026gt;\n    \u0026lt;span class=\u0026quot;hljs-attr\u0026quot;\u0026gt;build:\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;.\u0026lt;/span\u0026gt;\n    \u0026lt;span class=\u0026quot;hljs-attr\u0026quot;\u0026gt;depends_on:\u0026lt;/span\u0026gt;\n      \u0026lt;span class=\u0026quot;hljs-bullet\u0026quot;\u0026gt;-\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;selenium\u0026quot;\u0026lt;/span\u0026gt;\n    \u0026lt;span class=\u0026quot;hljs-attr\u0026quot;\u0026gt;environment:\u0026lt;/span\u0026gt;\n      \u0026lt;span class=\u0026quot;hljs-bullet\u0026quot;\u0026gt;-\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;SELENIUM_LOCATION=samplecrawler_selenium_1\u0026lt;/span\u0026gt;\n    \u0026lt;span class=\u0026quot;hljs-attr\u0026quot;\u0026gt;volumes:\u0026lt;/span\u0026gt;\n      \u0026lt;span class=\u0026quot;hljs-bullet\u0026quot;\u0026gt;-\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;.:/my_scraper\u0026lt;/span\u0026gt;\n    \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# use this command to keep the container running\u0026lt;/span\u0026gt;\n    \u0026lt;span class=\u0026quot;hljs-attr\u0026quot;\u0026gt;command:\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;tail\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;-f\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;/dev/null\u0026lt;/span\u0026gt;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Run \u0026lt;code\u0026gt;docker-compose up -d\u0026lt;/code\u0026gt;. If you\u0026apos;re doing this the first time it will take a while for it to fetch the latest selenium/standalone-chrome and the build your scraper image as well. \u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;Once it\u0026apos;s done, you can check that your containers are running with \u0026lt;code\u0026gt;docker ps\u0026lt;/code\u0026gt; and also check that the name of the selenium container matches that of the environment variable that we passed to our scraper container (here, it was \u0026lt;code\u0026gt;SELENIUM_LOCATION=samplecrawler_selenium_1\u0026lt;/code\u0026gt;). \u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;Enter your scraper container with \u0026lt;code\u0026gt;docker exec -ti YOUR_CONTAINER_NAME sh\u0026lt;/code\u0026gt; , the command for me was \u0026lt;code\u0026gt;docker exec -ti samplecrawler_my_scraper_1 sh\u0026lt;/code\u0026gt;, cd into the right directory and run your scraper with \u0026lt;code\u0026gt;scrapy crawl my_spider\u0026lt;/code\u0026gt;.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;The entire thing is on my github page and you can get it from \u0026lt;a href=\u0026quot;https://github.com/tarikki/sample_crawler\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;here\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;A mix of BeautifulSoup and Selenium works very well for me.\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-coffeescript\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; selenium \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; webdriver\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; selenium.webdriver.common.\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;by\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; By\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; selenium.webdriver.support.ui \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; WebDriverWait\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; selenium.webdriver.support \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; expected_conditions \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;as\u0026lt;/span\u0026gt; EC\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; bs4 \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; BeautifulSoup \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;as\u0026lt;/span\u0026gt; bs\n\ndriver = webdriver.Firefox()\ndriver.get(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;http://somedomain/url_that_delays_loading\u0026quot;\u0026lt;/span\u0026gt;)\n    try:\n        element = WebDriverWait(driver, \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;10\u0026lt;/span\u0026gt;).\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;until\u0026lt;/span\u0026gt;(\n        EC.presence_of_element_located((By.ID, \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;myDynamicElement\u0026quot;\u0026lt;/span\u0026gt;))) \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;#waits 10 seconds until element is located. Can have other wait conditions  such as visibility_of_element_located or text_to_be_present_in_element\u0026lt;/span\u0026gt;\n\n        html = driver.page_source\n        soup = bs(html, \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;lxml\u0026quot;\u0026lt;/span\u0026gt;)\n        dynamic_text = soup.find_all(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;p\u0026quot;\u0026lt;/span\u0026gt;, {\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;class\u0026quot;\u0026lt;/span\u0026gt;:\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;class_name\u0026quot;\u0026lt;/span\u0026gt;}) \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;#or other attributes, optional\u0026lt;/span\u0026gt;\n    else:\n        \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;print\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;Couldnt locate element\u0026quot;\u0026lt;/span\u0026gt;)\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;P.S. You can find more wait conditions \u0026lt;a href=\u0026quot;http://selenium-python.readthedocs.io/waits.html\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;here\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;Using PyQt5\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; PyQt5.QtWidgets \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; QApplication\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; PyQt5.QtCore \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; QUrl\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; PyQt5.QtWebEngineWidgets \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; QWebEnginePage\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; sys\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; bs4 \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;as\u0026lt;/span\u0026gt; bs\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; urllib.request\n\n\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;class\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title class_\u0026quot;\u0026gt;Client\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-title class_ inherited__\u0026quot;\u0026gt;QWebEnginePage\u0026lt;/span\u0026gt;):\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;__init__\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;self,url\u0026lt;/span\u0026gt;):\n        \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;global\u0026lt;/span\u0026gt; app\n        self.app = QApplication(sys.argv)\n        QWebEnginePage.__init__(self)\n        self.html = \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;\u0026quot;\u0026lt;/span\u0026gt;\n        self.loadFinished.connect(self.on_load_finished)\n        self.load(QUrl(url))\n        self.app.exec_()\n\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;on_load_finished\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;self\u0026lt;/span\u0026gt;):\n        self.html = self.toHtml(self.\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;Callable\u0026lt;/span\u0026gt;)\n        \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;print\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;Load Finished\u0026quot;\u0026lt;/span\u0026gt;)\n\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;Callable\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;self,data\u0026lt;/span\u0026gt;):\n        self.html = data\n        self.app.quit()\n\n\u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# url = \u0026quot;\u0026quot;\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# client_response = Client(url)\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# print(client_response.html)\u0026lt;/span\u0026gt;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n    ","\n\u0026lt;p\u0026gt;You\u0026apos;ll want to use urllib, requests, beautifulSoup and selenium web driver in your script for different parts of the page, (to name a few).\u0026lt;br\u0026gt;\nSometimes you\u0026apos;ll get what you need with just one of these modules.\u0026lt;br\u0026gt;\nSometimes you\u0026apos;ll need two, three, or all of these modules.\u0026lt;br\u0026gt;\nSometimes you\u0026apos;ll need to switch off the js on your browser.\u0026lt;br\u0026gt;\nSometimes you\u0026apos;ll need header info in your script.\u0026lt;br\u0026gt;\nNo websites can be scraped the same way and no website can be scraped in the same way forever without having to modify your crawler, usually after a few months. But they can all be scraped! Where there\u0026apos;s a will there\u0026apos;s a way for sure.\u0026lt;br\u0026gt;\nIf you need scraped data continuously into the future just scrape everything you need and store it in .dat files with pickle.\u0026lt;br\u0026gt;\nJust keep searching how to try what with these modules and copying and pasting your errors into the Google.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;h2\u0026gt;Pyppeteer\u0026lt;/h2\u0026gt;\n\u0026lt;p\u0026gt;You might consider \u0026lt;a href=\u0026quot;https://github.com/pyppeteer/pyppeteer\u0026quot; rel=\u0026quot;nofollow noreferrer\u0026quot;\u0026gt;Pyppeteer\u0026lt;/a\u0026gt;, a Python port of the Chrome/Chromium driver front-end \u0026lt;a href=\u0026quot;https://github.com/puppeteer/puppeteer/\u0026quot; rel=\u0026quot;nofollow noreferrer\u0026quot;\u0026gt;Puppeteer\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;Here\u0026apos;s a simple example to show how you can use Pyppeteer to access data that was injected into the page dynamically:\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; asyncio\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; pyppeteer \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; launch\n\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;async\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;def\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;main\u0026lt;/span\u0026gt;():\n    browser = \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;await\u0026lt;/span\u0026gt; launch({\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;headless\u0026quot;\u0026lt;/span\u0026gt;: \u0026lt;span class=\u0026quot;hljs-literal\u0026quot;\u0026gt;True\u0026lt;/span\u0026gt;})\n    [page] = \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;await\u0026lt;/span\u0026gt; browser.pages()\n\n    \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# normally, you go to a live site...\u0026lt;/span\u0026gt;\n    \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;#await page.goto(\u0026quot;http://www.example.com\u0026quot;)\u0026lt;/span\u0026gt;\n    \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# but for this example, just set the HTML directly:\u0026lt;/span\u0026gt;\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;await\u0026lt;/span\u0026gt; page.setContent(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;\u0026quot;\u0026quot;\n    \u0026amp;lt;body\u0026amp;gt;\n    \u0026amp;lt;script\u0026amp;gt;\n    // inject content dynamically with JS, not part of the static HTML!\n    document.body.innerHTML = `\u0026amp;lt;p\u0026amp;gt;hello world\u0026amp;lt;/p\u0026amp;gt;`; \n    \u0026amp;lt;/script\u0026amp;gt;\n    \u0026amp;lt;/body\u0026amp;gt;\n    \u0026quot;\u0026quot;\u0026quot;\u0026lt;/span\u0026gt;)\n    \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;print\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;await\u0026lt;/span\u0026gt; page.content()) \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# shows that the `\u0026amp;lt;p\u0026amp;gt;` was inserted\u0026lt;/span\u0026gt;\n\n    \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# evaluate a JS expression in browser context and scrape the data\u0026lt;/span\u0026gt;\n    expr = \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;document.querySelector(\u0026apos;p\u0026apos;).textContent\u0026quot;\u0026lt;/span\u0026gt;\n    \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;print\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;await\u0026lt;/span\u0026gt; page.evaluate(expr, force_expr=\u0026lt;span class=\u0026quot;hljs-literal\u0026quot;\u0026gt;True\u0026lt;/span\u0026gt;)) \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# =\u0026amp;gt; hello world\u0026lt;/span\u0026gt;\n\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;await\u0026lt;/span\u0026gt; browser.close()\n\nasyncio.get_event_loop().run_until_complete(main())\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;See \u0026lt;a href=\u0026quot;https://pyppeteer.github.io/pyppeteer/reference.html\u0026quot; rel=\u0026quot;nofollow noreferrer\u0026quot;\u0026gt;Pyppeteer\u0026apos;s reference docs\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;h2\u0026gt;Try accessing the API directly\u0026lt;/h2\u0026gt;\n\u0026lt;p\u0026gt;A common scenario you\u0026apos;ll see in scraping is that the data is being requested asynchronously from an API endpoint by the webpage. A minimal example of this would be the following site:\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;div class=\u0026quot;snippet\u0026quot; data-lang=\u0026quot;js\u0026quot; data-hide=\u0026quot;false\u0026quot; data-console=\u0026quot;true\u0026quot; data-babel=\u0026quot;false\u0026quot;\u0026gt;\n\u0026lt;div class=\u0026quot;snippet-code\u0026quot;\u0026gt;\n\u0026lt;pre class=\u0026quot;snippet-code-html lang-html s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-xml\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-tag\u0026quot;\u0026gt;\u0026amp;lt;\u0026lt;span class=\u0026quot;hljs-name\u0026quot;\u0026gt;body\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-tag\u0026quot;\u0026gt;\u0026amp;lt;\u0026lt;span class=\u0026quot;hljs-name\u0026quot;\u0026gt;script\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;language-javascript\u0026quot;\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;fetch\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;https://jsonplaceholder.typicode.com/posts/1\u0026quot;\u0026lt;/span\u0026gt;)\n  .\u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;then\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-function\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;res\u0026lt;/span\u0026gt; =\u0026amp;gt;\u0026lt;/span\u0026gt; {\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;if\u0026lt;/span\u0026gt; (!res.\u0026lt;span class=\u0026quot;hljs-property\u0026quot;\u0026gt;ok\u0026lt;/span\u0026gt;) \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;throw\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title class_\u0026quot;\u0026gt;Error\u0026lt;/span\u0026gt;(res.\u0026lt;span class=\u0026quot;hljs-property\u0026quot;\u0026gt;status\u0026lt;/span\u0026gt;);\n    \n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;return\u0026lt;/span\u0026gt; res.\u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;json\u0026lt;/span\u0026gt;();\n  })\n  .\u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;then\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-function\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;data\u0026lt;/span\u0026gt; =\u0026amp;gt;\u0026lt;/span\u0026gt; {\n    \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;// inject data dynamically via JS after page load\u0026lt;/span\u0026gt;\n    \u0026lt;span class=\u0026quot;hljs-variable language_\u0026quot;\u0026gt;document\u0026lt;/span\u0026gt;.\u0026lt;span class=\u0026quot;hljs-property\u0026quot;\u0026gt;body\u0026lt;/span\u0026gt;.\u0026lt;span class=\u0026quot;hljs-property\u0026quot;\u0026gt;innerText\u0026lt;/span\u0026gt; = data.\u0026lt;span class=\u0026quot;hljs-property\u0026quot;\u0026gt;title\u0026lt;/span\u0026gt;;\n  })\n  .\u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;catch\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-function\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;err\u0026lt;/span\u0026gt; =\u0026amp;gt;\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-variable language_\u0026quot;\u0026gt;console\u0026lt;/span\u0026gt;.\u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;error\u0026lt;/span\u0026gt;(err))\n;\n\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;hljs-tag\u0026quot;\u0026gt;\u0026amp;lt;/\u0026lt;span class=\u0026quot;hljs-name\u0026quot;\u0026gt;script\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-tag\u0026quot;\u0026gt;\u0026amp;lt;/\u0026lt;span class=\u0026quot;hljs-name\u0026quot;\u0026gt;body\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;div class=\u0026quot;snippet-result\u0026quot;\u0026gt;\u0026lt;div class=\u0026quot;snippet-ctas\u0026quot;\u0026gt;\u0026lt;button type=\u0026quot;button\u0026quot; class=\u0026quot;s-btn s-btn__primary\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;icon-play-white _hover\u0026quot;\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; Run code snippet\u0026lt;/span\u0026gt;\u0026lt;/button\u0026gt;\u0026lt;input class=\u0026quot;copySnippet s-btn s-btn__filled\u0026quot; type=\u0026quot;button\u0026quot; value=\u0026quot;Copy snippet to answer\u0026quot; style=\u0026quot;display: none;\u0026quot;\u0026gt;\u0026lt;button type=\u0026quot;button\u0026quot; class=\u0026quot;s-btn hideResults\u0026quot; style=\u0026quot;display: none;\u0026quot;\u0026gt;Hide results\u0026lt;/button\u0026gt;\u0026lt;div class=\u0026quot;popout-code\u0026quot;\u0026gt;\u0026lt;a class=\u0026quot;snippet-expand-link\u0026quot;\u0026gt;Expand snippet\u0026lt;/a\u0026gt;\u0026lt;/div\u0026gt;\u0026lt;/div\u0026gt;\u0026lt;div class=\u0026quot;snippet-result-code\u0026quot; style=\u0026quot;display: none;\u0026quot;\u0026gt;\u0026lt;iframe name=\u0026quot;sif1\u0026quot; sandbox=\u0026quot;allow-forms allow-modals allow-scripts\u0026quot; class=\u0026quot;snippet-box-edit snippet-box-result\u0026quot; frameborder=\u0026quot;0\u0026quot;\u0026gt;\u0026lt;/iframe\u0026gt;\u0026lt;/div\u0026gt;\u0026lt;/div\u0026gt;\u0026lt;/div\u0026gt;\n\u0026lt;/div\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;In many cases, the API will be protected by CORS or an access token or prohibitively rate limited, but in other cases it\u0026apos;s publicly-accessible and you can bypass the website entirely. For CORS issues, you might try \u0026lt;a href=\u0026quot;https://stackoverflow.com/questions/29670703/how-to-use-cors-anywhere-to-reverse-proxy-and-add-cors-headers\u0026quot;\u0026gt;cors-anywhere\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;The general procedure is to use your browser\u0026apos;s developer tools\u0026apos; network tab to search the requests made by the page for keywords/substrings of the data you want to scrape. Often, you\u0026apos;ll see an unprotected API request endpoint with a JSON payload that you can access directly with \u0026lt;code\u0026gt;urllib\u0026lt;/code\u0026gt; or \u0026lt;code\u0026gt;requests\u0026lt;/code\u0026gt; modules. That\u0026apos;s the case with the above runnable snippet which you can use to practice. After clicking \u0026quot;run snippet\u0026quot;, here\u0026apos;s how I found the endpoint in my network tab:\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;a href=\u0026quot;https://i.stack.imgur.com/EOxkc.png\u0026quot; rel=\u0026quot;nofollow noreferrer\u0026quot;\u0026gt;\u0026lt;img src=\u0026quot;https://i.stack.imgur.com/EOxkc.png\u0026quot; alt=\u0026quot;example network tab showing remote URL endpoint found with a search\u0026quot;\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;This example is contrived; the endpoint URL will likely be non-obvious from looking at the static markup because it could be dynamically assembled, minified and buried under dozens of other requests and endpoints. The network request will also show any relevant request payload details like access token you may need.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;After obtaining the endpoint URL and relevant details, build a request in Python using a standard HTTP library and request the data:\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;\u0026amp;gt;\u0026amp;gt;\u0026amp;gt; \u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; requests\n\u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;\u0026amp;gt;\u0026amp;gt;\u0026amp;gt; \u0026lt;/span\u0026gt;res = requests.get(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;https://jsonplaceholder.typicode.com/posts/1\u0026quot;\u0026lt;/span\u0026gt;)\n\u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;\u0026amp;gt;\u0026amp;gt;\u0026amp;gt; \u0026lt;/span\u0026gt;data = res.json()\n\u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;\u0026amp;gt;\u0026amp;gt;\u0026amp;gt; \u0026lt;/span\u0026gt;data[\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;title\u0026quot;\u0026lt;/span\u0026gt;]\n\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026apos;\u0026lt;/span\u0026gt;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;When you can get away with it, this tends to be much easier, faster and more reliable than scraping the page with Selenium, Pyppeteer, Scrapy or whatever the popular scraping libraries are at the time you\u0026apos;re reading this post.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;If you\u0026apos;re unlucky and the data hasn\u0026apos;t arrived via an API request that returns the data in a nice format, it could be part of the original browser\u0026apos;s payload in a \u0026lt;code\u0026gt;\u0026amp;lt;script\u0026amp;gt;\u0026lt;/code\u0026gt; tag, either as a JSON string or (more likely) a JS object. For example:\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\u0026lt;div class=\u0026quot;snippet\u0026quot; data-lang=\u0026quot;js\u0026quot; data-hide=\u0026quot;false\u0026quot; data-console=\u0026quot;true\u0026quot; data-babel=\u0026quot;false\u0026quot;\u0026gt;\n\u0026lt;div class=\u0026quot;snippet-code\u0026quot;\u0026gt;\n\u0026lt;pre class=\u0026quot;snippet-code-html lang-html s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-xml\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-tag\u0026quot;\u0026gt;\u0026amp;lt;\u0026lt;span class=\u0026quot;hljs-name\u0026quot;\u0026gt;body\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-tag\u0026quot;\u0026gt;\u0026amp;lt;\u0026lt;span class=\u0026quot;hljs-name\u0026quot;\u0026gt;script\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;language-javascript\u0026quot;\u0026gt;\n  \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;var\u0026lt;/span\u0026gt; someHardcodedData = {\n    \u0026lt;span class=\u0026quot;hljs-attr\u0026quot;\u0026gt;userId\u0026lt;/span\u0026gt;: \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;,\n    \u0026lt;span class=\u0026quot;hljs-attr\u0026quot;\u0026gt;id\u0026lt;/span\u0026gt;: \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;,\n    \u0026lt;span class=\u0026quot;hljs-attr\u0026quot;\u0026gt;title\u0026lt;/span\u0026gt;: \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026apos;\u0026lt;/span\u0026gt;, \n    \u0026lt;span class=\u0026quot;hljs-attr\u0026quot;\u0026gt;body\u0026lt;/span\u0026gt;: \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;quia et suscipit\\nsuscipit recusandae con sequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026apos;\u0026lt;/span\u0026gt;\n  };\n  \u0026lt;span class=\u0026quot;hljs-variable language_\u0026quot;\u0026gt;document\u0026lt;/span\u0026gt;.\u0026lt;span class=\u0026quot;hljs-property\u0026quot;\u0026gt;body\u0026lt;/span\u0026gt;.\u0026lt;span class=\u0026quot;hljs-property\u0026quot;\u0026gt;textContent\u0026lt;/span\u0026gt; = someHardcodedData.\u0026lt;span class=\u0026quot;hljs-property\u0026quot;\u0026gt;title\u0026lt;/span\u0026gt;;\n\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;hljs-tag\u0026quot;\u0026gt;\u0026amp;lt;/\u0026lt;span class=\u0026quot;hljs-name\u0026quot;\u0026gt;script\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-tag\u0026quot;\u0026gt;\u0026amp;lt;/\u0026lt;span class=\u0026quot;hljs-name\u0026quot;\u0026gt;body\u0026lt;/span\u0026gt;\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;div class=\u0026quot;snippet-result\u0026quot;\u0026gt;\u0026lt;div class=\u0026quot;snippet-ctas\u0026quot;\u0026gt;\u0026lt;button type=\u0026quot;button\u0026quot; class=\u0026quot;s-btn s-btn__primary\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;icon-play-white _hover\u0026quot;\u0026gt;\u0026lt;/span\u0026gt;\u0026lt;span\u0026gt; Run code snippet\u0026lt;/span\u0026gt;\u0026lt;/button\u0026gt;\u0026lt;input class=\u0026quot;copySnippet s-btn s-btn__filled\u0026quot; type=\u0026quot;button\u0026quot; value=\u0026quot;Copy snippet to answer\u0026quot; style=\u0026quot;display: none;\u0026quot;\u0026gt;\u0026lt;button type=\u0026quot;button\u0026quot; class=\u0026quot;s-btn hideResults\u0026quot; style=\u0026quot;display: none;\u0026quot;\u0026gt;Hide results\u0026lt;/button\u0026gt;\u0026lt;div class=\u0026quot;popout-code\u0026quot;\u0026gt;\u0026lt;a class=\u0026quot;snippet-expand-link\u0026quot;\u0026gt;Expand snippet\u0026lt;/a\u0026gt;\u0026lt;/div\u0026gt;\u0026lt;/div\u0026gt;\u0026lt;div class=\u0026quot;snippet-result-code\u0026quot; style=\u0026quot;display: none;\u0026quot;\u0026gt;\u0026lt;iframe name=\u0026quot;sif2\u0026quot; sandbox=\u0026quot;allow-forms allow-modals allow-scripts\u0026quot; class=\u0026quot;snippet-box-edit snippet-box-result\u0026quot; frameborder=\u0026quot;0\u0026quot;\u0026gt;\u0026lt;/iframe\u0026gt;\u0026lt;/div\u0026gt;\u0026lt;/div\u0026gt;\u0026lt;/div\u0026gt;\n\u0026lt;/div\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;There\u0026apos;s no one-size-fits-all way to obtain this data. The basic technique is to use BeautifulSoup to access the \u0026lt;code\u0026gt;\u0026amp;lt;script\u0026amp;gt;\u0026lt;/code\u0026gt; tag text, then apply a regex or a parse to extract the object structure, JSON string, or whatever format the data might be in. Here\u0026apos;s a proof-of-concept on the sample structure shown above:\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; json\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; re\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; bs4 \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; BeautifulSoup\n\n\u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# pretend we\u0026apos;ve already used requests to retrieve the data, \u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;# so we hardcode it for the purposes of this example\u0026lt;/span\u0026gt;\ntext = \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;\u0026quot;\u0026quot;\n\u0026amp;lt;body\u0026amp;gt;\n\u0026amp;lt;script\u0026amp;gt;\n  var someHardcodedData = {\n    userId: 1,\n    id: 1,\n    title: \u0026apos;sunt aut facere repellat provident occaecati excepturi optio reprehenderit\u0026apos;, \n    body: \u0026apos;quia et suscipit\\nsuscipit recusandae con sequuntur expedita et cum\\nreprehenderit molestiae ut ut quas totam\\nnostrum rerum est autem sunt rem eveniet architecto\u0026apos;\n  };\n  document.body.textContent = someHardcodedData.title;\n\u0026amp;lt;/script\u0026amp;gt;\n\u0026amp;lt;/body\u0026amp;gt;\n\u0026quot;\u0026quot;\u0026quot;\u0026lt;/span\u0026gt;\nsoup = BeautifulSoup(text, \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;lxml\u0026quot;\u0026lt;/span\u0026gt;)\nscript_text = \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;str\u0026lt;/span\u0026gt;(soup.select_one(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;script\u0026quot;\u0026lt;/span\u0026gt;))\npattern = \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;r\u0026quot;title: \u0026apos;(.*?)\u0026apos;\u0026quot;\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;print\u0026lt;/span\u0026gt;(re.search(pattern, script_text, re.S).group(\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;))\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;Check out these resources for parsing JS objects that aren\u0026apos;t quite valid JSON:\u0026lt;/p\u0026gt;\n\u0026lt;ul\u0026gt;\n\u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;https://stackoverflow.com/questions/24027589/how-to-convert-raw-javascript-object-to-python-dictionary\u0026quot;\u0026gt;How to convert raw javascript object to python dictionary?\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;https://stackoverflow.com/questions/50947760/how-to-fix-json-key-values-without-double-quotes\u0026quot;\u0026gt;How to Fix JSON Key Values without double-quotes?\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\n\u0026lt;/ul\u0026gt;\n\u0026lt;p\u0026gt;Here are some additional case studies/proofs-of-concept where scraping was bypassed using an API:\u0026lt;/p\u0026gt;\n\u0026lt;ul\u0026gt;\n\u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;https://stackoverflow.com/questions/69801378/how-can-i-scrape-yelp-reviews-and-star-ratings-into-csv-using-python-beautifulso?noredirect=1#comment123391238_69801378\u0026quot;\u0026gt;How can I scrape yelp reviews and star ratings into CSV using Python beautifulsoup\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;https://stackoverflow.com/a/59378253/6243352\u0026quot;\u0026gt;Beautiful Soup returns None on existing element\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;https://stackoverflow.com/a/65905956/6243352\u0026quot;\u0026gt;Extract data from  BeautifulSoup Python\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;https://stackoverflow.com/a/64419449/6243352\u0026quot;\u0026gt;Scraping Bandcamp fan collections via POST\u0026lt;/a\u0026gt; (uses a hybrid approach where an initial request was made to the website to extract a token from the markup using BeautifulSoup which was then used in a second request to a JSON endpoint)\u0026lt;/li\u0026gt;\n\u0026lt;/ul\u0026gt;\n\u0026lt;p\u0026gt;If all else fails, try one of the many dynamic scraping libraries listed in this thread.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;As mentioned, Selenium is a good choice for rendering the results of the JavaScript:\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; selenium.webdriver \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; Firefox\n\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; selenium.webdriver.firefox.options \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; Options\n\noptions = Options()\noptions.headless = \u0026lt;span class=\u0026quot;hljs-literal\u0026quot;\u0026gt;True\u0026lt;/span\u0026gt;\nbrowser = Firefox(executable_path=\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;/usr/local/bin/geckodriver\u0026quot;\u0026lt;/span\u0026gt;, options=options)\n\nurl = \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;https://www.example.com\u0026quot;\u0026lt;/span\u0026gt;\nbrowser.get(url)\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;And \u0026lt;a href=\u0026quot;https://github.com/maxhumber/gazpacho\u0026quot; rel=\u0026quot;nofollow noreferrer\u0026quot;\u0026gt;gazpacho\u0026lt;/a\u0026gt; is a really easy library to parse over the rendered html:\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-py s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-python\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; gazpacho \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; Soup\n\nsoup = Soup(browser.page_source)\nsoup.find(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;a\u0026quot;\u0026lt;/span\u0026gt;).attrs[\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;href\u0026apos;\u0026lt;/span\u0026gt;]\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n    ","\n\u0026lt;p\u0026gt;I recently used requests_html library to solve this problem.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;Their \u0026lt;a href=\u0026quot;https://requests.readthedocs.io/projects/requests-html/en/latest/\u0026quot; rel=\u0026quot;nofollow noreferrer\u0026quot;\u0026gt;expanded documentation\u0026lt;/a\u0026gt; at readthedocs.io is pretty good (skip the annotated version at pypi.org). If your use case is basic, you are likely to have some success.\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-coffeescript\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; requests_html \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;import\u0026lt;/span\u0026gt; HTMLSession\nsession = HTMLSession()\nresponse = session.request(method=\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;get\u0026quot;\u0026lt;/span\u0026gt;,url=\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;www.google.com/\u0026quot;\u0026lt;/span\u0026gt;)\nresponse.html.render()\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;If you are having trouble rendering the data you need with response.html.render(), you can pass some javascript to the render function to render the particular js object you need. This is copied from their docs, but it might be just what you need:\u0026lt;/p\u0026gt;\n\u0026lt;blockquote\u0026gt;\n\u0026lt;p\u0026gt;If script is specified, it will execute the provided JavaScript at\nruntime. Example:\u0026lt;/p\u0026gt;\n\u0026lt;/blockquote\u0026gt;\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-ini\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-attr\u0026quot;\u0026gt;script\u0026lt;/span\u0026gt; = \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;\u0026quot;\u0026quot;\n    () =\u0026amp;gt; {\n        return {\n            width: document.documentElement.clientWidth,\n            height: document.documentElement.clientHeight,\n            deviceScaleFactor: window.devicePixelRatio,\n        }\n    } \n\u0026quot;\u0026quot;\u0026quot;\u0026lt;/span\u0026gt;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;blockquote\u0026gt;\n\u0026lt;p\u0026gt;Returns the return value of the executed script, if any is provided:\u0026lt;/p\u0026gt;\n\u0026lt;/blockquote\u0026gt;\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-javascript\u0026quot;\u0026gt;\u0026amp;gt;\u0026amp;gt;\u0026amp;gt; response.\u0026lt;span class=\u0026quot;hljs-property\u0026quot;\u0026gt;html\u0026lt;/span\u0026gt;.\u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;render\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;script=script\u0026lt;/span\u0026gt;)\n{\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;width\u0026apos;\u0026lt;/span\u0026gt;: \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;800\u0026lt;/span\u0026gt;, \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;height\u0026apos;\u0026lt;/span\u0026gt;: \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;600\u0026lt;/span\u0026gt;, \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026apos;deviceScaleFactor\u0026apos;\u0026lt;/span\u0026gt;: \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;In my case, the data I wanted were the arrays that populated a javascript plot but the data wasn\u0026apos;t getting rendered as text anywhere in the html. Sometimes its not clear at all what the object names are of the data you want if the data is populated dynamically. If you can\u0026apos;t track down the js objects directly from view source or inspect, you can type in \u0026quot;window\u0026quot; followed by ENTER in the debugger console in the browser (Chrome) to pull up a full list of objects rendered by the browser. If you make a few educated guesses about where the data is stored, you might have some luck finding it there. My graph data was under window.view.data in the console, so in the \u0026quot;script\u0026quot; variable passed to the .render() method quoted above, I used:\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-kotlin\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;return\u0026lt;/span\u0026gt; {\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;data\u0026lt;/span\u0026gt;: window.view.\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;data\u0026lt;/span\u0026gt;\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n    ","\n\u0026lt;h2\u0026gt;Playwright-Python\u0026lt;/h2\u0026gt;\n\u0026lt;p\u0026gt;Yet another option is \u0026lt;a href=\u0026quot;https://github.com/microsoft/playwright-python\u0026quot; rel=\u0026quot;nofollow noreferrer\u0026quot;\u0026gt;\u0026lt;code\u0026gt;playwright-python\u0026lt;/code\u0026gt;\u0026lt;/a\u0026gt;, a port of Microsoft\u0026apos;s Playwright (itself a Puppeteer-influenced browser automation library) to Python.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;Here\u0026apos;s the minimal example of selecting an element and grabbing its text:\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-css\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-selector-tag\u0026quot;\u0026gt;from\u0026lt;/span\u0026gt; playwright\u0026lt;span class=\u0026quot;hljs-selector-class\u0026quot;\u0026gt;.sync_api\u0026lt;/span\u0026gt; import sync_playwright\n\nwith sync_playwright() as \u0026lt;span class=\u0026quot;hljs-selector-tag\u0026quot;\u0026gt;p\u0026lt;/span\u0026gt;:\n    browser = p.chromium.\u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;launch\u0026lt;/span\u0026gt;()\n    page = browser.\u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;new_page\u0026lt;/span\u0026gt;()\n    page.\u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;goto\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;http://whatsmyuseragent.org/\u0026quot;\u0026lt;/span\u0026gt;)\n    ua = page.\u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;query_selector\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;.user-agent\u0026quot;\u0026lt;/span\u0026gt;);\n    print(ua\u0026lt;span class=\u0026quot;hljs-selector-class\u0026quot;\u0026gt;.text_content\u0026lt;/span\u0026gt;())\n    browser\u0026lt;span class=\u0026quot;hljs-selector-class\u0026quot;\u0026gt;.close\u0026lt;/span\u0026gt;()\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n    ","\n\u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;Easy and Quick Solution:\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;I was dealing with same problem. I want to scrape some data which is build with JavaScript. If I scrape only text from this site with BeautifulSoup then I ended with  tags in text.\nI want to render this  tag and wills to grab information from this.\nAlso, I dont want to use heavy frameworks  like Scrapy and selenium.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;So, I found that \u0026lt;strong\u0026gt;get\u0026lt;/strong\u0026gt; method of requests \u0026lt;strong\u0026gt;module\u0026lt;/strong\u0026gt; takes urls, and it actually renders the script tag.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;Example:\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-makefile\u0026quot;\u0026gt;import requests\ncustom_User_agent = \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:47.0) Gecko/20100101 Firefox/47.0\u0026quot;\u0026lt;/span\u0026gt;\nurl = \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;https://www.abc.xyz/your/url\u0026quot;\u0026lt;/span\u0026gt;\nresponse = requests.get(url, headers={\u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;User-Agent\u0026quot;\u0026lt;/span\u0026gt;: custom_User_agent})\nhtml_text = response.text\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;This will renders load site and renders  tags.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;Hope this will help as quick and easy solution to render site which is loaded with script tags.\u0026lt;/p\u0026gt;\n    "],"id":512,"title":"Web-scraping JavaScript page with Python","content":"\n                \n\u0026lt;p\u0026gt;I\u0026apos;m trying to develop a simple web scraper. I want to extract text without the HTML code. It works on plain HTML, but not in some pages where JavaScript code adds text.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;For example, if some JavaScript code adds some text, I can\u0026apos;t see it, because when I call:\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;default s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-ini\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-attr\u0026quot;\u0026gt;response\u0026lt;/span\u0026gt; = urllib2.urlopen(request)\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;I get the original text without the added one (because JavaScript is executed in the client).\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;So, I\u0026apos;m looking for some ideas to solve this problem.\u0026lt;/p\u0026gt;\n    ","slug":"web-scraping-javascript-page-with-python-1657388240875","postType":"QUESTION","createdAt":"2022-07-09T17:37:20.000Z","updatedAt":"2022-07-09T17:37:20.000Z","tags":[{"id":2541,"name":"python-2.x","slug":"python-2.x","createdAt":"2022-07-09T17:37:20.000Z","updatedAt":"2022-07-09T17:37:20.000Z","Questions_Tags":{"questionId":512,"tagId":2541}}],"relatedQuestions":[{"title":"Web-scraping JavaScript page with Python","slug":"web-scraping-javascript-page-with-python-1657388240875","tags":[{"name":"python-2.x","Questions_Tags":{"questionId":512,"tagId":2541}}]}]},"randomQuestions":[{"title":"How to filter Pandas dataframe using 'in' and 'not in' like in SQL","slug":"how-to-filter-pandas-dataframe-using-'in'-and-'not-in'-like-in-sql-1657387371355"},{"title":"Remove duplicate values from JS array [duplicate]","slug":"remove-duplicate-values-from-js-array-duplicate-1657387801931"},{"title":"What is the difference between JSON and Object Literal Notation?","slug":"what-is-the-difference-between-json-and-object-literal-notation-1657387515710"},{"title":"How do I set, clear, and toggle a single bit?","slug":"how-do-i-set-clear-and-toggle-a-single-bit-1657388227052"},{"title":"What does enctype='multipart/form-data' mean?","slug":"what-does-enctype'multipartform-data'-mean-1657388229352"},{"title":"How to access the correct `this` inside a callback","slug":"how-to-access-the-correct-this-inside-a-callback-1657384283261"},{"title":"How can I convert ereg expressions to preg in PHP?","slug":"how-can-i-convert-ereg-expressions-to-preg-in-php-1657387652855"},{"title":"Reference: mod_rewrite, URL rewriting and \"pretty links\" explained","slug":"reference:-mod_rewrite-url-rewriting-and-\"pretty-links\"-explained-1657384905504"},{"title":"Is it possible to escape regex metacharacters reliably with sed","slug":"is-it-possible-to-escape-regex-metacharacters-reliably-with-sed-1657388428795"},{"title":"How to reshape data from long to wide format","slug":"how-to-reshape-data-from-long-to-wide-format-1657384486421"},{"title":"How do I clone a list so that it doesn't change unexpectedly after assignment?","slug":"how-do-i-clone-a-list-so-that-it-doesn't-change-unexpectedly-after-assignment-1657384423195"},{"title":"Iterator invalidation rules for C++ containers","slug":"iterator-invalidation-rules-for-c++-containers-1657387561090"},{"title":"Calling a function of a module by using its name (a string)","slug":"calling-a-function-of-a-module-by-using-its-name-(a-string)-1657388565656"},{"title":"Why does my recursive function return None?","slug":"why-does-my-recursive-function-return-none-1657387792894"},{"title":"Captured variable in a loop in C#","slug":"captured-variable-in-a-loop-in-c-1657387696779"},{"title":"How do you access the matched groups in a JavaScript regular expression?","slug":"how-do-you-access-the-matched-groups-in-a-javascript-regular-expression-1657388233817"},{"title":"Does Python have a ternary conditional operator?","slug":"does-python-have-a-ternary-conditional-operator-1657387555448"},{"title":"Dynamic tabs with user-click chosen components","slug":"dynamic-tabs-with-user-click-chosen-components-1657388465232"},{"title":"What is the difference between const int*, const int * const, and int const *?","slug":"what-is-the-difference-between-const-int*-const-int-*-const-and-int-const-*-1657388184604"},{"title":"Make container shrink-to-fit child elements as they wrap","slug":"make-container-shrink-to-fit-child-elements-as-they-wrap-1657388134549"}]},"__N_SSG":true},"page":"/questions/[slug]","query":{"slug":"web-scraping-javascript-page-with-python-1657388240875"},"buildId":"Zo3C7AOWQzKM9qqyzx2hf","isFallback":false,"gsp":true,"locale":"en","locales":["en"],"defaultLocale":"en","scriptLoader":[]}</script></body></html>