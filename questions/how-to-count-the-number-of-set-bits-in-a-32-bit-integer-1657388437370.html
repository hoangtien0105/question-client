<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><meta name="next-head-count" content="2"/><link rel="preload" href="/_next/static/css/2eccd4d47c856f2b.css" as="style"/><link rel="stylesheet" href="/_next/static/css/2eccd4d47c856f2b.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-0d1b80a048d4787e.js"></script><script src="/_next/static/chunks/webpack-cb7634a8b6194820.js" defer=""></script><script src="/_next/static/chunks/framework-4556c45dd113b893.js" defer=""></script><script src="/_next/static/chunks/main-25e5079ab4bd6ecd.js" defer=""></script><script src="/_next/static/chunks/pages/_app-20edbe0b078add93.js" defer=""></script><script src="/_next/static/chunks/29107295-fbcfe2172188e46f.js" defer=""></script><script src="/_next/static/chunks/613-1e0aa2b2023820bb.js" defer=""></script><script src="/_next/static/chunks/495-bb1d5b202c02d7f2.js" defer=""></script><script src="/_next/static/chunks/471-84c36aa98dd4107c.js" defer=""></script><script src="/_next/static/chunks/81-301f760ac8107464.js" defer=""></script><script src="/_next/static/chunks/pages/questions/%5Bslug%5D-76d2c3e2d98bb08b.js" defer=""></script><script src="/_next/static/8pZkyd0U8-Y2Qf3QK9j7l/_buildManifest.js" defer=""></script><script src="/_next/static/8pZkyd0U8-Y2Qf3QK9j7l/_ssgManifest.js" defer=""></script><style data-styled="" data-styled-version="5.3.5">.eZIPKL code{padding:5px;color:hsl(210deg 8% 15%);background-color:hsl(210deg 8% 90%);border-radius:3px;}/*!sc*/
data-styled.g5[id="sc-c4b0431a-0"]{content:"eZIPKL,"}/*!sc*/
</style></head><body><div id="__next"><div class="sc-9099c029-0 cIPEih"><header><nav class="bg-white border-gray-200 px-4 lg:px-6 py-2.5 dark:bg-gray-800"><div class="flex flex-wrap justify-between items-center mx-auto max-w-screen-xl"><a class="flex items-center" href="/"><img src="https://flowbite.com/docs/images/logo.svg" class="mr-3 h-6 sm:h-9" alt="Flowbite Logo"/><span class="self-center text-xl font-semibold whitespace-nowrap dark:text-white">Solution Hunter</span></a><div class="flex items-center lg:order-2"><button data-collapse-toggle="mobile-menu-2" type="button" class="inline-flex items-center p-2 ml-1 text-sm text-gray-500 rounded-lg lg:hidden hover:bg-gray-100 focus:outline-none focus:ring-2 focus:ring-gray-200 dark:text-gray-400 dark:hover:bg-gray-700 dark:focus:ring-gray-600" aria-controls="mobile-menu-2" aria-expanded="false"><span class="sr-only">Open main menu</span><svg class="w-6 h-6" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M3 5a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 10a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 15a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1z" clip-rule="evenodd"></path></svg><svg class="hidden w-6 h-6" fill="currentColor" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><path fill-rule="evenodd" d="M4.293 4.293a1 1 0 011.414 0L10 8.586l4.293-4.293a1 1 0 111.414 1.414L11.414 10l4.293 4.293a1 1 0 01-1.414 1.414L10 11.414l-4.293 4.293a1 1 0 01-1.414-1.414L8.586 10 4.293 5.707a1 1 0 010-1.414z" clip-rule="evenodd"></path></svg></button></div><div class="hidden justify-between items-center w-full lg:flex lg:w-auto lg:order-1" id="mobile-menu-2"><ul class="flex flex-col mt-4 font-medium lg:flex-row lg:space-x-8 lg:mt-0"><li><a class="block py-2 pr-4 pl-3 text-gray-700 border-b border-gray-100 hover:bg-gray-50 lg:hover:bg-transparent lg:border-0 lg:hover:text-blue-700 lg:p-0 dark:text-gray-400 lg:dark:hover:text-white dark:hover:bg-gray-700 dark:hover:text-white lg:dark:hover:bg-transparent dark:border-gray-700" aria-current="page" href="/">Home</a></li><li><a class="block py-2 pr-4 pl-3 text-gray-700 border-b border-gray-100 hover:bg-gray-50 lg:hover:bg-transparent lg:border-0 lg:hover:text-blue-700 lg:p-0 dark:text-gray-400 lg:dark:hover:text-white dark:hover:bg-gray-700 dark:hover:text-white lg:dark:hover:bg-transparent dark:border-gray-700" href="/questions?tab=news">Questions</a></li><li><a class="block py-2 pr-4 pl-3 text-gray-700 border-b border-gray-100 hover:bg-gray-50 lg:hover:bg-transparent lg:border-0 lg:hover:text-blue-700 lg:p-0 dark:text-gray-400 lg:dark:hover:text-white dark:hover:bg-gray-700 dark:hover:text-white lg:dark:hover:bg-transparent dark:border-gray-700" href="/post?tab=news">Post</a></li><li><a class="block py-2 pr-4 pl-3 text-gray-700 border-b border-gray-100 hover:bg-gray-50 lg:hover:bg-transparent lg:border-0 lg:hover:text-blue-700 lg:p-0 dark:text-gray-400 lg:dark:hover:text-white dark:hover:bg-gray-700 dark:hover:text-white lg:dark:hover:bg-transparent dark:border-gray-700" href="/questions/how-to-count-the-number-of-set-bits-in-a-32-bit-integer-1657388437370#">Coding</a></li></ul></div></div></nav></header><div class="main-content"><div class="sc-c5440139-0 figLul question my-5"><div class="sc-c4b0431a-0 eZIPKL flex question-header items-center justify-center"><div class="rounded-xl border p-5 shadow-md w-9/12 bg-white"><div class="flex w-full items-center justify-between border-b pb-3"><div class="flex items-center space-x-3"><div class="text-lg font-bold text-slate-700"><a href="/questions/how-to-count-the-number-of-set-bits-in-a-32-bit-integer-1657388437370">How to count the number of set bits in a 32-bit integer?</a></div></div><div class="flex flex-wrap h-auto justify-end items-center space-x-8"><a class="rounded-2xl border bg-neutral-100 px-3 py-1 text-sm font-semibold" href="/questions/tag/binary">binary</a><a class="rounded-2xl border bg-neutral-100 px-3 py-1 text-sm font-semibold" href="/questions/tag/hammingweight">hammingweight</a><a class="rounded-2xl border bg-neutral-100 px-3 py-1 text-sm font-semibold" href="/questions/tag/iec10967">iec10967</a></div></div><div class="question-content mt-5">
                
<p>8 bits representing the number 7 look like this:</p>

<pre><code>00000111
</code></pre>

<p>Three bits are set.   </p>

<p>What are algorithms to determine the number of set bits in a 32-bit integer?</p>
    </div></div></div><div class="sc-c4b0431a-2 cRqwQe"><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 1</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>This is known as the '<a href="https://en.wikipedia.org/wiki/Hamming_weight" rel="noreferrer">Hamming Weight</a>', 'popcount' or 'sideways addition'.</p>
<p>Some CPUs have a single built-in instruction to do it and others have parallel instructions which act on bit vectors.  Instructions like x86's <a href="https://www.felixcloutier.com/x86/popcnt" rel="noreferrer"><code>popcnt</code></a> (on CPUs where it's supported) will almost certainly be fastest for a single integer.  Some other architectures may have a slow instruction implemented with a microcoded loop that tests a bit per cycle (<em>citation needed</em> - hardware popcount is normally fast if it exists at all.).</p>
<p>The 'best' algorithm really depends on which CPU you are on and what your usage pattern is.</p>
<p>Your compiler may know how to do something that's good for the specific CPU you're compiling for, e.g. <a href="https://en.cppreference.com/w/cpp/numeric/popcount" rel="noreferrer">C++20 <code>std::popcount()</code></a>, or C++ <a href="https://en.cppreference.com/w/cpp/utility/bitset/count" rel="noreferrer"><code>std::bitset&lt;32&gt;::count()</code></a>, as a portable way to access builtin / intrinsic functions (see <a href="https://stackoverflow.com/questions/109023/how-to-count-the-number-of-set-bits-in-a-32-bit-integer/109069#109069">another answer</a> on this question).  But your compiler's choice of fallback for target CPUs that don't have hardware popcnt might not be optimal for your use-case.  Or your language (e.g. C) might not expose any portable function that could use a CPU-specific popcount when there is one.</p>
<hr>
<h3>Portable algorithms that don't need (or benefit from) any HW support</h3>
<p>A pre-populated table lookup method can be very fast if your CPU has a large cache and you are doing lots of these operations in a tight loop. However it can suffer because of the expense of a 'cache miss', where the CPU has to fetch some of the table from main memory.  (Look up each byte separately to keep the table small.)  If you want popcount for a contiguous range of numbers, only the low byte is changing for groups of 256 numbers, <a href="https://stackoverflow.com/questions/66520106/count-integers-in-1-n-with-k-zero-bits-below-the-leading-1-popcount-for-a-c/66532113#66532113">making this very good</a>.</p>
<p>If you know that your bytes will be mostly 0's or mostly 1's then there are efficient algorithms for these scenarios, e.g. clearing the lowest set with a bithack in a loop until it becomes zero.</p>
<p>I believe a very good general purpose algorithm is the following, known as 'parallel' or 'variable-precision SWAR algorithm'. I have expressed this in a C-like pseudo language, you may need to adjust it to work for a particular language (e.g. using uint32_t for C++ and &gt;&gt;&gt; in Java):</p>
<p>GCC10 and clang 10.0 can recognize this pattern / idiom and compile it to a hardware popcnt or equivalent instruction when available, giving you the best of both worlds. (<a href="https://godbolt.org/z/qGdh1dvKK" rel="noreferrer">https://godbolt.org/z/qGdh1dvKK</a>)</p>
<pre class="lang-c s-code-block"><code class="hljs language-c"><span class="hljs-type">int</span> <span class="hljs-title function_">numberOfSetBits</span><span class="hljs-params">(<span class="hljs-type">uint32_t</span> i)</span>
{
     <span class="hljs-comment">// Java: use int, and use &gt;&gt;&gt; instead of &gt;&gt;. Or use Integer.bitCount()</span>
     <span class="hljs-comment">// C or C++: use uint32_t</span>
     i = i - ((i &gt;&gt; <span class="hljs-number">1</span>) &amp; <span class="hljs-number">0x55555555</span>);        <span class="hljs-comment">// add pairs of bits</span>
     i = (i &amp; <span class="hljs-number">0x33333333</span>) + ((i &gt;&gt; <span class="hljs-number">2</span>) &amp; <span class="hljs-number">0x33333333</span>);  <span class="hljs-comment">// quads</span>
     i = (i + (i &gt;&gt; <span class="hljs-number">4</span>)) &amp; <span class="hljs-number">0x0F0F0F0F</span>;        <span class="hljs-comment">// groups of 8</span>
     <span class="hljs-keyword">return</span> (i * <span class="hljs-number">0x01010101</span>) &gt;&gt; <span class="hljs-number">24</span>;          <span class="hljs-comment">// horizontal sum of bytes</span>
}
</code></pre>
<p>For JavaScript: <a href="https://stackoverflow.com/questions/109023/how-to-count-the-number-of-set-bits-in-a-32-bit-integer/109025#comment103845611_109025">coerce to integer</a> with <code>|0</code> for performance: change the first line to <code>i = (i|0) - ((i &gt;&gt; 1) &amp; 0x55555555);</code></p>
<p>This has the best worst-case behaviour of any of the algorithms discussed, so will efficiently deal with any usage pattern or values you throw at it.  (Its performance is not data-dependent on normal CPUs where all integer operations including multiply are constant-time.  It doesn't get any faster with "simple" inputs, but it's still pretty decent.)</p>
<p>References:</p>
<ul>
<li><a href="https://graphics.stanford.edu/%7Eseander/bithacks.html#CountBitsSetParallel" rel="noreferrer">https://graphics.stanford.edu/~seander/bithacks.html</a></li>
<li><a href="https://en.wikipedia.org/wiki/Hamming_weight" rel="noreferrer">https://en.wikipedia.org/wiki/Hamming_weight</a></li>
<li><a href="http://gurmeet.net/puzzles/fast-bit-counting-routines/" rel="noreferrer">http://gurmeet.net/puzzles/fast-bit-counting-routines/</a></li>
<li><a href="http://aggregate.ee.engr.uky.edu/MAGIC/#Population%20Count%20(Ones%20Count)" rel="noreferrer">http://aggregate.ee.engr.uky.edu/MAGIC/#Population%20Count%20(Ones%20Count)</a></li>
</ul>
<hr>
<h3>How this SWAR bithack works:</h3>
<pre><code>i = i - ((i &gt;&gt; 1) &amp; 0x55555555);
</code></pre>
<p>The first step is an optimized version of masking to isolate the odd / even bits, shifting to line them up, and adding.  This effectively does 16 separate additions in 2-bit accumulators (<a href="https://en.wikipedia.org/wiki/SWAR" rel="noreferrer">SWAR = SIMD Within A Register</a>).  Like <code>(i &amp; 0x55555555) + ((i&gt;&gt;1) &amp; 0x55555555)</code>.</p>
<p>The next step takes the odd/even eight of those 16x 2-bit accumulators and adds again, producing 8x 4-bit sums.  The <code>i - ...</code> optimization isn't possible this time so it does just mask before / after shifting.  Using the same <code>0x33...</code> constant both times instead of <code>0xccc...</code> before shifting is a good thing when compiling for ISAs that need to construct 32-bit constants in registers separately.</p>
<p>The final shift-and-add step of <code>(i + (i &gt;&gt; 4)) &amp; 0x0F0F0F0F</code> widens to 4x 8-bit accumulators.  It masks <em>after</em> adding instead of before, because the maximum value in any 4-bit accumulator is <code>4</code>, if all 4 bits of the corresponding input bits were set.  4+4 = 8 which still fits in 4 bits, so carry between nibble elements is impossible in <code>i + (i &gt;&gt; 4)</code>.</p>
<p>So far this is just fairly normal SIMD using SWAR techniques with a few clever optimizations.  Continuing on with the same pattern for 2 more steps can widen to 2x 16-bit then 1x 32-bit counts.  But there is a more efficient way on machines with fast hardware multiply:</p>
<p>Once we have few enough "elements", <strong>a multiply with a magic constant can sum all the elements into the top element</strong>.  In this case byte elements.  Multiply is done by left-shifting and adding, so <strong>a multiply of <code>x * 0x01010101</code> results in <code>x + (x&lt;&lt;8) + (x&lt;&lt;16) + (x&lt;&lt;24)</code>.</strong>  Our 8-bit elements are wide enough (and holding small enough counts) that this doesn't produce carry <em>into</em> that top 8 bits.</p>
<p><strong>A 64-bit version of this</strong> can do 8x 8-bit elements in a 64-bit integer with a 0x0101010101010101 multiplier, and extract the high byte with <code>&gt;&gt;56</code>.  So it doesn't take any extra steps, just wider constants.  This is what GCC uses for <code>__builtin_popcountll</code> on x86 systems when the hardware <code>popcnt</code> instruction isn't enabled.  If you can use builtins or intrinsics for this, do so to give the compiler a chance to do target-specific optimizations.</p>
<hr>
<h3>With full SIMD for wider vectors (e.g. counting a whole array)</h3>
<p>This bitwise-SWAR algorithm could parallelize to be done in multiple vector elements at once, instead of in a single integer register, for a speedup on CPUs with SIMD but no usable popcount instruction.  (e.g. x86-64 code that has to run on any CPU, not just Nehalem or later.)</p>
<p>However, the best way to use vector instructions for popcount is usually by using a variable-shuffle to do a table-lookup for 4 bits at a time of each byte in parallel.  (The 4 bits index a 16 entry table held in a vector register).</p>
<p>On Intel CPUs, the hardware 64bit popcnt instruction can outperform an <a href="http://wm.ite.pl/articles/sse-popcount.html" rel="noreferrer">SSSE3 <code>PSHUFB</code> bit-parallel implementation</a> by about a factor of 2, but only <a href="http://danluu.com/assembly-intrinsics/" rel="noreferrer">if your compiler gets it just right</a>.  Otherwise SSE can come out significantly ahead.  Newer compiler versions are aware of the <a href="https://stackoverflow.com/a/25089720/224132">popcnt false dependency</a> <a href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=62011" rel="noreferrer">problem on Intel</a>.</p>
<ul>
<li><a href="https://github.com/WojciechMula/sse-popcount" rel="noreferrer">https://github.com/WojciechMula/sse-popcount</a> state-of-the-art x86 SIMD popcount for SSSE3, AVX2, AVX512BW, AVX512VBMI, or AVX512 VPOPCNT.  Using Harley-Seal across vectors to defer popcount within an element.  (Also ARM NEON)</li>
<li><a href="https://stackoverflow.com/questions/50081465/counting-1-bits-population-count-on-large-data-using-avx-512-or-avx-2">Counting 1 bits (population count) on large data using AVX-512 or AVX-2</a></li>
<li>related: <a href="https://github.com/mklarqvist/positional-popcount" rel="noreferrer">https://github.com/mklarqvist/positional-popcount</a> - separate counts for each bit-position of multiple 8, 16, 32, or 64-bit integers.  (Again, x86 SIMD including AVX-512 which is really good at this, with <code>vpternlogd</code> making Harley-Seal <em>very</em> good.)</li>
</ul>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 2</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>Some languages portably expose the operation in a way that <em>can</em> use efficient hardware support if available, otherwise some library fallback that's hopefully decent.</p>
<p>For example (from <a href="https://en.wikichip.org/wiki/population_count#Software_support" rel="noreferrer">a table by language</a>):</p>
<ul>
<li>C++ has <code>std::bitset&lt;&gt;::count()</code>, or  <a href="https://en.cppreference.com/w/cpp/numeric/popcount" rel="noreferrer">C++20 <code>std::popcount(T x)</code></a></li>
<li>Java has <code>java.lang.Integer.bitCount()</code> (also for Long or BigInteger)</li>
<li>C# has <code>System.Numerics.BitOperations.PopCount()</code></li>
<li>Python has <code>int.bit_count()</code> (since 3.10)</li>
</ul>
<p>Not all compilers / libraries actually manage to use HW support when it's available, though. (Notably MSVC, even with options that make std::popcount inline as x86 popcnt, its std::bitset::count still always uses a lookup table.  This will hopefully change in future versions.)</p>
<p>Also consider the built-in functions of your compiler when the portable language doesn't have this basic bit operation.  In GNU C for example:</p>

<pre class="lang-c++ s-code-block"><code class="hljs language-c"><span class="hljs-type">int</span> __builtin_popcount (<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> x);
<span class="hljs-type">int</span> __builtin_popcountll (<span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> <span class="hljs-type">long</span> x);
</code></pre>
<p>In the worst case (no single-instruction HW support) the compiler will generate a call to a function (which in current GCC uses a shift/and bit-hack <a href="https://stackoverflow.com/questions/109023/how-to-count-the-number-of-set-bits-in-a-32-bit-integer/109025#109025">like this answer</a>, at least for x86). In the best case the compiler will emit a cpu instruction to do the job. (Just like a <code>*</code> or <code>/</code> operator - GCC will use a hardware multiply or divide instruction if available, otherwise will call a libgcc helper function.)  Or even better, if the operand is a compile-time constant after inlining, it can do constant-propagation to get a compile-time-constant popcount result.</p>
<p>The GCC builtins even work across multiple platforms. Popcount has almost become mainstream in the x86 architecture, so it makes sense to start using the builtin now so you can recompile to let it inline a hardware instruction when you compile with <code>-mpopcnt</code> or something that includes that (e.g. <a href="https://godbolt.org/z/Ma5e5a" rel="noreferrer">https://godbolt.org/z/Ma5e5a</a>). Other architectures have had popcount for years, but in the x86 world there are still some ancient Core 2 and similar vintage AMD CPUs in use.</p>
<hr>
<p>On x86, you can tell the compiler that it can assume support for <code>popcnt</code> instruction with <code>-mpopcnt</code> (also implied by <code>-msse4.2</code>).  See <a href="https://gcc.gnu.org/onlinedocs/gcc/x86-Options.html" rel="noreferrer">GCC x86 options</a>.  <code>-march=nehalem -mtune=skylake</code> (or <code>-march=</code> whatever CPU you want your code to assume and to tune for) could be a good choice.   Running the resulting binary on an older CPU will result in an illegal-instruction fault.</p>
<p>To make binaries optimized for the machine you build them on, <strong>use <code>-march=native</code></strong>  (with gcc, clang, or ICC).</p>
<p><a href="https://stackoverflow.com/questions/3849337/msvc-equivalent-to-builtin-popcount">MSVC provides an intrinsic for the x86 <code>popcnt</code> instruction</a>, but unlike gcc it's really an intrinsic for the hardware instruction and requires hardware support.</p>
<hr>
<h2>Using <code>std::bitset&lt;&gt;::count()</code> instead of a built-in</h2>
<p>In theory, any compiler that knows how to popcount efficiently for the target CPU should expose that functionality through ISO C++ <a href="http://en.cppreference.com/w/cpp/utility/bitset/count" rel="noreferrer"><code>std::bitset&lt;&gt;</code></a>.  In practice, you might be better off with the bit-hack AND/shift/ADD in some cases for some target CPUs.</p>
<p>For target architectures where hardware popcount is an optional extension (like x86), not all compilers have a <code>std::bitset</code> that takes advantage of it when available.  For example, MSVC has no way to enable <code>popcnt</code> support at compile time, and it's <code>std::bitset&lt;&gt;::count</code> always uses <a href="https://stackoverflow.com/questions/12324081/how-does-this-implementation-of-bitsetcount-work">a table lookup</a>, even with <code>/Ox /arch:AVX</code> (which implies SSE4.2, which in turn implies the popcnt feature.)  (Update: see below; that <em>does</em> get MSVC's C++20 <code>std::popcount</code> to use x86 <code>popcnt</code>, but still not its bitset&lt;&gt;::count.  MSVC could fix that by updating their standard library headers to use std::popcount when available.)</p>
<p>But at least you get something portable that works everywhere, and with gcc/clang with the right target options, you get hardware popcount for architectures that support it.</p>
<pre class="lang-c++ s-code-block"><code class="hljs language-c"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;bitset&gt;</span></span>
<span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;limits&gt;</span></span>
<span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;type_traits&gt;</span></span>

template&lt;typename T&gt;
<span class="hljs-comment">//static inline  // static if you want to compile with -mpopcnt in one compilation unit but not others</span>
typename <span class="hljs-built_in">std</span>::enable_if&lt;<span class="hljs-built_in">std</span>::is_integral&lt;T&gt;::value,  <span class="hljs-type">unsigned</span> &gt;::type 
<span class="hljs-title function_">popcount</span><span class="hljs-params">(T x)</span>
{
    <span class="hljs-keyword">static_assert</span>(<span class="hljs-built_in">std</span>::numeric_limits&lt;T&gt;::radix == <span class="hljs-number">2</span>, <span class="hljs-string">"non-binary type"</span>);

    <span class="hljs-comment">// sizeof(x)*CHAR_BIT</span>
    constexpr <span class="hljs-type">int</span> bitwidth = <span class="hljs-built_in">std</span>::numeric_limits&lt;T&gt;::digits + <span class="hljs-built_in">std</span>::numeric_limits&lt;T&gt;::is_signed;
    <span class="hljs-comment">// std::bitset constructor was only unsigned long before C++11.  Beware if porting to C++03</span>
    <span class="hljs-keyword">static_assert</span>(bitwidth &lt;= <span class="hljs-built_in">std</span>::numeric_limits&lt;<span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> <span class="hljs-type">long</span>&gt;::digits, <span class="hljs-string">"arg too wide for std::bitset() constructor"</span>);

    <span class="hljs-keyword">typedef</span> typename <span class="hljs-built_in">std</span>::make_unsigned&lt;T&gt;::type UT;        <span class="hljs-comment">// probably not needed, bitset width chops after sign-extension</span>

    <span class="hljs-built_in">std</span>::<span class="hljs-built_in">bitset</span>&lt;bitwidth&gt; <span class="hljs-title function_">bs</span><span class="hljs-params">( static_cast&lt;UT&gt;(x) )</span>;
    <span class="hljs-keyword">return</span> bs.count();
}
</code></pre>
<p>See <a href="https://gcc.godbolt.org/#z:OYLghAFBqd5TKALEBjA9gEwKYFFMCWALugE4A0BIEAViAIzkDO6ArqatiAOQCkATAGYCAO1QAbVjgDUvQQGEARsSbYic3LwAMAQQHCxkmXPniCAWxUbteoaIlTsshUQCeAB2wB9IqQCGVoKaugD0IdIAqqrSREhOSOieAGas4uKuALTA6FjSTESYICDKRKpERRisIkQQAJTSFu7i2ObY1X5EBOgi0klk0n6kJf6krg3V2MDYpDEe2Ew2YdI6AG7oBJhMeQTAIhnYAB5EbYQiwNu72Jizngu6i%2BEA8j3AqKgDItcSfmfk0tgAR1YBBWfma1Ri6GkXi8imB4k6Ii87kSlWqaTqD2kmHQAHcREwNlwBuJcX5XFtWKotgA2AAsGRK0kS0x%2BmAyhIAXk4IN1pPTGcRpPIAApRWpYgBiZE4W25pHQ%2ByObUJfJI/IZJQAdFidOIWHlxHjptJccQEqwiNIkINMGTSE4Ue40UQ/vNPKgCGD0qbzQMYn5FM0Mkb0ABrVjuaSh9w60JPHoHAAcNL%2BuLI0ViCtYwCQ7ktzJ6OgAsgARaQAIVS4hx8oyST8lh9sR%2B0kE/EFVqdqGquv1ULJ%2BXm/oASrgABrSdwOpIEA5xvS6Y7mJodbAmNyeESNpwAFWs8fyHQI71EZhETmkSyPnVPSWkrjYpp%2BVvVGBXBGavti0gyK9REKiIWTjvu4n7HnyVRCnCVoiOgVrwXEpB3Dom5tDueQFEU6FBt4BBJCY%2BSFCABBMF4ojHMA/jiCY%2B5BEUoKSNgfzSFUhKXNcGhFGhsi6N2bDVBAu7SAcEr3AA7BWNjaAAnDeJ5eH4TCqKQNREUUIisK0pAKWYlilLRXEgP4hAHM4pZyOW/B/AI/BwXsyjbqMNzrvw/ASoIUn3N5MnXgQ3LoEkECiQAVPIAASOgjl4FYAJL7j5GAEscBzTuMVolGamA/pZmHEZp2m6RYgTyHRuBFIQwAqLI/AVnlGladMRX6QsChlUUpFeOxF6YHIXmLr54TqcUKhqNISX5KQrCoCQMyDoWPpsTsPXRt05yKNgfQOsKAhSbV9D0Fq0iVtg9pOPhU5kIi5zqvIu27Vogg2Mdx3yaginKdMNSZRsOUKLlw0FU1716SVS0catZyQ8ARmVSoNluYMN05L6MhbfVI2lGodTjd0k3TbNtkef10laDJaE4PeaHbq0GPmH4YbeODPWGfRIA8REdF1S9PNLNO6CKIGPpwbB2BXFcfwlGUqM/qgCTuFsfhJMcMzdUqxwEl0Iik3JWGY2UJg/dlSAaNIihMBAmHHu9qBKeoCicxowX1MTOsOkQ7A9ObWoupinnSeJFneYuOjM1cMTzEQyKogJUdMAkqkQPHV0DPUvCSdI7ue5dzqxxAfjE7Igc2GH1zHPk0e51UUcURAFGp0XdVZ6QPT8dX%2BeF%2BnQc6GEpcRxXbfVF4pcQH3BeN5najZ4PNQF31Rfd335dRzP9IQEaUMb%2Bc4/p03U8tznvtz55C9YjhzTkfe%2BSJFssSkb0CrmLjH7nsj/o4qwuEZBofdJSs0yqm1vGJekdK7vQ/rhCAECvw7wzs3VuMd27Hzql3UmId659HQEnBOVo/B/C3tDM2adJJu33j0HWh8847x8rtSh7dFCu10C9PqAdu5oKWDCCi9B%2BBJgaFsLKJoWw9D7gQre0k7D3noDVGkAgaTYk2qIK4EAYQAGVYoAC1cCPElF4WKAA5Xc3CkwwjEj3cIsQnBvQ%2BipK018FYxCQPfJIj9n5gVftICA6pug%2BhdA4pwRpcTWjBEkUxvdNYQ2XmA2ORjlHkWqEYhuu9J4ewPjPDu89UHByWLuRxWwbSoDDKaMgYYth8leKgEI3wzggAGMpRqZtRpWnvmCMkFJejiA6NIVo5gyCuBAM9F6SxYrRk2q%2BXJzICyBT8RHFcHTjhm2wLbKk50iBgG4FsEWl1VJC3XD5MI%2BEk7%2BWwIFZ2zhcDbACkFERa1oa1DTns8IL1umoHcK4CAsjzYIxpAcP4XJjlBXNnclhwd9D2CME4EwqBJqiBhkEEu4SVr5LDFE6uMTOHxJ4YkkhPlhpSzUCYIxptzbpP9j5Z5rz3n8BpJ86ReCLn/IgICwuV5wj2hEDCmpGBXkwo%2BMyRQNBFkIXvPZDIvgQRenEC5DxZofww1qrtUxsl4FmyYD7POjC9DF3uEIE4%2BEbDcFqOQcQPAACs3ByAiB4Foc16AeB3XlbVPIbAOAQqEPQc15RuDWrueQMMIBBBJi1FoGk4lxL0BkgGmkSYkxaC0HSI1PA6TmvMCAcSWgtT0BpDSdsWhM3Zv4Lm1MlqvU2p4OapgIAtDkE9d68gcBYAoFAp%2BaYlBqBNuaKQEA7hnT0maMAbNVbZwIgAdQRQVrzXvlaNUZ46Rx3kEIA6GaIJ5hzootgY1JbDVmHNvAQ1iROh4x4BkAA6t6X8jxBC/iIpZXYrB7r7XdcwZ1nAGBbtNea4t1ryC2u4CKY0pARTyA1PyLUggg0ePwMQfo%2BhGDCnQC/E0MHagevHT6uIfgcCdrqAm7gSbyApv4DJLUSZBCCBDTJEjZHxIUYDRaudP7y2Vurahw1fqA1BpDWGiNKZo2xvjRuwQH76NluY5uutiB63IDQPBtxLaqAQHbdMNAHSzhkZ%2BUOlWFbGVzsnW0IgM6%2BklvnQQRdnR/4VqM2ujdtbt0VsgHu9wB6CRHuvYIUst770VgOlego27LLbtQJ538p60jnsvX%2BbsEI/yDDlpZG0TBcTrvEOW59XBGBkmnY52KIg%2Bg8HdW%2B7gZq6NGZ/cmGkGR6TjRU%2BcMDciICQdmjVQQsH5AyebTMfQghkOie9Ya9DmHqCsf9YGmSdIkwmpkuJJMdITUxqozhvDKbSPEfoLm3NMkZLcJNVNmSxWv0MeYExmtBrxPwAgI2trHbW0Kcu0p4AdJRvkA0yO2JXgtCDfIGOozunp0iFnUZhdgrl0Wa/VZudNAgTTEM2B/gGbzXgmALEBg5BpzYBWI8flgrqAwje9QLknJmj0BNcG4Nm2TV0jG4IagVRKaKMKOvSYJx4D0HEoINNu2q3cHy3crdbREcoEYKj9HmOZrY5hO92gABFVgUP2yrZI4RmSNJHoza0MTjbJr6DUEIEwVchmTv48J8T5XNIycU5I9Tz4CierUD7UzyALO2dk3IJz7nPqEdI/oDzo1BAd32e/Y5rWFmT1noyBenzvU3MeYdV5qREWAJWmixwE2bn4uJbSCl9gL6vc4aK5%2B0t3AysVbpNIcp0g6RaiIyX%2BrhBGswb%2BK1hDHWhAmu68d93ibk3%2BpNcRmkE2c1K7I3SAtJq9sF8Y1W9vp2G3Sab9dxTnaTyoBZ09z8mmxe4%2Bw19r9P39N/cM1%2BwHS7zOromNZ81EOZejB4DDuHRq%2Bee5Rw6YXArRevYl4b7AROSem6J%2Bbqno8Vus4NuDOUwnwzO4kBaq2Lu5AXOBq3uHuAuT%2BaOGOr%2B5Q7%2B1ANA0usu/A8u7YG2yuggqu6uMkmu2upEeuZahqn%2B3%2BJuZulOlutOIBdu4BDukBa2MBcBPOvOZwnuCBvudm2G%2B6QeR6IWkqYe4Wrm7mmknm3m8ezoUW9Myelk24Zm2AmeLqr6ueQmJWPARelWS%2B0gLOEGte0GbqDet2zeRBbeLG5A/WSm2GG6i2/q6a7YggSuE23CbO1GY%2B36ImFak%2BthbGYGY2fej0SYrO/AkBYaOGgmvhB2U%2Bkm52s%2BsmFA8mC%2Bym4aXg9Iq%2Bw6yEo6Om8GU6e%2B/2h%2BJmQOJ%2BlmZ%2BqGPufuQhgeh63AIQjwZkIQMWKAOgAAauOBodnuQBlvplljlj%2BvltofEXoSmMXsKAADJGEyTSBQHiTSAji7jHomFQZWEtaWFNbuQoabpDY8JagU7bbiQhruHTaQF94LY6H7b%2BFHa2Ebr8Bd6rZVr55%2BHcB7G9bkD/zIRawgB0hAA%3D" rel="noreferrer">asm from gcc, clang, icc, and MSVC</a> on the Godbolt compiler explorer.</p>
<p>x86-64 <code>gcc -O3 -std=gnu++11 -mpopcnt</code> emits this:</p>
<pre class="lang-c++ s-code-block"><code class="hljs language-c"><span class="hljs-type">unsigned</span> <span class="hljs-title function_">test_short</span><span class="hljs-params">(<span class="hljs-type">short</span> a)</span> { <span class="hljs-keyword">return</span> popcount(a); }
    movzx   eax, di      <span class="hljs-meta"># note zero-extension, not sign-extension</span>
    popcnt  rax, rax
    ret

<span class="hljs-type">unsigned</span> <span class="hljs-title function_">test_int</span><span class="hljs-params">(<span class="hljs-type">int</span> a)</span> { <span class="hljs-keyword">return</span> popcount(a); }
    mov     eax, edi
    popcnt  rax, rax        <span class="hljs-meta"># unnecessary 64-bit operand size</span>
    ret

<span class="hljs-type">unsigned</span> <span class="hljs-title function_">test_u64</span><span class="hljs-params">(<span class="hljs-type">unsigned</span> <span class="hljs-type">long</span> <span class="hljs-type">long</span> a)</span> { <span class="hljs-keyword">return</span> popcount(a); }
    xor     eax, eax     <span class="hljs-meta"># gcc avoids false dependencies for Intel CPUs</span>
    popcnt  rax, rdi
    ret
</code></pre>
<p>PowerPC64 <code>gcc -O3 -std=gnu++11</code> emits (for the <code>int</code> arg version):</p>
<pre class="lang-c++ s-code-block"><code class="hljs language-c">    rldicl <span class="hljs-number">3</span>,<span class="hljs-number">3</span>,<span class="hljs-number">0</span>,<span class="hljs-number">32</span>     <span class="hljs-meta"># zero-extend from 32 to 64-bit</span>
    popcntd <span class="hljs-number">3</span>,<span class="hljs-number">3</span>         <span class="hljs-meta"># popcount</span>
    blr
</code></pre>
<p>This source isn't x86-specific or GNU-specific at all, but only compiles well with gcc/clang/icc, at least when targeting x86 (including x86-64).</p>
<p>Also note that gcc's fallback for architectures without single-instruction popcount is a byte-at-a-time table lookup.  This isn't wonderful <a href="https://stackoverflow.com/questions/15736602/fastest-way-to-count-number-of-1s-in-a-register-arm-assembly">for ARM, for example</a>.</p>
<h2><a href="https://en.cppreference.com/w/cpp/numeric/popcount" rel="noreferrer">C++20 has <code>std::popcount(T)</code></a></h2>
<p>Current libstdc++ headers unfortunately define it with a special case <code>if(x==0) return 0;</code> at the start, which clang doesn't optimize away when compiling for x86:</p>
<pre class="lang-c++ s-code-block"><code class="hljs language-c"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;bit&gt;</span></span>
<span class="hljs-type">int</span> <span class="hljs-title function_">bar</span><span class="hljs-params">(<span class="hljs-type">unsigned</span> x)</span> {
    <span class="hljs-keyword">return</span> <span class="hljs-built_in">std</span>::popcount(x);
}
</code></pre>
<p>clang 11.0.1 <code>-O3  -std=gnu++20 -march=nehalem</code>  (<a href="https://godbolt.org/z/arMe5a" rel="noreferrer">https://godbolt.org/z/arMe5a</a>)</p>
<pre class="lang-c++ s-code-block"><code class="hljs language-c"><span class="hljs-meta"># clang 11</span>
    bar(<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span>):                                # @bar(<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span>)
        popcnt  eax, edi
        cmove   eax, edi         <span class="hljs-meta"># redundant: <span class="hljs-keyword">if</span> popcnt result is 0, return the original 0 instead of the popcnt-generated 0...</span>
        ret
</code></pre>
<p>But GCC compiles nicely:</p>
<pre class="lang-c++ s-code-block"><code class="hljs language-c"><span class="hljs-meta"># gcc 10</span>
        xor     eax, eax         <span class="hljs-meta"># break false dependency on Intel SnB-family before Ice Lake.</span>
        popcnt  eax, edi
        ret
</code></pre>
<p>Even MSVC does well with it, as long as you use <code>-arch:AVX</code>  or later (and enable C++20 with <code>-std:c++latest</code>). <a href="https://godbolt.org/z/7K4Gef" rel="noreferrer">https://godbolt.org/z/7K4Gef</a></p>
<pre class="lang-c++ s-code-block"><code class="hljs language-c"><span class="hljs-type">int</span> <span class="hljs-title function_">bar</span><span class="hljs-params">(<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span>)</span> PROC                                 ; bar, COMDAT
        popcnt  eax, ecx
        ret     <span class="hljs-number">0</span>
<span class="hljs-type">int</span> <span class="hljs-title function_">bar</span><span class="hljs-params">(<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span>)</span> ENDP                                 ; bar
</code></pre>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 3</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>In my opinion, the "best" solution is the one that can be read by another programmer (or the original programmer two years later) without copious comments.  You may well want the fastest or cleverest solution which some have already provided but I prefer readability over cleverness any time.</p>

<pre><code>unsigned int bitCount (unsigned int value) {
    unsigned int count = 0;
    while (value &gt; 0) {           // until all bits are zero
        if ((value &amp; 1) == 1)     // check lower bit
            count++;
        value &gt;&gt;= 1;              // shift bits, removing lower bit
    }
    return count;
}
</code></pre>

<p>If you want more speed (and assuming you document it well to help out your successors), you could use a table lookup:</p>

<pre><code>// Lookup table for fast calculation of bits set in 8-bit unsigned char.

static unsigned char oneBitsInUChar[] = {
//  0  1  2  3  4  5  6  7  8  9  A  B  C  D  E  F (&lt;- n)
//  =====================================================
    0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4, // 0n
    1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5, // 1n
    : : :
    4, 5, 5, 6, 5, 6, 6, 7, 5, 6, 6, 7, 6, 7, 7, 8, // Fn
};

// Function for fast calculation of bits set in 16-bit unsigned short.

unsigned char oneBitsInUShort (unsigned short x) {
    return oneBitsInUChar [x &gt;&gt;    8]
         + oneBitsInUChar [x &amp;  0xff];
}

// Function for fast calculation of bits set in 32-bit unsigned int.

unsigned char oneBitsInUInt (unsigned int x) {
    return oneBitsInUShort (x &gt;&gt;     16)
         + oneBitsInUShort (x &amp;  0xffff);
}
</code></pre>

<p>Although these rely on specific data type sizes so they're not that portable. But, since many performance optimisations aren't portable anyway, that may not be an issue. If you want portability, I'd stick to the readable solution.</p>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 4</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p><a href="http://books.google.com/books?id=iBNKMspIlqEC&amp;pg=PA66" rel="noreferrer">From Hacker's Delight, p. 66, Figure 5-2</a></p>

<pre><code>int pop(unsigned x)
{
    x = x - ((x &gt;&gt; 1) &amp; 0x55555555);
    x = (x &amp; 0x33333333) + ((x &gt;&gt; 2) &amp; 0x33333333);
    x = (x + (x &gt;&gt; 4)) &amp; 0x0F0F0F0F;
    x = x + (x &gt;&gt; 8);
    x = x + (x &gt;&gt; 16);
    return x &amp; 0x0000003F;
}
</code></pre>

<p>Executes in ~20-ish instructions (arch dependent), no branching.<br><br><a href="http://books.google.com/books?id=iBNKMspIlqEC" rel="noreferrer">Hacker's Delight</a> <em>is</em> delightful! Highly recommended.</p>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 5</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>I think the fastest waywithout using lookup tables and <em>popcount</em>is the following. It counts the set bits with just 12 operations.</p>

<pre><code>int popcount(int v) {
    v = v - ((v &gt;&gt; 1) &amp; 0x55555555);                // put count of each 2 bits into those 2 bits
    v = (v &amp; 0x33333333) + ((v &gt;&gt; 2) &amp; 0x33333333); // put count of each 4 bits into those 4 bits  
    return c = ((v + (v &gt;&gt; 4) &amp; 0xF0F0F0F) * 0x1010101) &gt;&gt; 24;
}
</code></pre>

<p>It works because you can count the total number of set bits by dividing in two halves, counting the number of set bits in both halves and then adding them up. Also know as <code>Divide and Conquer</code> paradigm. Let's get into detail.. </p>

<pre><code>v = v - ((v &gt;&gt; 1) &amp; 0x55555555); 
</code></pre>

<p>The number of bits in two bits can be <code>0b00</code>, <code>0b01</code> or <code>0b10</code>. Lets try to work this out on 2 bits.. </p>

<pre><code> ---------------------------------------------
 |   v    |   (v &gt;&gt; 1) &amp; 0b0101   |  v - x   |
 ---------------------------------------------
   0b00           0b00               0b00   
   0b01           0b00               0b01     
   0b10           0b01               0b01
   0b11           0b01               0b10
</code></pre>

<p>This is what was required: the last column shows the count of set bits in every two bit pair. If the two bit number is <code>&gt;= 2 (0b10)</code> then <code>and</code> produces <code>0b01</code>, else it produces <code>0b00</code>. </p>

<pre><code>v = (v &amp; 0x33333333) + ((v &gt;&gt; 2) &amp; 0x33333333); 
</code></pre>

<p>This statement should be easy to understand. After the first operation we have the count of set bits in every two bits, now we sum up that count in every 4 bits.</p>

<pre><code>v &amp; 0b00110011         //masks out even two bits
(v &gt;&gt; 2) &amp; 0b00110011  // masks out odd two bits
</code></pre>

<p>We then sum up the above result, giving us the total count of set bits in 4 bits. The last statement is the most tricky.</p>

<pre><code>c = ((v + (v &gt;&gt; 4) &amp; 0xF0F0F0F) * 0x1010101) &gt;&gt; 24;
</code></pre>

<p>Let's break it down further... </p>

<pre><code>v + (v &gt;&gt; 4)
</code></pre>

<p>It's similar to the second statement; we are counting the set bits in groups of 4 instead. We knowbecause of our previous operationsthat every nibble has the count of set bits in it. Let's look an example. Suppose we have the byte <code>0b01000010</code>. It means the first nibble has its 4bits set and the second one has its 2bits set. Now we add those nibbles together. </p>

<pre><code>0b01000010 + 0b01000000
</code></pre>

<p>It gives us the count of set bits in a byte, in the first nibble <code>0b01100010</code> and therefore we mask the last four bytes of all the bytes in the number (discarding them).</p>

<pre><code>0b01100010 &amp; 0xF0 = 0b01100000
</code></pre>

<p>Now every byte has the count of set bits in it. We need to add them up all together. The trick is to multiply the result by <code>0b10101010</code> which has an interesting property. If our number has four bytes, <code>A B C D</code>, it will result in a new number with these bytes <code>A+B+C+D B+C+D C+D D</code>. A 4 byte number can have maximum of 32 bits set, which can be represented as <code>0b00100000</code>.</p>

<p>All we need now is the first byte which has the sum of all set bits in all the bytes, and we get it by  <code>&gt;&gt; 24</code>. This algorithm was designed for <code>32 bit</code> words but can be easily modified for <code>64 bit</code> words.</p>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 6</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>If you happen to be using Java, the built-in method <code>Integer.bitCount</code> will do that.</p>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 7</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>I got bored, and timed a billion iterations of three approaches. Compiler is gcc -O3. CPU is whatever they put in the 1st gen Macbook Pro.</p>

<p>Fastest is the following, at 3.7 seconds:</p>

<pre><code>static unsigned char wordbits[65536] = { bitcounts of ints between 0 and 65535 };
static int popcount( unsigned int i )
{
    return( wordbits[i&amp;0xFFFF] + wordbits[i&gt;&gt;16] );
}
</code></pre>

<p>Second place goes to the same code but looking up 4 bytes instead of 2 halfwords. That took around 5.5 seconds.</p>

<p>Third place goes to the bit-twiddling 'sideways addition' approach, which took 8.6 seconds.</p>

<p>Fourth place goes to GCC's __builtin_popcount(), at a shameful 11 seconds.</p>

<p>The counting one-bit-at-a-time approach was waaaay slower, and I got bored of waiting for it to complete.</p>

<p>So if you care about performance above all else then use the first approach. If you care, but not enough to spend 64Kb of RAM on it, use the second approach. Otherwise use the readable (but slow) one-bit-at-a-time approach.</p>

<p>It's hard to think of a situation where you'd want to use the bit-twiddling approach.</p>

<p>Edit: Similar results <a href="http://www.dalkescientific.com/writings/diary/archive/2008/07/03/hakmem_and_other_popcounts.html" rel="noreferrer">here</a>.</p>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 8</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<pre><code>unsigned int count_bit(unsigned int x)
{
  x = (x &amp; 0x55555555) + ((x &gt;&gt; 1) &amp; 0x55555555);
  x = (x &amp; 0x33333333) + ((x &gt;&gt; 2) &amp; 0x33333333);
  x = (x &amp; 0x0F0F0F0F) + ((x &gt;&gt; 4) &amp; 0x0F0F0F0F);
  x = (x &amp; 0x00FF00FF) + ((x &gt;&gt; 8) &amp; 0x00FF00FF);
  x = (x &amp; 0x0000FFFF) + ((x &gt;&gt; 16)&amp; 0x0000FFFF);
  return x;
}
</code></pre>

<p>Let me explain this algorithm.</p>

<p>This algorithm is based on Divide and Conquer Algorithm. Suppose there is a 8bit integer 213(11010101 in binary), the algorithm works like this(each time merge two neighbor blocks):</p>

<pre><code>+-------------------------------+
| 1 | 1 | 0 | 1 | 0 | 1 | 0 | 1 |  &lt;- x
|  1 0  |  0 1  |  0 1  |  0 1  |  &lt;- first time merge
|    0 0 1 1    |    0 0 1 0    |  &lt;- second time merge
|        0 0 0 0 0 1 0 1        |  &lt;- third time ( answer = 00000101 = 5)
+-------------------------------+
</code></pre>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 9</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>Why not iteratively divide by 2?</p>

<pre>count = 0
while n &gt; 0
  if (n % 2) == 1
    count += 1
  n /= 2  
</pre>

<p>I agree that this isn't the fastest, but "best" is somewhat ambiguous. I'd argue though that "best" should have an element of clarity</p>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 10</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>This is one of those questions where it helps to know your micro-architecture.   I just timed two variants under gcc 4.3.3 compiled with -O3 using C++ inlines to eliminate function call overhead, one billion iterations, keeping the running sum of all counts to ensure the compiler doesn't remove anything important, using rdtsc for timing (clock cycle precise).  </p>

<pre>inline int pop2(unsigned x, unsigned y)
{
    x = x - ((x &gt;&gt; 1) &amp; 0x55555555);
    y = y - ((y &gt;&gt; 1) &amp; 0x55555555);
    x = (x &amp; 0x33333333) + ((x &gt;&gt; 2) &amp; 0x33333333);
    y = (y &amp; 0x33333333) + ((y &gt;&gt; 2) &amp; 0x33333333);
    x = (x + (x &gt;&gt; 4)) &amp; 0x0F0F0F0F;
    y = (y + (y &gt;&gt; 4)) &amp; 0x0F0F0F0F;
    x = x + (x &gt;&gt; 8);
    y = y + (y &gt;&gt; 8);
    x = x + (x &gt;&gt; 16);
    y = y + (y &gt;&gt; 16);
    return (x+y) &amp; 0x000000FF;
}
</pre> 

<p>The unmodified Hacker's Delight took 12.2 gigacycles.  My parallel version (counting twice as many bits) runs in 13.0 gigacycles.  10.5s total elapsed for both together on a 2.4GHz Core Duo.  25 gigacycles = just over 10 seconds at this clock frequency, so I'm confident my timings are right.  </p>

<p>This has to do with instruction dependency chains, which are very bad for this algorithm.  I could nearly double the speed again by using a pair of 64-bit registers.  In fact, if I was clever and added x+y a little sooner I could shave off some shifts.  The 64-bit version with some small tweaks would come out about even, but count twice as many bits again.  </p>

<p>With 128 bit SIMD registers, yet another factor of two, and the SSE instruction sets often have clever short-cuts, too.  </p>

<p>There's no reason for the code to be especially transparent.  The interface is simple, the algorithm can be referenced on-line in many places, and it's amenable to comprehensive unit test.  The programmer who stumbles upon it might even learn something.  These bit operations are extremely natural at the machine level.  </p>

<p>OK, I decided to bench the tweaked 64-bit version.  For this one  sizeof(unsigned long) == 8 </p>

<pre>inline int pop2(unsigned long x, unsigned long y)
{
    x = x - ((x &gt;&gt; 1) &amp; 0x5555555555555555);
    y = y - ((y &gt;&gt; 1) &amp; 0x5555555555555555);
    x = (x &amp; 0x3333333333333333) + ((x &gt;&gt; 2) &amp; 0x3333333333333333);
    y = (y &amp; 0x3333333333333333) + ((y &gt;&gt; 2) &amp; 0x3333333333333333);
    x = (x + (x &gt;&gt; 4)) &amp; 0x0F0F0F0F0F0F0F0F;
    y = (y + (y &gt;&gt; 4)) &amp; 0x0F0F0F0F0F0F0F0F;
    x = x + y; 
    x = x + (x &gt;&gt; 8);
    x = x + (x &gt;&gt; 16);
    x = x + (x &gt;&gt; 32); 
    return x &amp; 0xFF;
}
</pre> 

<p>That looks about right (I'm not testing carefully, though).   Now the timings come out at 10.70 gigacycles / 14.1 gigacycles.   That later number summed 128 billion bits and corresponds to 5.9s elapsed on this machine.   The non-parallel version speeds up a tiny bit because I'm running in 64-bit mode and it likes 64-bit registers slightly better than 32-bit registers.  </p>

<p>Let's see if there's a bit more OOO pipelining to be had here.   This was a bit more involved, so I actually tested a bit.  Each term alone sums to 64, all combined sum to 256.  </p>

<pre>inline int pop4(unsigned long x, unsigned long y, 
                unsigned long u, unsigned long v)
{
  enum { m1 = 0x5555555555555555, 
         m2 = 0x3333333333333333, 
         m3 = 0x0F0F0F0F0F0F0F0F, 
         m4 = 0x000000FF000000FF };

    x = x - ((x &gt;&gt; 1) &amp; m1);
    y = y - ((y &gt;&gt; 1) &amp; m1);
    u = u - ((u &gt;&gt; 1) &amp; m1);
    v = v - ((v &gt;&gt; 1) &amp; m1);
    x = (x &amp; m2) + ((x &gt;&gt; 2) &amp; m2);
    y = (y &amp; m2) + ((y &gt;&gt; 2) &amp; m2);
    u = (u &amp; m2) + ((u &gt;&gt; 2) &amp; m2);
    v = (v &amp; m2) + ((v &gt;&gt; 2) &amp; m2);
    x = x + y; 
    u = u + v; 
    x = (x &amp; m3) + ((x &gt;&gt; 4) &amp; m3);
    u = (u &amp; m3) + ((u &gt;&gt; 4) &amp; m3);
    x = x + u; 
    x = x + (x &gt;&gt; 8);
    x = x + (x &gt;&gt; 16);
    x = x &amp; m4; 
    x = x + (x &gt;&gt; 32);
    return x &amp; 0x000001FF;
}
</pre>

<p>I was excited for a moment, but it turns out gcc is playing inline tricks with -O3 even though I'm not using the inline keyword in some tests.  When I let gcc play tricks, a billion calls to pop4() takes 12.56 gigacycles, but I determined it was folding arguments as constant expressions.   A more realistic number appears to be 19.6gc for another 30% speed-up.  My test loop now looks like this, making sure each argument is different enough to stop gcc from playing tricks.   </p>

<pre>   hitime b4 = rdtsc(); 
   for (unsigned long i = 10L * 1000*1000*1000; i &lt; 11L * 1000*1000*1000; ++i) 
      sum += pop4 (i,  i^1, ~i, i|1); 
   hitime e4 = rdtsc(); 
</pre>

<p>256 billion bits summed in 8.17s elapsed.  Works out to 1.02s for 32 million bits as benchmarked in the 16-bit table lookup.  Can't compare directly, because the other bench doesn't give a clock speed, but looks like I've slapped the snot out of the 64KB table edition, which is a tragic use of L1 cache in the first place.  </p>

<p>Update: decided to do the obvious and create pop6() by adding four more duplicated lines.  Came out to 22.8gc, 384 billion bits summed in 9.5s elapsed.   So there's another 20%   Now at 800ms for 32 billion bits.  </p>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 11</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>The Hacker's Delight bit-twiddling becomes so much clearer when you write out the bit patterns.  </p>

<pre><code>unsigned int bitCount(unsigned int x)
{
  x = ((x &gt;&gt; 1) &amp; 0b01010101010101010101010101010101)
     + (x       &amp; 0b01010101010101010101010101010101);
  x = ((x &gt;&gt; 2) &amp; 0b00110011001100110011001100110011)
     + (x       &amp; 0b00110011001100110011001100110011); 
  x = ((x &gt;&gt; 4) &amp; 0b00001111000011110000111100001111)
     + (x       &amp; 0b00001111000011110000111100001111); 
  x = ((x &gt;&gt; 8) &amp; 0b00000000111111110000000011111111)
     + (x       &amp; 0b00000000111111110000000011111111); 
  x = ((x &gt;&gt; 16)&amp; 0b00000000000000001111111111111111)
     + (x       &amp; 0b00000000000000001111111111111111); 
  return x;
}
</code></pre>

<p>The first step adds the even bits to the odd bits, producing a sum of bits in each two.  The other steps add high-order chunks to low-order chunks, doubling the chunk size all the way up, until we have the final count taking up the entire int.</p>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 12</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>For a happy medium between a 2<sup>32</sup> lookup table and iterating through each bit individually:</p>

<pre><code>int bitcount(unsigned int num){
    int count = 0;
    static int nibblebits[] =
        {0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4};
    for(; num != 0; num &gt;&gt;= 4)
        count += nibblebits[num &amp; 0x0f];
    return count;
}
</code></pre>

<p>From <a href="http://ctips.pbwiki.com/CountBits" rel="noreferrer">http://ctips.pbwiki.com/CountBits</a></p>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 13</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>This can be done in <code>O(k)</code>, where <code>k</code> is the number of bits set.</p>

<pre><code>int NumberOfSetBits(int n)
{
    int count = 0;

    while (n){
        ++ count;
        n = (n - 1) &amp; n;
    }

    return count;
}
</code></pre>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 14</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>It's not the fastest or best solution, but I found the same question in my way, and I started to think and think. finally I realized that it can be done like this if you get the problem from mathematical side, and draw a graph, then you find that it's a function which has some periodic part, and then you realize the difference between the periods... so here you go:</p>

<pre><code>unsigned int f(unsigned int x)
{
    switch (x) {
        case 0:
            return 0;
        case 1:
            return 1;
        case 2:
            return 1;
        case 3:
            return 2;
        default:
            return f(x/4) + f(x%4);
    }
}
</code></pre>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 15</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>I think the <a href="https://graphics.stanford.edu/~seander/bithacks.html#CountBitsSetKernighan" rel="noreferrer">Brian Kernighan's</a> method will be useful too...
It goes through as many iterations as there are set bits. So if we have a 32-bit word with only the high bit set, then it will only go once through the loop.  </p>

<pre><code>int countSetBits(unsigned int n) { 
    unsigned int n; // count the number of bits set in n
    unsigned int c; // c accumulates the total bits set in n
    for (c=0;n&gt;0;n=n&amp;(n-1)) c++; 
    return c; 
}
</code></pre>

<blockquote>
  <p>Published in 1988, the C Programming Language 2nd Ed. (by Brian W. Kernighan and Dennis M. Ritchie) mentions this in exercise 2-9. On April 19, 2006 Don Knuth pointed out to me that this method "was first published by Peter Wegner in CACM 3 (1960), 322. (Also discovered independently by Derrick Lehmer and published in 1964 in a book edited by Beckenbach.)"</p>
</blockquote>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 16</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>The function you are looking for is often called the "sideways sum" or "population count" of a binary number.  Knuth discusses it in pre-Fascicle 1A, pp11-12 (although there was a brief reference in Volume 2, 4.6.3-(7).)</p>

<p>The <em>locus classicus</em> is Peter Wegner's article "A Technique for Counting Ones in a Binary Computer", from the <a href="http://cacm.acm.org/magazines/1960/5/14709-a-technique-for-counting-ones-in-a-binary-computer/abstract" rel="nofollow noreferrer"><em>Communications of the ACM</em>, Volume 3 (1960) Number 5, page 322</a>.  He gives two different algorithms there, one optimized for numbers expected to be "sparse" (i.e., have a small number of ones) and one for the opposite case.</p>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 17</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<pre class="lang-java s-code-block"><code class="hljs language-java">  <span class="hljs-keyword">private</span> <span class="hljs-type">int</span> <span class="hljs-title function_">get_bits_set</span><span class="hljs-params">(<span class="hljs-type">int</span> v)</span>
    {
      <span class="hljs-type">int</span> c; <span class="hljs-comment">// c accumulates the total bits set in v</span>
        <span class="hljs-keyword">for</span> (c = <span class="hljs-number">0</span>; v&gt;<span class="hljs-number">0</span>; c++)
        {
            v &amp;= v - <span class="hljs-number">1</span>; <span class="hljs-comment">// clear the least significant bit set</span>
        }
        <span class="hljs-keyword">return</span> c;
    }
</code></pre>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 18</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>Few open questions:-</p>

<ol>
<li>If the number is negative then?</li>
<li>If the number is 1024 , then the "iteratively divide by 2" method will iterate 10 times.</li>
</ol>

<p>we can modify the algo to support the negative number as follows:-</p>

<pre><code>count = 0
while n != 0
if ((n % 2) == 1 || (n % 2) == -1
    count += 1
  n /= 2  
return count
</code></pre>

<p>now to overcome the second problem we can write the algo like:-</p>

<pre><code>int bit_count(int num)
{
    int count=0;
    while(num)
    {
        num=(num)&amp;(num-1);
        count++;
    }
    return count;
}
</code></pre>

<p>for complete reference see :</p>

<p><a href="http://goursaha.freeoda.com/Miscellaneous/IntegerBitCount.html" rel="noreferrer">http://goursaha.freeoda.com/Miscellaneous/IntegerBitCount.html</a></p>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 19</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>I use the below code which is more intuitive.</p>

<pre><code>int countSetBits(int n) {
    return !n ? 0 : 1 + countSetBits(n &amp; (n-1));
}
</code></pre>

<p>Logic : n &amp; (n-1)  resets the last set bit of n.</p>

<p>P.S : I know this is not O(1) solution, albeit an interesting solution.</p>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 20</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>What do you means with "Best algorithm"? The shorted code or the fasted code? Your code look very elegant and it has a constant execution time. The code is also very short.</p>

<p>But if the speed is the major factor and not the code size then I think the follow can be faster:</p>

<pre><code>       static final int[] BIT_COUNT = { 0, 1, 1, ... 256 values with a bitsize of a byte ... };
        static int bitCountOfByte( int value ){
            return BIT_COUNT[ value &amp; 0xFF ];
        }

        static int bitCountOfInt( int value ){
            return bitCountOfByte( value ) 
                 + bitCountOfByte( value &gt;&gt; 8 ) 
                 + bitCountOfByte( value &gt;&gt; 16 ) 
                 + bitCountOfByte( value &gt;&gt; 24 );
        }
</code></pre>

<p>I think that this will not more faster for a 64 bit value but a 32 bit value can be faster.</p>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 21</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>I wrote a fast bitcount macro for RISC machines in about 1990.  It does not use advanced arithmetic (multiplication, division, %), memory fetches (way too slow), branches (way too slow), but it does assume the CPU has a 32-bit barrel shifter (in other words, &gt;&gt; 1 and &gt;&gt; 32 take the same amount of cycles.)  It assumes that small constants (such as 6, 12, 24) cost nothing to load into the registers, or are stored in temporaries and reused over and over again.</p>

<p>With these assumptions, it counts 32 bits in about 16 cycles/instructions on most RISC machines.  Note that 15 instructions/cycles is close to a lower bound on the number of cycles or instructions, because it seems to take at least 3 instructions (mask, shift, operator) to cut the number of addends in half, so log_2(32) = 5, 5 x 3 = 15 instructions is a quasi-lowerbound.</p>

<pre><code>#define BitCount(X,Y)           \
                Y = X - ((X &gt;&gt; 1) &amp; 033333333333) - ((X &gt;&gt; 2) &amp; 011111111111); \
                Y = ((Y + (Y &gt;&gt; 3)) &amp; 030707070707); \
                Y =  (Y + (Y &gt;&gt; 6)); \
                Y = (Y + (Y &gt;&gt; 12) + (Y &gt;&gt; 24)) &amp; 077;
</code></pre>

<p>Here is a secret to the first and most complex step:</p>

<pre><code>input output
AB    CD             Note
00    00             = AB
01    01             = AB
10    01             = AB - (A &gt;&gt; 1) &amp; 0x1
11    10             = AB - (A &gt;&gt; 1) &amp; 0x1
</code></pre>

<p>so if I take the 1st column (A) above, shift it right 1 bit, and subtract it from AB, I get the output (CD).  The extension to 3 bits is similar; you can check it with an 8-row boolean table like mine above if you wish.</p>

<ul>
<li>Don Gillies</li>
</ul>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 22</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>if you're using C++ another option is to use template metaprogramming:</p>

<pre><code>// recursive template to sum bits in an int
template &lt;int BITS&gt;
int countBits(int val) {
        // return the least significant bit plus the result of calling ourselves with
        // .. the shifted value
        return (val &amp; 0x1) + countBits&lt;BITS-1&gt;(val &gt;&gt; 1);
}

// template specialisation to terminate the recursion when there's only one bit left
template&lt;&gt;
int countBits&lt;1&gt;(int val) {
        return val &amp; 0x1;
}
</code></pre>

<p>usage would be:</p>

<pre><code>// to count bits in a byte/char (this returns 8)
countBits&lt;8&gt;( 255 )

// another byte (this returns 7)
countBits&lt;8&gt;( 254 )

// counting bits in a word/short (this returns 1)
countBits&lt;16&gt;( 256 )
</code></pre>

<p>you could of course further expand this template to use different types (even auto-detecting bit size) but I've kept it simple for clarity.</p>

<p><strong>edit: forgot to mention this is good because it <em>should</em> work in any C++ compiler and it basically just unrolls your loop for you if a constant value is used for the bit count</strong> (in other words, I'm pretty sure it's the fastest general method you'll find)</p>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 23</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>what you can do is </p>

<pre><code>while(n){
    n=n&amp;(n-1);
    count++;
}
</code></pre>

<p>the logic behind this is the bits of n-1 is inverted from rightmost set bit of n.
if n=6 i.e 110
then 5 is 101 the bits are inverted from rightmost set bit of n.
so if we &amp; these two we will make the rightmost bit 0 in every iteration and always go to the next rightmost set bit.Hence, counting the set bit.The worst time complexity will be O(logn) when every bit is set.</p>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 24</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>I'm particularly fond of this example from the fortune file:</p>

<pre>#define BITCOUNT(x)    (((BX_(x)+(BX_(x)&gt;&gt;4)) &amp; 0x0F0F0F0F) % 255)
#define BX_(x)         ((x) - (((x)&gt;&gt;1)&amp;0x77777777)
                             - (((x)&gt;&gt;2)&amp;0x33333333)
                             - (((x)&gt;&gt;3)&amp;0x11111111))
</pre>

<p>I like it best because it's so pretty!</p>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 25</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>Java JDK1.5</p>

<p>Integer.bitCount(n);</p>

<p>where n is the number whose 1's are to be counted.</p>

<p>check also,</p>

<pre><code>Integer.highestOneBit(n);
Integer.lowestOneBit(n);
Integer.numberOfLeadingZeros(n);
Integer.numberOfTrailingZeros(n);

//Beginning with the value 1, rotate left 16 times
     n = 1;
         for (int i = 0; i &lt; 16; i++) {
            n = Integer.rotateLeft(n, 1);
            System.out.println(n);
         }
</code></pre>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 26</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>Fast C# solution using pre-calculated table of Byte bit counts with branching on input size.</p>

<pre><code>public static class BitCount
{
    public static uint GetSetBitsCount(uint n)
    {
        var counts = BYTE_BIT_COUNTS;
        return n &lt;= 0xff ? counts[n]
             : n &lt;= 0xffff ? counts[n &amp; 0xff] + counts[n &gt;&gt; 8]
             : n &lt;= 0xffffff ? counts[n &amp; 0xff] + counts[(n &gt;&gt; 8) &amp; 0xff] + counts[(n &gt;&gt; 16) &amp; 0xff]
             : counts[n &amp; 0xff] + counts[(n &gt;&gt; 8) &amp; 0xff] + counts[(n &gt;&gt; 16) &amp; 0xff] + counts[(n &gt;&gt; 24) &amp; 0xff];
    }

    public static readonly uint[] BYTE_BIT_COUNTS = 
    {
        0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4,
        1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5,
        1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5,
        2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
        1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5,
        2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
        2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
        3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7,
        1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5,
        2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
        2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
        3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7,
        2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,
        3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7,
        3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7,
        4, 5, 5, 6, 5, 6, 6, 7, 5, 6, 6, 7, 6, 7, 7, 8
    };
}
</code></pre>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 27</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>I found an implementation of bit counting in an array with using of SIMD instruction (SSSE3 and AVX2). It has in 2-2.5 times better performance than if it will use __popcnt64 intrinsic function.</p>

<p>SSSE3 version:</p>

<pre><code>#include &lt;smmintrin.h&gt;
#include &lt;stdint.h&gt;

const __m128i Z = _mm_set1_epi8(0x0);
const __m128i F = _mm_set1_epi8(0xF);
//Vector with pre-calculated bit count:
const __m128i T = _mm_setr_epi8(0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4);

uint64_t BitCount(const uint8_t * src, size_t size)
{
    __m128i _sum =  _mm128_setzero_si128();
    for (size_t i = 0; i &lt; size; i += 16)
    {
        //load 16-byte vector
        __m128i _src = _mm_loadu_si128((__m128i*)(src + i));
        //get low 4 bit for every byte in vector
        __m128i lo = _mm_and_si128(_src, F);
        //sum precalculated value from T
        _sum = _mm_add_epi64(_sum, _mm_sad_epu8(Z, _mm_shuffle_epi8(T, lo)));
        //get high 4 bit for every byte in vector
        __m128i hi = _mm_and_si128(_mm_srli_epi16(_src, 4), F);
        //sum precalculated value from T
        _sum = _mm_add_epi64(_sum, _mm_sad_epu8(Z, _mm_shuffle_epi8(T, hi)));
    }
    uint64_t sum[2];
    _mm_storeu_si128((__m128i*)sum, _sum);
    return sum[0] + sum[1];
}
</code></pre>

<p>AVX2 version:</p>

<pre><code>#include &lt;immintrin.h&gt;
#include &lt;stdint.h&gt;

const __m256i Z = _mm256_set1_epi8(0x0);
const __m256i F = _mm256_set1_epi8(0xF);
//Vector with pre-calculated bit count:
const __m256i T = _mm256_setr_epi8(0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4, 
                                   0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4);

uint64_t BitCount(const uint8_t * src, size_t size)
{
    __m256i _sum =  _mm256_setzero_si256();
    for (size_t i = 0; i &lt; size; i += 32)
    {
        //load 32-byte vector
        __m256i _src = _mm256_loadu_si256((__m256i*)(src + i));
        //get low 4 bit for every byte in vector
        __m256i lo = _mm256_and_si256(_src, F);
        //sum precalculated value from T
        _sum = _mm256_add_epi64(_sum, _mm256_sad_epu8(Z, _mm256_shuffle_epi8(T, lo)));
        //get high 4 bit for every byte in vector
        __m256i hi = _mm256_and_si256(_mm256_srli_epi16(_src, 4), F);
        //sum precalculated value from T
        _sum = _mm256_add_epi64(_sum, _mm256_sad_epu8(Z, _mm256_shuffle_epi8(T, hi)));
    }
    uint64_t sum[4];
    _mm256_storeu_si256((__m256i*)sum, _sum);
    return sum[0] + sum[1] + sum[2] + sum[3];
}
</code></pre>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 28</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>I always use this in Competitive Programming and it's easy to write and efficient:</p>

<pre><code>#include &lt;bits/stdc++.h&gt;

using namespace std;

int countOnes(int n) {
    bitset&lt;32&gt; b(n);
    return b.count();
}
</code></pre>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 29</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p><strong>C++20 <code>std::popcount</code></strong></p>

<p>The following proposal has been merged <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0553r4.html" rel="noreferrer">http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0553r4.html</a> and should add it to a the <code>&lt;bit&gt;</code> header.</p>

<p>I expect the usage to be like:</p>

<pre><code>#include &lt;bit&gt;
#include &lt;iostream&gt;

int main() {
    std::cout &lt;&lt; std::popcount(0x55) &lt;&lt; std::endl;
}
</code></pre>

<p>I'll give it a try when support arrives to GCC, GCC 9.1.0 with <code>g++-9 -std=c++2a</code> still doesn't support it.</p>

<p>The proposal says:</p>

<blockquote>
  <p>Header: <code>&lt;bit&gt;</code></p>

<pre><code>namespace std {

  // 25.5.6, counting
  template&lt;class T&gt;
    constexpr int popcount(T x) noexcept;
</code></pre>
</blockquote>

<p>and:</p>

<blockquote>
<pre><code>template&lt;class T&gt;
  constexpr int popcount(T x) noexcept;
</code></pre>
  
  <p>Constraints: T is an unsigned integer type (3.9.1 [basic.fundamental]).</p>
  
  <p>Returns: The number of 1 bits in the value of x.</p>
</blockquote>

<p><code>std::rotl</code> and <code>std::rotr</code> were also added to do circular bit rotations: <a href="https://stackoverflow.com/questions/776508/best-practices-for-circular-shift-rotate-operations-in-c/57285854#57285854">Best practices for circular shift (rotate) operations in C++</a></p>
    </div></div></div></div><div class="flex mt-5 answer items-center justify-center py-5"><div class="rounded-xl border p-10 shadow-md w-9/12 bg-white"><h4 class="text-4xl font-semibold mb-5">Solution 30</h4><div class=" items-center justify-between"><div class=" space-x-4 md:space-x-8">
<p>There are many algorithm to count the set bits; but i think the best one is the faster one!
You can see the detailed on this page:</p>

<p><a href="http://graphics.stanford.edu/~seander/bithacks.html">Bit Twiddling Hacks</a> </p>

<p>I suggest this one:</p>

<p><strong>Counting bits set in 14, 24, or 32-bit words using 64-bit instructions</strong></p>

<pre><code>unsigned int v; // count the number of bits set in v
unsigned int c; // c accumulates the total bits set in v

// option 1, for at most 14-bit values in v:
c = (v * 0x200040008001ULL &amp; 0x111111111111111ULL) % 0xf;

// option 2, for at most 24-bit values in v:
c =  ((v &amp; 0xfff) * 0x1001001001001ULL &amp; 0x84210842108421ULL) % 0x1f;
c += (((v &amp; 0xfff000) &gt;&gt; 12) * 0x1001001001001ULL &amp; 0x84210842108421ULL) 
     % 0x1f;

// option 3, for at most 32-bit values in v:
c =  ((v &amp; 0xfff) * 0x1001001001001ULL &amp; 0x84210842108421ULL) % 0x1f;
c += (((v &amp; 0xfff000) &gt;&gt; 12) * 0x1001001001001ULL &amp; 0x84210842108421ULL) % 
     0x1f;
c += ((v &gt;&gt; 24) * 0x1001001001001ULL &amp; 0x84210842108421ULL) % 0x1f;
</code></pre>

<p>This method requires a 64-bit CPU with fast modulus division to be efficient. The first option takes only 3 operations; the second option takes 10; and the third option takes 15. </p>
    </div></div></div></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"data":{"answer":["\n\u0026lt;p\u0026gt;This is known as the \u0026apos;\u0026lt;a href=\u0026quot;https://en.wikipedia.org/wiki/Hamming_weight\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;Hamming Weight\u0026lt;/a\u0026gt;\u0026apos;, \u0026apos;popcount\u0026apos; or \u0026apos;sideways addition\u0026apos;.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;Some CPUs have a single built-in instruction to do it and others have parallel instructions which act on bit vectors.  Instructions like x86\u0026apos;s \u0026lt;a href=\u0026quot;https://www.felixcloutier.com/x86/popcnt\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;\u0026lt;code\u0026gt;popcnt\u0026lt;/code\u0026gt;\u0026lt;/a\u0026gt; (on CPUs where it\u0026apos;s supported) will almost certainly be fastest for a single integer.  Some other architectures may have a slow instruction implemented with a microcoded loop that tests a bit per cycle (\u0026lt;em\u0026gt;citation needed\u0026lt;/em\u0026gt; - hardware popcount is normally fast if it exists at all.).\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;The \u0026apos;best\u0026apos; algorithm really depends on which CPU you are on and what your usage pattern is.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;Your compiler may know how to do something that\u0026apos;s good for the specific CPU you\u0026apos;re compiling for, e.g. \u0026lt;a href=\u0026quot;https://en.cppreference.com/w/cpp/numeric/popcount\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;C++20 \u0026lt;code\u0026gt;std::popcount()\u0026lt;/code\u0026gt;\u0026lt;/a\u0026gt;, or C++ \u0026lt;a href=\u0026quot;https://en.cppreference.com/w/cpp/utility/bitset/count\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;\u0026lt;code\u0026gt;std::bitset\u0026amp;lt;32\u0026amp;gt;::count()\u0026lt;/code\u0026gt;\u0026lt;/a\u0026gt;, as a portable way to access builtin / intrinsic functions (see \u0026lt;a href=\u0026quot;https://stackoverflow.com/questions/109023/how-to-count-the-number-of-set-bits-in-a-32-bit-integer/109069#109069\u0026quot;\u0026gt;another answer\u0026lt;/a\u0026gt; on this question).  But your compiler\u0026apos;s choice of fallback for target CPUs that don\u0026apos;t have hardware popcnt might not be optimal for your use-case.  Or your language (e.g. C) might not expose any portable function that could use a CPU-specific popcount when there is one.\u0026lt;/p\u0026gt;\n\u0026lt;hr\u0026gt;\n\u0026lt;h3\u0026gt;Portable algorithms that don\u0026apos;t need (or benefit from) any HW support\u0026lt;/h3\u0026gt;\n\u0026lt;p\u0026gt;A pre-populated table lookup method can be very fast if your CPU has a large cache and you are doing lots of these operations in a tight loop. However it can suffer because of the expense of a \u0026apos;cache miss\u0026apos;, where the CPU has to fetch some of the table from main memory.  (Look up each byte separately to keep the table small.)  If you want popcount for a contiguous range of numbers, only the low byte is changing for groups of 256 numbers, \u0026lt;a href=\u0026quot;https://stackoverflow.com/questions/66520106/count-integers-in-1-n-with-k-zero-bits-below-the-leading-1-popcount-for-a-c/66532113#66532113\u0026quot;\u0026gt;making this very good\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;If you know that your bytes will be mostly 0\u0026apos;s or mostly 1\u0026apos;s then there are efficient algorithms for these scenarios, e.g. clearing the lowest set with a bithack in a loop until it becomes zero.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;I believe a very good general purpose algorithm is the following, known as \u0026apos;parallel\u0026apos; or \u0026apos;variable-precision SWAR algorithm\u0026apos;. I have expressed this in a C-like pseudo language, you may need to adjust it to work for a particular language (e.g. using uint32_t for C++ and \u0026amp;gt;\u0026amp;gt;\u0026amp;gt; in Java):\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;GCC10 and clang 10.0 can recognize this pattern / idiom and compile it to a hardware popcnt or equivalent instruction when available, giving you the best of both worlds. (\u0026lt;a href=\u0026quot;https://godbolt.org/z/qGdh1dvKK\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;https://godbolt.org/z/qGdh1dvKK\u0026lt;/a\u0026gt;)\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-c s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-c\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;int\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;numberOfSetBits\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;(\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;uint32_t\u0026lt;/span\u0026gt; i)\u0026lt;/span\u0026gt;\n{\n     \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;// Java: use int, and use \u0026amp;gt;\u0026amp;gt;\u0026amp;gt; instead of \u0026amp;gt;\u0026amp;gt;. Or use Integer.bitCount()\u0026lt;/span\u0026gt;\n     \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;// C or C++: use uint32_t\u0026lt;/span\u0026gt;\n     i = i - ((i \u0026amp;gt;\u0026amp;gt; \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;) \u0026amp;amp; \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0x55555555\u0026lt;/span\u0026gt;);        \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;// add pairs of bits\u0026lt;/span\u0026gt;\n     i = (i \u0026amp;amp; \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0x33333333\u0026lt;/span\u0026gt;) + ((i \u0026amp;gt;\u0026amp;gt; \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;2\u0026lt;/span\u0026gt;) \u0026amp;amp; \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0x33333333\u0026lt;/span\u0026gt;);  \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;// quads\u0026lt;/span\u0026gt;\n     i = (i + (i \u0026amp;gt;\u0026amp;gt; \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;4\u0026lt;/span\u0026gt;)) \u0026amp;amp; \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0x0F0F0F0F\u0026lt;/span\u0026gt;;        \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;// groups of 8\u0026lt;/span\u0026gt;\n     \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;return\u0026lt;/span\u0026gt; (i * \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0x01010101\u0026lt;/span\u0026gt;) \u0026amp;gt;\u0026amp;gt; \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;24\u0026lt;/span\u0026gt;;          \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;// horizontal sum of bytes\u0026lt;/span\u0026gt;\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;For JavaScript: \u0026lt;a href=\u0026quot;https://stackoverflow.com/questions/109023/how-to-count-the-number-of-set-bits-in-a-32-bit-integer/109025#comment103845611_109025\u0026quot;\u0026gt;coerce to integer\u0026lt;/a\u0026gt; with \u0026lt;code\u0026gt;|0\u0026lt;/code\u0026gt; for performance: change the first line to \u0026lt;code\u0026gt;i = (i|0) - ((i \u0026amp;gt;\u0026amp;gt; 1) \u0026amp;amp; 0x55555555);\u0026lt;/code\u0026gt;\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;This has the best worst-case behaviour of any of the algorithms discussed, so will efficiently deal with any usage pattern or values you throw at it.  (Its performance is not data-dependent on normal CPUs where all integer operations including multiply are constant-time.  It doesn\u0026apos;t get any faster with \u0026quot;simple\u0026quot; inputs, but it\u0026apos;s still pretty decent.)\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;References:\u0026lt;/p\u0026gt;\n\u0026lt;ul\u0026gt;\n\u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;https://graphics.stanford.edu/%7Eseander/bithacks.html#CountBitsSetParallel\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;https://graphics.stanford.edu/~seander/bithacks.html\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;https://en.wikipedia.org/wiki/Hamming_weight\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;https://en.wikipedia.org/wiki/Hamming_weight\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;http://gurmeet.net/puzzles/fast-bit-counting-routines/\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;http://gurmeet.net/puzzles/fast-bit-counting-routines/\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;http://aggregate.ee.engr.uky.edu/MAGIC/#Population%20Count%20(Ones%20Count)\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;http://aggregate.ee.engr.uky.edu/MAGIC/#Population%20Count%20(Ones%20Count)\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\n\u0026lt;/ul\u0026gt;\n\u0026lt;hr\u0026gt;\n\u0026lt;h3\u0026gt;How this SWAR bithack works:\u0026lt;/h3\u0026gt;\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;i = i - ((i \u0026amp;gt;\u0026amp;gt; 1) \u0026amp;amp; 0x55555555);\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;The first step is an optimized version of masking to isolate the odd / even bits, shifting to line them up, and adding.  This effectively does 16 separate additions in 2-bit accumulators (\u0026lt;a href=\u0026quot;https://en.wikipedia.org/wiki/SWAR\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;SWAR = SIMD Within A Register\u0026lt;/a\u0026gt;).  Like \u0026lt;code\u0026gt;(i \u0026amp;amp; 0x55555555) + ((i\u0026amp;gt;\u0026amp;gt;1) \u0026amp;amp; 0x55555555)\u0026lt;/code\u0026gt;.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;The next step takes the odd/even eight of those 16x 2-bit accumulators and adds again, producing 8x 4-bit sums.  The \u0026lt;code\u0026gt;i - ...\u0026lt;/code\u0026gt; optimization isn\u0026apos;t possible this time so it does just mask before / after shifting.  Using the same \u0026lt;code\u0026gt;0x33...\u0026lt;/code\u0026gt; constant both times instead of \u0026lt;code\u0026gt;0xccc...\u0026lt;/code\u0026gt; before shifting is a good thing when compiling for ISAs that need to construct 32-bit constants in registers separately.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;The final shift-and-add step of \u0026lt;code\u0026gt;(i + (i \u0026amp;gt;\u0026amp;gt; 4)) \u0026amp;amp; 0x0F0F0F0F\u0026lt;/code\u0026gt; widens to 4x 8-bit accumulators.  It masks \u0026lt;em\u0026gt;after\u0026lt;/em\u0026gt; adding instead of before, because the maximum value in any 4-bit accumulator is \u0026lt;code\u0026gt;4\u0026lt;/code\u0026gt;, if all 4 bits of the corresponding input bits were set.  4+4 = 8 which still fits in 4 bits, so carry between nibble elements is impossible in \u0026lt;code\u0026gt;i + (i \u0026amp;gt;\u0026amp;gt; 4)\u0026lt;/code\u0026gt;.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;So far this is just fairly normal SIMD using SWAR techniques with a few clever optimizations.  Continuing on with the same pattern for 2 more steps can widen to 2x 16-bit then 1x 32-bit counts.  But there is a more efficient way on machines with fast hardware multiply:\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;Once we have few enough \u0026quot;elements\u0026quot;, \u0026lt;strong\u0026gt;a multiply with a magic constant can sum all the elements into the top element\u0026lt;/strong\u0026gt;.  In this case byte elements.  Multiply is done by left-shifting and adding, so \u0026lt;strong\u0026gt;a multiply of \u0026lt;code\u0026gt;x * 0x01010101\u0026lt;/code\u0026gt; results in \u0026lt;code\u0026gt;x + (x\u0026amp;lt;\u0026amp;lt;8) + (x\u0026amp;lt;\u0026amp;lt;16) + (x\u0026amp;lt;\u0026amp;lt;24)\u0026lt;/code\u0026gt;.\u0026lt;/strong\u0026gt;  Our 8-bit elements are wide enough (and holding small enough counts) that this doesn\u0026apos;t produce carry \u0026lt;em\u0026gt;into\u0026lt;/em\u0026gt; that top 8 bits.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;A 64-bit version of this\u0026lt;/strong\u0026gt; can do 8x 8-bit elements in a 64-bit integer with a 0x0101010101010101 multiplier, and extract the high byte with \u0026lt;code\u0026gt;\u0026amp;gt;\u0026amp;gt;56\u0026lt;/code\u0026gt;.  So it doesn\u0026apos;t take any extra steps, just wider constants.  This is what GCC uses for \u0026lt;code\u0026gt;__builtin_popcountll\u0026lt;/code\u0026gt; on x86 systems when the hardware \u0026lt;code\u0026gt;popcnt\u0026lt;/code\u0026gt; instruction isn\u0026apos;t enabled.  If you can use builtins or intrinsics for this, do so to give the compiler a chance to do target-specific optimizations.\u0026lt;/p\u0026gt;\n\u0026lt;hr\u0026gt;\n\u0026lt;h3\u0026gt;With full SIMD for wider vectors (e.g. counting a whole array)\u0026lt;/h3\u0026gt;\n\u0026lt;p\u0026gt;This bitwise-SWAR algorithm could parallelize to be done in multiple vector elements at once, instead of in a single integer register, for a speedup on CPUs with SIMD but no usable popcount instruction.  (e.g. x86-64 code that has to run on any CPU, not just Nehalem or later.)\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;However, the best way to use vector instructions for popcount is usually by using a variable-shuffle to do a table-lookup for 4 bits at a time of each byte in parallel.  (The 4 bits index a 16 entry table held in a vector register).\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;On Intel CPUs, the hardware 64bit popcnt instruction can outperform an \u0026lt;a href=\u0026quot;http://wm.ite.pl/articles/sse-popcount.html\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;SSSE3 \u0026lt;code\u0026gt;PSHUFB\u0026lt;/code\u0026gt; bit-parallel implementation\u0026lt;/a\u0026gt; by about a factor of 2, but only \u0026lt;a href=\u0026quot;http://danluu.com/assembly-intrinsics/\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;if your compiler gets it just right\u0026lt;/a\u0026gt;.  Otherwise SSE can come out significantly ahead.  Newer compiler versions are aware of the \u0026lt;a href=\u0026quot;https://stackoverflow.com/a/25089720/224132\u0026quot;\u0026gt;popcnt false dependency\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026quot;https://gcc.gnu.org/bugzilla/show_bug.cgi?id=62011\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;problem on Intel\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\n\u0026lt;ul\u0026gt;\n\u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;https://github.com/WojciechMula/sse-popcount\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;https://github.com/WojciechMula/sse-popcount\u0026lt;/a\u0026gt; state-of-the-art x86 SIMD popcount for SSSE3, AVX2, AVX512BW, AVX512VBMI, or AVX512 VPOPCNT.  Using Harley-Seal across vectors to defer popcount within an element.  (Also ARM NEON)\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;\u0026lt;a href=\u0026quot;https://stackoverflow.com/questions/50081465/counting-1-bits-population-count-on-large-data-using-avx-512-or-avx-2\u0026quot;\u0026gt;Counting 1 bits (population count) on large data using AVX-512 or AVX-2\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;related: \u0026lt;a href=\u0026quot;https://github.com/mklarqvist/positional-popcount\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;https://github.com/mklarqvist/positional-popcount\u0026lt;/a\u0026gt; - separate counts for each bit-position of multiple 8, 16, 32, or 64-bit integers.  (Again, x86 SIMD including AVX-512 which is really good at this, with \u0026lt;code\u0026gt;vpternlogd\u0026lt;/code\u0026gt; making Harley-Seal \u0026lt;em\u0026gt;very\u0026lt;/em\u0026gt; good.)\u0026lt;/li\u0026gt;\n\u0026lt;/ul\u0026gt;\n    ","\n\u0026lt;p\u0026gt;Some languages portably expose the operation in a way that \u0026lt;em\u0026gt;can\u0026lt;/em\u0026gt; use efficient hardware support if available, otherwise some library fallback that\u0026apos;s hopefully decent.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;For example (from \u0026lt;a href=\u0026quot;https://en.wikichip.org/wiki/population_count#Software_support\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;a table by language\u0026lt;/a\u0026gt;):\u0026lt;/p\u0026gt;\n\u0026lt;ul\u0026gt;\n\u0026lt;li\u0026gt;C++ has \u0026lt;code\u0026gt;std::bitset\u0026amp;lt;\u0026amp;gt;::count()\u0026lt;/code\u0026gt;, or  \u0026lt;a href=\u0026quot;https://en.cppreference.com/w/cpp/numeric/popcount\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;C++20 \u0026lt;code\u0026gt;std::popcount(T x)\u0026lt;/code\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;Java has \u0026lt;code\u0026gt;java.lang.Integer.bitCount()\u0026lt;/code\u0026gt; (also for Long or BigInteger)\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;C# has \u0026lt;code\u0026gt;System.Numerics.BitOperations.PopCount()\u0026lt;/code\u0026gt;\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;Python has \u0026lt;code\u0026gt;int.bit_count()\u0026lt;/code\u0026gt; (since 3.10)\u0026lt;/li\u0026gt;\n\u0026lt;/ul\u0026gt;\n\u0026lt;p\u0026gt;Not all compilers / libraries actually manage to use HW support when it\u0026apos;s available, though. (Notably MSVC, even with options that make std::popcount inline as x86 popcnt, its std::bitset::count still always uses a lookup table.  This will hopefully change in future versions.)\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;Also consider the built-in functions of your compiler when the portable language doesn\u0026apos;t have this basic bit operation.  In GNU C for example:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre class=\u0026quot;lang-c++ s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-c\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;int\u0026lt;/span\u0026gt; __builtin_popcount (\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;unsigned\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;int\u0026lt;/span\u0026gt; x);\n\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;int\u0026lt;/span\u0026gt; __builtin_popcountll (\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;unsigned\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;long\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;long\u0026lt;/span\u0026gt; x);\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;In the worst case (no single-instruction HW support) the compiler will generate a call to a function (which in current GCC uses a shift/and bit-hack \u0026lt;a href=\u0026quot;https://stackoverflow.com/questions/109023/how-to-count-the-number-of-set-bits-in-a-32-bit-integer/109025#109025\u0026quot;\u0026gt;like this answer\u0026lt;/a\u0026gt;, at least for x86). In the best case the compiler will emit a cpu instruction to do the job. (Just like a \u0026lt;code\u0026gt;*\u0026lt;/code\u0026gt; or \u0026lt;code\u0026gt;/\u0026lt;/code\u0026gt; operator - GCC will use a hardware multiply or divide instruction if available, otherwise will call a libgcc helper function.)  Or even better, if the operand is a compile-time constant after inlining, it can do constant-propagation to get a compile-time-constant popcount result.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;The GCC builtins even work across multiple platforms. Popcount has almost become mainstream in the x86 architecture, so it makes sense to start using the builtin now so you can recompile to let it inline a hardware instruction when you compile with \u0026lt;code\u0026gt;-mpopcnt\u0026lt;/code\u0026gt; or something that includes that (e.g. \u0026lt;a href=\u0026quot;https://godbolt.org/z/Ma5e5a\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;https://godbolt.org/z/Ma5e5a\u0026lt;/a\u0026gt;). Other architectures have had popcount for years, but in the x86 world there are still some ancient Core 2 and similar vintage AMD CPUs in use.\u0026lt;/p\u0026gt;\n\u0026lt;hr\u0026gt;\n\u0026lt;p\u0026gt;On x86, you can tell the compiler that it can assume support for \u0026lt;code\u0026gt;popcnt\u0026lt;/code\u0026gt; instruction with \u0026lt;code\u0026gt;-mpopcnt\u0026lt;/code\u0026gt; (also implied by \u0026lt;code\u0026gt;-msse4.2\u0026lt;/code\u0026gt;).  See \u0026lt;a href=\u0026quot;https://gcc.gnu.org/onlinedocs/gcc/x86-Options.html\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;GCC x86 options\u0026lt;/a\u0026gt;.  \u0026lt;code\u0026gt;-march=nehalem -mtune=skylake\u0026lt;/code\u0026gt; (or \u0026lt;code\u0026gt;-march=\u0026lt;/code\u0026gt; whatever CPU you want your code to assume and to tune for) could be a good choice.   Running the resulting binary on an older CPU will result in an illegal-instruction fault.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;To make binaries optimized for the machine you build them on, \u0026lt;strong\u0026gt;use \u0026lt;code\u0026gt;-march=native\u0026lt;/code\u0026gt;\u0026lt;/strong\u0026gt;  (with gcc, clang, or ICC).\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;\u0026lt;a href=\u0026quot;https://stackoverflow.com/questions/3849337/msvc-equivalent-to-builtin-popcount\u0026quot;\u0026gt;MSVC provides an intrinsic for the x86 \u0026lt;code\u0026gt;popcnt\u0026lt;/code\u0026gt; instruction\u0026lt;/a\u0026gt;, but unlike gcc it\u0026apos;s really an intrinsic for the hardware instruction and requires hardware support.\u0026lt;/p\u0026gt;\n\u0026lt;hr\u0026gt;\n\u0026lt;h2\u0026gt;Using \u0026lt;code\u0026gt;std::bitset\u0026amp;lt;\u0026amp;gt;::count()\u0026lt;/code\u0026gt; instead of a built-in\u0026lt;/h2\u0026gt;\n\u0026lt;p\u0026gt;In theory, any compiler that knows how to popcount efficiently for the target CPU should expose that functionality through ISO C++ \u0026lt;a href=\u0026quot;http://en.cppreference.com/w/cpp/utility/bitset/count\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;\u0026lt;code\u0026gt;std::bitset\u0026amp;lt;\u0026amp;gt;\u0026lt;/code\u0026gt;\u0026lt;/a\u0026gt;.  In practice, you might be better off with the bit-hack AND/shift/ADD in some cases for some target CPUs.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;For target architectures where hardware popcount is an optional extension (like x86), not all compilers have a \u0026lt;code\u0026gt;std::bitset\u0026lt;/code\u0026gt; that takes advantage of it when available.  For example, MSVC has no way to enable \u0026lt;code\u0026gt;popcnt\u0026lt;/code\u0026gt; support at compile time, and it\u0026apos;s \u0026lt;code\u0026gt;std::bitset\u0026amp;lt;\u0026amp;gt;::count\u0026lt;/code\u0026gt; always uses \u0026lt;a href=\u0026quot;https://stackoverflow.com/questions/12324081/how-does-this-implementation-of-bitsetcount-work\u0026quot;\u0026gt;a table lookup\u0026lt;/a\u0026gt;, even with \u0026lt;code\u0026gt;/Ox /arch:AVX\u0026lt;/code\u0026gt; (which implies SSE4.2, which in turn implies the popcnt feature.)  (Update: see below; that \u0026lt;em\u0026gt;does\u0026lt;/em\u0026gt; get MSVC\u0026apos;s C++20 \u0026lt;code\u0026gt;std::popcount\u0026lt;/code\u0026gt; to use x86 \u0026lt;code\u0026gt;popcnt\u0026lt;/code\u0026gt;, but still not its bitset\u0026amp;lt;\u0026amp;gt;::count.  MSVC could fix that by updating their standard library headers to use std::popcount when available.)\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;But at least you get something portable that works everywhere, and with gcc/clang with the right target options, you get hardware popcount for architectures that support it.\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-c++ s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-c\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;#\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;include\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026amp;lt;bitset\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;#\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;include\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026amp;lt;limits\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;#\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;include\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026amp;lt;type_traits\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\n\ntemplate\u0026amp;lt;typename T\u0026amp;gt;\n\u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;//static inline  // static if you want to compile with -mpopcnt in one compilation unit but not others\u0026lt;/span\u0026gt;\ntypename \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;std\u0026lt;/span\u0026gt;::enable_if\u0026amp;lt;\u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;std\u0026lt;/span\u0026gt;::is_integral\u0026amp;lt;T\u0026amp;gt;::value,  \u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;unsigned\u0026lt;/span\u0026gt; \u0026amp;gt;::type \n\u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;popcount\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;(T x)\u0026lt;/span\u0026gt;\n{\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;static_assert\u0026lt;/span\u0026gt;(\u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;std\u0026lt;/span\u0026gt;::numeric_limits\u0026amp;lt;T\u0026amp;gt;::radix == \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;2\u0026lt;/span\u0026gt;, \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;non-binary type\u0026quot;\u0026lt;/span\u0026gt;);\n\n    \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;// sizeof(x)*CHAR_BIT\u0026lt;/span\u0026gt;\n    constexpr \u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;int\u0026lt;/span\u0026gt; bitwidth = \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;std\u0026lt;/span\u0026gt;::numeric_limits\u0026amp;lt;T\u0026amp;gt;::digits + \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;std\u0026lt;/span\u0026gt;::numeric_limits\u0026amp;lt;T\u0026amp;gt;::is_signed;\n    \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;// std::bitset constructor was only unsigned long before C++11.  Beware if porting to C++03\u0026lt;/span\u0026gt;\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;static_assert\u0026lt;/span\u0026gt;(bitwidth \u0026amp;lt;= \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;std\u0026lt;/span\u0026gt;::numeric_limits\u0026amp;lt;\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;unsigned\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;long\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;long\u0026lt;/span\u0026gt;\u0026amp;gt;::digits, \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026quot;arg too wide for std::bitset() constructor\u0026quot;\u0026lt;/span\u0026gt;);\n\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;typedef\u0026lt;/span\u0026gt; typename \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;std\u0026lt;/span\u0026gt;::make_unsigned\u0026amp;lt;T\u0026amp;gt;::type UT;        \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;// probably not needed, bitset width chops after sign-extension\u0026lt;/span\u0026gt;\n\n    \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;std\u0026lt;/span\u0026gt;::\u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;bitset\u0026lt;/span\u0026gt;\u0026amp;lt;bitwidth\u0026amp;gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;bs\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;( static_cast\u0026amp;lt;UT\u0026amp;gt;(x) )\u0026lt;/span\u0026gt;;\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;return\u0026lt;/span\u0026gt; bs.count();\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;See \u0026lt;a href=\u0026quot;https://gcc.godbolt.org/#z:OYLghAFBqd5TKALEBjA9gEwKYFFMCWALugE4A0BIEAViAIzkDO6ArqatiAOQCkATAGYCAO1QAbVjgDUvQQGEARsSbYic3LwAMAQQHCxkmXPniCAWxUbteoaIlTsshUQCeAB2wB9IqQCGVoKaugD0IdIAqqrSREhOSOieAGas4uKuALTA6FjSTESYICDKRKpERRisIkQQAJTSFu7i2ObY1X5EBOgi0klk0n6kJf6krg3V2MDYpDEe2Ew2YdI6AG7oBJhMeQTAIhnYAB5EbYQiwNu72Jizngu6i%2BEA8j3AqKgDItcSfmfk0tgAR1YBBWfma1Ri6GkXi8imB4k6Ii87kSlWqaTqD2kmHQAHcREwNlwBuJcX5XFtWKotgA2AAsGRK0kS0x%2BmAyhIAXk4IN1pPTGcRpPIAApRWpYgBiZE4W25pHQ%2ByObUJfJI/IZJQAdFidOIWHlxHjptJccQEqwiNIkINMGTSE4Ue40UQ/vNPKgCGD0qbzQMYn5FM0Mkb0ABrVjuaSh9w60JPHoHAAcNL%2BuLI0ViCtYwCQ7ktzJ6OgAsgARaQAIVS4hx8oyST8lh9sR%2B0kE/EFVqdqGquv1ULJ%2BXm/oASrgABrSdwOpIEA5xvS6Y7mJodbAmNyeESNpwAFWs8fyHQI71EZhETmkSyPnVPSWkrjYpp%2BVvVGBXBGavti0gyK9REKiIWTjvu4n7HnyVRCnCVoiOgVrwXEpB3Dom5tDueQFEU6FBt4BBJCY%2BSFCABBMF4ojHMA/jiCY%2B5BEUoKSNgfzSFUhKXNcGhFGhsi6N2bDVBAu7SAcEr3AA7BWNjaAAnDeJ5eH4TCqKQNREUUIisK0pAKWYlilLRXEgP4hAHM4pZyOW/B/AI/BwXsyjbqMNzrvw/ASoIUn3N5MnXgQ3LoEkECiQAVPIAASOgjl4FYAJL7j5GAEscBzTuMVolGamA/pZmHEZp2m6RYgTyHRuBFIQwAqLI/AVnlGladMRX6QsChlUUpFeOxF6YHIXmLr54TqcUKhqNISX5KQrCoCQMyDoWPpsTsPXRt05yKNgfQOsKAhSbV9D0Fq0iVtg9pOPhU5kIi5zqvIu27Vogg2Mdx3yaginKdMNSZRsOUKLlw0FU1716SVS0catZyQ8ARmVSoNluYMN05L6MhbfVI2lGodTjd0k3TbNtkef10laDJaE4PeaHbq0GPmH4YbeODPWGfRIA8REdF1S9PNLNO6CKIGPpwbB2BXFcfwlGUqM/qgCTuFsfhJMcMzdUqxwEl0Iik3JWGY2UJg/dlSAaNIihMBAmHHu9qBKeoCicxowX1MTOsOkQ7A9ObWoupinnSeJFneYuOjM1cMTzEQyKogJUdMAkqkQPHV0DPUvCSdI7ue5dzqxxAfjE7Igc2GH1zHPk0e51UUcURAFGp0XdVZ6QPT8dX%2BeF%2BnQc6GEpcRxXbfVF4pcQH3BeN5najZ4PNQF31Rfd335dRzP9IQEaUMb%2Bc4/p03U8tznvtz55C9YjhzTkfe%2BSJFssSkb0CrmLjH7nsj/o4qwuEZBofdJSs0yqm1vGJekdK7vQ/rhCAECvw7wzs3VuMd27Hzql3UmId659HQEnBOVo/B/C3tDM2adJJu33j0HWh8847x8rtSh7dFCu10C9PqAdu5oKWDCCi9B%2BBJgaFsLKJoWw9D7gQre0k7D3noDVGkAgaTYk2qIK4EAYQAGVYoAC1cCPElF4WKAA5Xc3CkwwjEj3cIsQnBvQ%2BipK018FYxCQPfJIj9n5gVftICA6pug%2BhdA4pwRpcTWjBEkUxvdNYQ2XmA2ORjlHkWqEYhuu9J4ewPjPDu89UHByWLuRxWwbSoDDKaMgYYth8leKgEI3wzggAGMpRqZtRpWnvmCMkFJejiA6NIVo5gyCuBAM9F6SxYrRk2q%2BXJzICyBT8RHFcHTjhm2wLbKk50iBgG4FsEWl1VJC3XD5MI%2BEk7%2BWwIFZ2zhcDbACkFERa1oa1DTns8IL1umoHcK4CAsjzYIxpAcP4XJjlBXNnclhwd9D2CME4EwqBJqiBhkEEu4SVr5LDFE6uMTOHxJ4YkkhPlhpSzUCYIxptzbpP9j5Z5rz3n8BpJ86ReCLn/IgICwuV5wj2hEDCmpGBXkwo%2BMyRQNBFkIXvPZDIvgQRenEC5DxZofww1qrtUxsl4FmyYD7POjC9DF3uEIE4%2BEbDcFqOQcQPAACs3ByAiB4Foc16AeB3XlbVPIbAOAQqEPQc15RuDWrueQMMIBBBJi1FoGk4lxL0BkgGmkSYkxaC0HSI1PA6TmvMCAcSWgtT0BpDSdsWhM3Zv4Lm1MlqvU2p4OapgIAtDkE9d68gcBYAoFAp%2BaYlBqBNuaKQEA7hnT0maMAbNVbZwIgAdQRQVrzXvlaNUZ46Rx3kEIA6GaIJ5hzootgY1JbDVmHNvAQ1iROh4x4BkAA6t6X8jxBC/iIpZXYrB7r7XdcwZ1nAGBbtNea4t1ryC2u4CKY0pARTyA1PyLUggg0ePwMQfo%2BhGDCnQC/E0MHagevHT6uIfgcCdrqAm7gSbyApv4DJLUSZBCCBDTJEjZHxIUYDRaudP7y2Vurahw1fqA1BpDWGiNKZo2xvjRuwQH76NluY5uutiB63IDQPBtxLaqAQHbdMNAHSzhkZ%2BUOlWFbGVzsnW0IgM6%2BklvnQQRdnR/4VqM2ujdtbt0VsgHu9wB6CRHuvYIUst770VgOlego27LLbtQJ538p60jnsvX%2BbsEI/yDDlpZG0TBcTrvEOW59XBGBkmnY52KIg%2Bg8HdW%2B7gZq6NGZ/cmGkGR6TjRU%2BcMDciICQdmjVQQsH5AyebTMfQghkOie9Ya9DmHqCsf9YGmSdIkwmpkuJJMdITUxqozhvDKbSPEfoLm3NMkZLcJNVNmSxWv0MeYExmtBrxPwAgI2trHbW0Kcu0p4AdJRvkA0yO2JXgtCDfIGOozunp0iFnUZhdgrl0Wa/VZudNAgTTEM2B/gGbzXgmALEBg5BpzYBWI8flgrqAwje9QLknJmj0BNcG4Nm2TV0jG4IagVRKaKMKOvSYJx4D0HEoINNu2q3cHy3crdbREcoEYKj9HmOZrY5hO92gABFVgUP2yrZI4RmSNJHoza0MTjbJr6DUEIEwVchmTv48J8T5XNIycU5I9Tz4CierUD7UzyALO2dk3IJz7nPqEdI/oDzo1BAd32e/Y5rWFmT1noyBenzvU3MeYdV5qREWAJWmixwE2bn4uJbSCl9gL6vc4aK5%2B0t3AysVbpNIcp0g6RaiIyX%2BrhBGswb%2BK1hDHWhAmu68d93ibk3%2BpNcRmkE2c1K7I3SAtJq9sF8Y1W9vp2G3Sab9dxTnaTyoBZ09z8mmxe4%2Bw19r9P39N/cM1%2BwHS7zOromNZ81EOZejB4DDuHRq%2Bee5Rw6YXArRevYl4b7AROSem6J%2Bbqno8Vus4NuDOUwnwzO4kBaq2Lu5AXOBq3uHuAuT%2BaOGOr%2B5Q7%2B1ANA0usu/A8u7YG2yuggqu6uMkmu2upEeuZahqn%2B3%2BJuZulOlutOIBdu4BDukBa2MBcBPOvOZwnuCBvudm2G%2B6QeR6IWkqYe4Wrm7mmknm3m8ezoUW9Myelk24Zm2AmeLqr6ueQmJWPARelWS%2B0gLOEGte0GbqDet2zeRBbeLG5A/WSm2GG6i2/q6a7YggSuE23CbO1GY%2B36ImFak%2BthbGYGY2fej0SYrO/AkBYaOGgmvhB2U%2Bkm52s%2BsmFA8mC%2Bym4aXg9Iq%2Bw6yEo6Om8GU6e%2B/2h%2BJmQOJ%2BlmZ%2BqGPufuQhgeh63AIQjwZkIQMWKAOgAAauOBodnuQBlvplljlj%2BvltofEXoSmMXsKAADJGEyTSBQHiTSAji7jHomFQZWEtaWFNbuQoabpDY8JagU7bbiQhruHTaQF94LY6H7b%2BFHa2Ebr8Bd6rZVr55%2BHcB7G9bkD/zIRawgB0hAA%3D\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;asm from gcc, clang, icc, and MSVC\u0026lt;/a\u0026gt; on the Godbolt compiler explorer.\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;x86-64 \u0026lt;code\u0026gt;gcc -O3 -std=gnu++11 -mpopcnt\u0026lt;/code\u0026gt; emits this:\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-c++ s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-c\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;unsigned\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;test_short\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;(\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;short\u0026lt;/span\u0026gt; a)\u0026lt;/span\u0026gt; { \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;return\u0026lt;/span\u0026gt; popcount(a); }\n    movzx   eax, di      \u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;# note zero-extension, not sign-extension\u0026lt;/span\u0026gt;\n    popcnt  rax, rax\n    ret\n\n\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;unsigned\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;test_int\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;(\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;int\u0026lt;/span\u0026gt; a)\u0026lt;/span\u0026gt; { \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;return\u0026lt;/span\u0026gt; popcount(a); }\n    mov     eax, edi\n    popcnt  rax, rax        \u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;# unnecessary 64-bit operand size\u0026lt;/span\u0026gt;\n    ret\n\n\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;unsigned\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;test_u64\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;(\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;unsigned\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;long\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;long\u0026lt;/span\u0026gt; a)\u0026lt;/span\u0026gt; { \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;return\u0026lt;/span\u0026gt; popcount(a); }\n    xor     eax, eax     \u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;# gcc avoids false dependencies for Intel CPUs\u0026lt;/span\u0026gt;\n    popcnt  rax, rdi\n    ret\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;PowerPC64 \u0026lt;code\u0026gt;gcc -O3 -std=gnu++11\u0026lt;/code\u0026gt; emits (for the \u0026lt;code\u0026gt;int\u0026lt;/code\u0026gt; arg version):\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-c++ s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-c\u0026quot;\u0026gt;    rldicl \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;3\u0026lt;/span\u0026gt;,\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;3\u0026lt;/span\u0026gt;,\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0\u0026lt;/span\u0026gt;,\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;32\u0026lt;/span\u0026gt;     \u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;# zero-extend from 32 to 64-bit\u0026lt;/span\u0026gt;\n    popcntd \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;3\u0026lt;/span\u0026gt;,\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;3\u0026lt;/span\u0026gt;         \u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;# popcount\u0026lt;/span\u0026gt;\n    blr\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;This source isn\u0026apos;t x86-specific or GNU-specific at all, but only compiles well with gcc/clang/icc, at least when targeting x86 (including x86-64).\u0026lt;/p\u0026gt;\n\u0026lt;p\u0026gt;Also note that gcc\u0026apos;s fallback for architectures without single-instruction popcount is a byte-at-a-time table lookup.  This isn\u0026apos;t wonderful \u0026lt;a href=\u0026quot;https://stackoverflow.com/questions/15736602/fastest-way-to-count-number-of-1s-in-a-register-arm-assembly\u0026quot;\u0026gt;for ARM, for example\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\n\u0026lt;h2\u0026gt;\u0026lt;a href=\u0026quot;https://en.cppreference.com/w/cpp/numeric/popcount\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;C++20 has \u0026lt;code\u0026gt;std::popcount(T)\u0026lt;/code\u0026gt;\u0026lt;/a\u0026gt;\u0026lt;/h2\u0026gt;\n\u0026lt;p\u0026gt;Current libstdc++ headers unfortunately define it with a special case \u0026lt;code\u0026gt;if(x==0) return 0;\u0026lt;/code\u0026gt; at the start, which clang doesn\u0026apos;t optimize away when compiling for x86:\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-c++ s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-c\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;#\u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;include\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-string\u0026quot;\u0026gt;\u0026amp;lt;bit\u0026amp;gt;\u0026lt;/span\u0026gt;\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;int\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;bar\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;(\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;unsigned\u0026lt;/span\u0026gt; x)\u0026lt;/span\u0026gt; {\n    \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;return\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-built_in\u0026quot;\u0026gt;std\u0026lt;/span\u0026gt;::popcount(x);\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;clang 11.0.1 \u0026lt;code\u0026gt;-O3  -std=gnu++20 -march=nehalem\u0026lt;/code\u0026gt;  (\u0026lt;a href=\u0026quot;https://godbolt.org/z/arMe5a\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;https://godbolt.org/z/arMe5a\u0026lt;/a\u0026gt;)\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-c++ s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-c\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;# clang 11\u0026lt;/span\u0026gt;\n    bar(\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;unsigned\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;int\u0026lt;/span\u0026gt;):                                # @bar(\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;unsigned\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;int\u0026lt;/span\u0026gt;)\n        popcnt  eax, edi\n        cmove   eax, edi         \u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;# redundant: \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;if\u0026lt;/span\u0026gt; popcnt result is 0, return the original 0 instead of the popcnt-generated 0...\u0026lt;/span\u0026gt;\n        ret\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;But GCC compiles nicely:\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-c++ s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-c\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;# gcc 10\u0026lt;/span\u0026gt;\n        xor     eax, eax         \u0026lt;span class=\u0026quot;hljs-meta\u0026quot;\u0026gt;# break false dependency on Intel SnB-family before Ice Lake.\u0026lt;/span\u0026gt;\n        popcnt  eax, edi\n        ret\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;p\u0026gt;Even MSVC does well with it, as long as you use \u0026lt;code\u0026gt;-arch:AVX\u0026lt;/code\u0026gt;  or later (and enable C++20 with \u0026lt;code\u0026gt;-std:c++latest\u0026lt;/code\u0026gt;). \u0026lt;a href=\u0026quot;https://godbolt.org/z/7K4Gef\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;https://godbolt.org/z/7K4Gef\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n\u0026lt;pre class=\u0026quot;lang-c++ s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-c\u0026quot;\u0026gt;\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;int\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;bar\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;(\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;unsigned\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;int\u0026lt;/span\u0026gt;)\u0026lt;/span\u0026gt; PROC                                 ; bar, COMDAT\n        popcnt  eax, ecx\n        ret     \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0\u0026lt;/span\u0026gt;\n\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;int\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;bar\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;(\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;unsigned\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;int\u0026lt;/span\u0026gt;)\u0026lt;/span\u0026gt; ENDP                                 ; bar\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n    ","\n\u0026lt;p\u0026gt;In my opinion, the \u0026quot;best\u0026quot; solution is the one that can be read by another programmer (or the original programmer two years later) without copious comments.  You may well want the fastest or cleverest solution which some have already provided but I prefer readability over cleverness any time.\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;unsigned int bitCount (unsigned int value) {\n    unsigned int count = 0;\n    while (value \u0026amp;gt; 0) {           // until all bits are zero\n        if ((value \u0026amp;amp; 1) == 1)     // check lower bit\n            count++;\n        value \u0026amp;gt;\u0026amp;gt;= 1;              // shift bits, removing lower bit\n    }\n    return count;\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;If you want more speed (and assuming you document it well to help out your successors), you could use a table lookup:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;// Lookup table for fast calculation of bits set in 8-bit unsigned char.\n\nstatic unsigned char oneBitsInUChar[] = {\n//  0  1  2  3  4  5  6  7  8  9  A  B  C  D  E  F (\u0026amp;lt;- n)\n//  =====================================================\n    0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4, // 0n\n    1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5, // 1n\n    : : :\n    4, 5, 5, 6, 5, 6, 6, 7, 5, 6, 6, 7, 6, 7, 7, 8, // Fn\n};\n\n// Function for fast calculation of bits set in 16-bit unsigned short.\n\nunsigned char oneBitsInUShort (unsigned short x) {\n    return oneBitsInUChar [x \u0026amp;gt;\u0026amp;gt;    8]\n         + oneBitsInUChar [x \u0026amp;amp;  0xff];\n}\n\n// Function for fast calculation of bits set in 32-bit unsigned int.\n\nunsigned char oneBitsInUInt (unsigned int x) {\n    return oneBitsInUShort (x \u0026amp;gt;\u0026amp;gt;     16)\n         + oneBitsInUShort (x \u0026amp;amp;  0xffff);\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Although these rely on specific data type sizes so they\u0026apos;re not that portable. But, since many performance optimisations aren\u0026apos;t portable anyway, that may not be an issue. If you want portability, I\u0026apos;d stick to the readable solution.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;\u0026lt;a href=\u0026quot;http://books.google.com/books?id=iBNKMspIlqEC\u0026amp;amp;pg=PA66\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;From Hacker\u0026apos;s Delight, p. 66, Figure 5-2\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;int pop(unsigned x)\n{\n    x = x - ((x \u0026amp;gt;\u0026amp;gt; 1) \u0026amp;amp; 0x55555555);\n    x = (x \u0026amp;amp; 0x33333333) + ((x \u0026amp;gt;\u0026amp;gt; 2) \u0026amp;amp; 0x33333333);\n    x = (x + (x \u0026amp;gt;\u0026amp;gt; 4)) \u0026amp;amp; 0x0F0F0F0F;\n    x = x + (x \u0026amp;gt;\u0026amp;gt; 8);\n    x = x + (x \u0026amp;gt;\u0026amp;gt; 16);\n    return x \u0026amp;amp; 0x0000003F;\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Executes in ~20-ish instructions (arch dependent), no branching.\u0026lt;br\u0026gt;\u0026lt;br\u0026gt;\u0026lt;a href=\u0026quot;http://books.google.com/books?id=iBNKMspIlqEC\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;Hacker\u0026apos;s Delight\u0026lt;/a\u0026gt; \u0026lt;em\u0026gt;is\u0026lt;/em\u0026gt; delightful! Highly recommended.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;I think the fastest waywithout using lookup tables and \u0026lt;em\u0026gt;popcount\u0026lt;/em\u0026gt;is the following. It counts the set bits with just 12 operations.\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;int popcount(int v) {\n    v = v - ((v \u0026amp;gt;\u0026amp;gt; 1) \u0026amp;amp; 0x55555555);                // put count of each 2 bits into those 2 bits\n    v = (v \u0026amp;amp; 0x33333333) + ((v \u0026amp;gt;\u0026amp;gt; 2) \u0026amp;amp; 0x33333333); // put count of each 4 bits into those 4 bits  \n    return c = ((v + (v \u0026amp;gt;\u0026amp;gt; 4) \u0026amp;amp; 0xF0F0F0F) * 0x1010101) \u0026amp;gt;\u0026amp;gt; 24;\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;It works because you can count the total number of set bits by dividing in two halves, counting the number of set bits in both halves and then adding them up. Also know as \u0026lt;code\u0026gt;Divide and Conquer\u0026lt;/code\u0026gt; paradigm. Let\u0026apos;s get into detail.. \u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;v = v - ((v \u0026amp;gt;\u0026amp;gt; 1) \u0026amp;amp; 0x55555555); \n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;The number of bits in two bits can be \u0026lt;code\u0026gt;0b00\u0026lt;/code\u0026gt;, \u0026lt;code\u0026gt;0b01\u0026lt;/code\u0026gt; or \u0026lt;code\u0026gt;0b10\u0026lt;/code\u0026gt;. Lets try to work this out on 2 bits.. \u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt; ---------------------------------------------\n |   v    |   (v \u0026amp;gt;\u0026amp;gt; 1) \u0026amp;amp; 0b0101   |  v - x   |\n ---------------------------------------------\n   0b00           0b00               0b00   \n   0b01           0b00               0b01     \n   0b10           0b01               0b01\n   0b11           0b01               0b10\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;This is what was required: the last column shows the count of set bits in every two bit pair. If the two bit number is \u0026lt;code\u0026gt;\u0026amp;gt;= 2 (0b10)\u0026lt;/code\u0026gt; then \u0026lt;code\u0026gt;and\u0026lt;/code\u0026gt; produces \u0026lt;code\u0026gt;0b01\u0026lt;/code\u0026gt;, else it produces \u0026lt;code\u0026gt;0b00\u0026lt;/code\u0026gt;. \u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;v = (v \u0026amp;amp; 0x33333333) + ((v \u0026amp;gt;\u0026amp;gt; 2) \u0026amp;amp; 0x33333333); \n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;This statement should be easy to understand. After the first operation we have the count of set bits in every two bits, now we sum up that count in every 4 bits.\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;v \u0026amp;amp; 0b00110011         //masks out even two bits\n(v \u0026amp;gt;\u0026amp;gt; 2) \u0026amp;amp; 0b00110011  // masks out odd two bits\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;We then sum up the above result, giving us the total count of set bits in 4 bits. The last statement is the most tricky.\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;c = ((v + (v \u0026amp;gt;\u0026amp;gt; 4) \u0026amp;amp; 0xF0F0F0F) * 0x1010101) \u0026amp;gt;\u0026amp;gt; 24;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Let\u0026apos;s break it down further... \u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;v + (v \u0026amp;gt;\u0026amp;gt; 4)\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;It\u0026apos;s similar to the second statement; we are counting the set bits in groups of 4 instead. We knowbecause of our previous operationsthat every nibble has the count of set bits in it. Let\u0026apos;s look an example. Suppose we have the byte \u0026lt;code\u0026gt;0b01000010\u0026lt;/code\u0026gt;. It means the first nibble has its 4bits set and the second one has its 2bits set. Now we add those nibbles together. \u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;0b01000010 + 0b01000000\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;It gives us the count of set bits in a byte, in the first nibble \u0026lt;code\u0026gt;0b01100010\u0026lt;/code\u0026gt; and therefore we mask the last four bytes of all the bytes in the number (discarding them).\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;0b01100010 \u0026amp;amp; 0xF0 = 0b01100000\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Now every byte has the count of set bits in it. We need to add them up all together. The trick is to multiply the result by \u0026lt;code\u0026gt;0b10101010\u0026lt;/code\u0026gt; which has an interesting property. If our number has four bytes, \u0026lt;code\u0026gt;A B C D\u0026lt;/code\u0026gt;, it will result in a new number with these bytes \u0026lt;code\u0026gt;A+B+C+D B+C+D C+D D\u0026lt;/code\u0026gt;. A 4 byte number can have maximum of 32 bits set, which can be represented as \u0026lt;code\u0026gt;0b00100000\u0026lt;/code\u0026gt;.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;All we need now is the first byte which has the sum of all set bits in all the bytes, and we get it by  \u0026lt;code\u0026gt;\u0026amp;gt;\u0026amp;gt; 24\u0026lt;/code\u0026gt;. This algorithm was designed for \u0026lt;code\u0026gt;32 bit\u0026lt;/code\u0026gt; words but can be easily modified for \u0026lt;code\u0026gt;64 bit\u0026lt;/code\u0026gt; words.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;If you happen to be using Java, the built-in method \u0026lt;code\u0026gt;Integer.bitCount\u0026lt;/code\u0026gt; will do that.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;I got bored, and timed a billion iterations of three approaches. Compiler is gcc -O3. CPU is whatever they put in the 1st gen Macbook Pro.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;Fastest is the following, at 3.7 seconds:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;static unsigned char wordbits[65536] = { bitcounts of ints between 0 and 65535 };\nstatic int popcount( unsigned int i )\n{\n    return( wordbits[i\u0026amp;amp;0xFFFF] + wordbits[i\u0026amp;gt;\u0026amp;gt;16] );\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Second place goes to the same code but looking up 4 bytes instead of 2 halfwords. That took around 5.5 seconds.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;Third place goes to the bit-twiddling \u0026apos;sideways addition\u0026apos; approach, which took 8.6 seconds.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;Fourth place goes to GCC\u0026apos;s __builtin_popcount(), at a shameful 11 seconds.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;The counting one-bit-at-a-time approach was waaaay slower, and I got bored of waiting for it to complete.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;So if you care about performance above all else then use the first approach. If you care, but not enough to spend 64Kb of RAM on it, use the second approach. Otherwise use the readable (but slow) one-bit-at-a-time approach.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;It\u0026apos;s hard to think of a situation where you\u0026apos;d want to use the bit-twiddling approach.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;Edit: Similar results \u0026lt;a href=\u0026quot;http://www.dalkescientific.com/writings/diary/archive/2008/07/03/hakmem_and_other_popcounts.html\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;here\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;unsigned int count_bit(unsigned int x)\n{\n  x = (x \u0026amp;amp; 0x55555555) + ((x \u0026amp;gt;\u0026amp;gt; 1) \u0026amp;amp; 0x55555555);\n  x = (x \u0026amp;amp; 0x33333333) + ((x \u0026amp;gt;\u0026amp;gt; 2) \u0026amp;amp; 0x33333333);\n  x = (x \u0026amp;amp; 0x0F0F0F0F) + ((x \u0026amp;gt;\u0026amp;gt; 4) \u0026amp;amp; 0x0F0F0F0F);\n  x = (x \u0026amp;amp; 0x00FF00FF) + ((x \u0026amp;gt;\u0026amp;gt; 8) \u0026amp;amp; 0x00FF00FF);\n  x = (x \u0026amp;amp; 0x0000FFFF) + ((x \u0026amp;gt;\u0026amp;gt; 16)\u0026amp;amp; 0x0000FFFF);\n  return x;\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Let me explain this algorithm.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;This algorithm is based on Divide and Conquer Algorithm. Suppose there is a 8bit integer 213(11010101 in binary), the algorithm works like this(each time merge two neighbor blocks):\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;+-------------------------------+\n| 1 | 1 | 0 | 1 | 0 | 1 | 0 | 1 |  \u0026amp;lt;- x\n|  1 0  |  0 1  |  0 1  |  0 1  |  \u0026amp;lt;- first time merge\n|    0 0 1 1    |    0 0 1 0    |  \u0026amp;lt;- second time merge\n|        0 0 0 0 0 1 0 1        |  \u0026amp;lt;- third time ( answer = 00000101 = 5)\n+-------------------------------+\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n    ","\n\u0026lt;p\u0026gt;Why not iteratively divide by 2?\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;count = 0\nwhile n \u0026amp;gt; 0\n  if (n % 2) == 1\n    count += 1\n  n /= 2  \n\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;I agree that this isn\u0026apos;t the fastest, but \u0026quot;best\u0026quot; is somewhat ambiguous. I\u0026apos;d argue though that \u0026quot;best\u0026quot; should have an element of clarity\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;This is one of those questions where it helps to know your micro-architecture.   I just timed two variants under gcc 4.3.3 compiled with -O3 using C++ inlines to eliminate function call overhead, one billion iterations, keeping the running sum of all counts to ensure the compiler doesn\u0026apos;t remove anything important, using rdtsc for timing (clock cycle precise).  \u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;inline int pop2(unsigned x, unsigned y)\n{\n    x = x - ((x \u0026amp;gt;\u0026amp;gt; 1) \u0026amp;amp; 0x55555555);\n    y = y - ((y \u0026amp;gt;\u0026amp;gt; 1) \u0026amp;amp; 0x55555555);\n    x = (x \u0026amp;amp; 0x33333333) + ((x \u0026amp;gt;\u0026amp;gt; 2) \u0026amp;amp; 0x33333333);\n    y = (y \u0026amp;amp; 0x33333333) + ((y \u0026amp;gt;\u0026amp;gt; 2) \u0026amp;amp; 0x33333333);\n    x = (x + (x \u0026amp;gt;\u0026amp;gt; 4)) \u0026amp;amp; 0x0F0F0F0F;\n    y = (y + (y \u0026amp;gt;\u0026amp;gt; 4)) \u0026amp;amp; 0x0F0F0F0F;\n    x = x + (x \u0026amp;gt;\u0026amp;gt; 8);\n    y = y + (y \u0026amp;gt;\u0026amp;gt; 8);\n    x = x + (x \u0026amp;gt;\u0026amp;gt; 16);\n    y = y + (y \u0026amp;gt;\u0026amp;gt; 16);\n    return (x+y) \u0026amp;amp; 0x000000FF;\n}\n\u0026lt;/pre\u0026gt; \n\n\u0026lt;p\u0026gt;The unmodified Hacker\u0026apos;s Delight took 12.2 gigacycles.  My parallel version (counting twice as many bits) runs in 13.0 gigacycles.  10.5s total elapsed for both together on a 2.4GHz Core Duo.  25 gigacycles = just over 10 seconds at this clock frequency, so I\u0026apos;m confident my timings are right.  \u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;This has to do with instruction dependency chains, which are very bad for this algorithm.  I could nearly double the speed again by using a pair of 64-bit registers.  In fact, if I was clever and added x+y a little sooner I could shave off some shifts.  The 64-bit version with some small tweaks would come out about even, but count twice as many bits again.  \u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;With 128 bit SIMD registers, yet another factor of two, and the SSE instruction sets often have clever short-cuts, too.  \u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;There\u0026apos;s no reason for the code to be especially transparent.  The interface is simple, the algorithm can be referenced on-line in many places, and it\u0026apos;s amenable to comprehensive unit test.  The programmer who stumbles upon it might even learn something.  These bit operations are extremely natural at the machine level.  \u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;OK, I decided to bench the tweaked 64-bit version.  For this one  sizeof(unsigned long) == 8 \u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;inline int pop2(unsigned long x, unsigned long y)\n{\n    x = x - ((x \u0026amp;gt;\u0026amp;gt; 1) \u0026amp;amp; 0x5555555555555555);\n    y = y - ((y \u0026amp;gt;\u0026amp;gt; 1) \u0026amp;amp; 0x5555555555555555);\n    x = (x \u0026amp;amp; 0x3333333333333333) + ((x \u0026amp;gt;\u0026amp;gt; 2) \u0026amp;amp; 0x3333333333333333);\n    y = (y \u0026amp;amp; 0x3333333333333333) + ((y \u0026amp;gt;\u0026amp;gt; 2) \u0026amp;amp; 0x3333333333333333);\n    x = (x + (x \u0026amp;gt;\u0026amp;gt; 4)) \u0026amp;amp; 0x0F0F0F0F0F0F0F0F;\n    y = (y + (y \u0026amp;gt;\u0026amp;gt; 4)) \u0026amp;amp; 0x0F0F0F0F0F0F0F0F;\n    x = x + y; \n    x = x + (x \u0026amp;gt;\u0026amp;gt; 8);\n    x = x + (x \u0026amp;gt;\u0026amp;gt; 16);\n    x = x + (x \u0026amp;gt;\u0026amp;gt; 32); \n    return x \u0026amp;amp; 0xFF;\n}\n\u0026lt;/pre\u0026gt; \n\n\u0026lt;p\u0026gt;That looks about right (I\u0026apos;m not testing carefully, though).   Now the timings come out at 10.70 gigacycles / 14.1 gigacycles.   That later number summed 128 billion bits and corresponds to 5.9s elapsed on this machine.   The non-parallel version speeds up a tiny bit because I\u0026apos;m running in 64-bit mode and it likes 64-bit registers slightly better than 32-bit registers.  \u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;Let\u0026apos;s see if there\u0026apos;s a bit more OOO pipelining to be had here.   This was a bit more involved, so I actually tested a bit.  Each term alone sums to 64, all combined sum to 256.  \u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;inline int pop4(unsigned long x, unsigned long y, \n                unsigned long u, unsigned long v)\n{\n  enum { m1 = 0x5555555555555555, \n         m2 = 0x3333333333333333, \n         m3 = 0x0F0F0F0F0F0F0F0F, \n         m4 = 0x000000FF000000FF };\n\n    x = x - ((x \u0026amp;gt;\u0026amp;gt; 1) \u0026amp;amp; m1);\n    y = y - ((y \u0026amp;gt;\u0026amp;gt; 1) \u0026amp;amp; m1);\n    u = u - ((u \u0026amp;gt;\u0026amp;gt; 1) \u0026amp;amp; m1);\n    v = v - ((v \u0026amp;gt;\u0026amp;gt; 1) \u0026amp;amp; m1);\n    x = (x \u0026amp;amp; m2) + ((x \u0026amp;gt;\u0026amp;gt; 2) \u0026amp;amp; m2);\n    y = (y \u0026amp;amp; m2) + ((y \u0026amp;gt;\u0026amp;gt; 2) \u0026amp;amp; m2);\n    u = (u \u0026amp;amp; m2) + ((u \u0026amp;gt;\u0026amp;gt; 2) \u0026amp;amp; m2);\n    v = (v \u0026amp;amp; m2) + ((v \u0026amp;gt;\u0026amp;gt; 2) \u0026amp;amp; m2);\n    x = x + y; \n    u = u + v; \n    x = (x \u0026amp;amp; m3) + ((x \u0026amp;gt;\u0026amp;gt; 4) \u0026amp;amp; m3);\n    u = (u \u0026amp;amp; m3) + ((u \u0026amp;gt;\u0026amp;gt; 4) \u0026amp;amp; m3);\n    x = x + u; \n    x = x + (x \u0026amp;gt;\u0026amp;gt; 8);\n    x = x + (x \u0026amp;gt;\u0026amp;gt; 16);\n    x = x \u0026amp;amp; m4; \n    x = x + (x \u0026amp;gt;\u0026amp;gt; 32);\n    return x \u0026amp;amp; 0x000001FF;\n}\n\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;I was excited for a moment, but it turns out gcc is playing inline tricks with -O3 even though I\u0026apos;m not using the inline keyword in some tests.  When I let gcc play tricks, a billion calls to pop4() takes 12.56 gigacycles, but I determined it was folding arguments as constant expressions.   A more realistic number appears to be 19.6gc for another 30% speed-up.  My test loop now looks like this, making sure each argument is different enough to stop gcc from playing tricks.   \u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;   hitime b4 = rdtsc(); \n   for (unsigned long i = 10L * 1000*1000*1000; i \u0026amp;lt; 11L * 1000*1000*1000; ++i) \n      sum += pop4 (i,  i^1, ~i, i|1); \n   hitime e4 = rdtsc(); \n\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;256 billion bits summed in 8.17s elapsed.  Works out to 1.02s for 32 million bits as benchmarked in the 16-bit table lookup.  Can\u0026apos;t compare directly, because the other bench doesn\u0026apos;t give a clock speed, but looks like I\u0026apos;ve slapped the snot out of the 64KB table edition, which is a tragic use of L1 cache in the first place.  \u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;Update: decided to do the obvious and create pop6() by adding four more duplicated lines.  Came out to 22.8gc, 384 billion bits summed in 9.5s elapsed.   So there\u0026apos;s another 20%   Now at 800ms for 32 billion bits.  \u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;The Hacker\u0026apos;s Delight bit-twiddling becomes so much clearer when you write out the bit patterns.  \u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;unsigned int bitCount(unsigned int x)\n{\n  x = ((x \u0026amp;gt;\u0026amp;gt; 1) \u0026amp;amp; 0b01010101010101010101010101010101)\n     + (x       \u0026amp;amp; 0b01010101010101010101010101010101);\n  x = ((x \u0026amp;gt;\u0026amp;gt; 2) \u0026amp;amp; 0b00110011001100110011001100110011)\n     + (x       \u0026amp;amp; 0b00110011001100110011001100110011); \n  x = ((x \u0026amp;gt;\u0026amp;gt; 4) \u0026amp;amp; 0b00001111000011110000111100001111)\n     + (x       \u0026amp;amp; 0b00001111000011110000111100001111); \n  x = ((x \u0026amp;gt;\u0026amp;gt; 8) \u0026amp;amp; 0b00000000111111110000000011111111)\n     + (x       \u0026amp;amp; 0b00000000111111110000000011111111); \n  x = ((x \u0026amp;gt;\u0026amp;gt; 16)\u0026amp;amp; 0b00000000000000001111111111111111)\n     + (x       \u0026amp;amp; 0b00000000000000001111111111111111); \n  return x;\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;The first step adds the even bits to the odd bits, producing a sum of bits in each two.  The other steps add high-order chunks to low-order chunks, doubling the chunk size all the way up, until we have the final count taking up the entire int.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;For a happy medium between a 2\u0026lt;sup\u0026gt;32\u0026lt;/sup\u0026gt; lookup table and iterating through each bit individually:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;int bitcount(unsigned int num){\n    int count = 0;\n    static int nibblebits[] =\n        {0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4};\n    for(; num != 0; num \u0026amp;gt;\u0026amp;gt;= 4)\n        count += nibblebits[num \u0026amp;amp; 0x0f];\n    return count;\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;From \u0026lt;a href=\u0026quot;http://ctips.pbwiki.com/CountBits\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;http://ctips.pbwiki.com/CountBits\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;This can be done in \u0026lt;code\u0026gt;O(k)\u0026lt;/code\u0026gt;, where \u0026lt;code\u0026gt;k\u0026lt;/code\u0026gt; is the number of bits set.\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;int NumberOfSetBits(int n)\n{\n    int count = 0;\n\n    while (n){\n        ++ count;\n        n = (n - 1) \u0026amp;amp; n;\n    }\n\n    return count;\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n    ","\n\u0026lt;p\u0026gt;It\u0026apos;s not the fastest or best solution, but I found the same question in my way, and I started to think and think. finally I realized that it can be done like this if you get the problem from mathematical side, and draw a graph, then you find that it\u0026apos;s a function which has some periodic part, and then you realize the difference between the periods... so here you go:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;unsigned int f(unsigned int x)\n{\n    switch (x) {\n        case 0:\n            return 0;\n        case 1:\n            return 1;\n        case 2:\n            return 1;\n        case 3:\n            return 2;\n        default:\n            return f(x/4) + f(x%4);\n    }\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n    ","\n\u0026lt;p\u0026gt;I think the \u0026lt;a href=\u0026quot;https://graphics.stanford.edu/~seander/bithacks.html#CountBitsSetKernighan\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;Brian Kernighan\u0026apos;s\u0026lt;/a\u0026gt; method will be useful too...\nIt goes through as many iterations as there are set bits. So if we have a 32-bit word with only the high bit set, then it will only go once through the loop.  \u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;int countSetBits(unsigned int n) { \n    unsigned int n; // count the number of bits set in n\n    unsigned int c; // c accumulates the total bits set in n\n    for (c=0;n\u0026amp;gt;0;n=n\u0026amp;amp;(n-1)) c++; \n    return c; \n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;blockquote\u0026gt;\n  \u0026lt;p\u0026gt;Published in 1988, the C Programming Language 2nd Ed. (by Brian W. Kernighan and Dennis M. Ritchie) mentions this in exercise 2-9. On April 19, 2006 Don Knuth pointed out to me that this method \u0026quot;was first published by Peter Wegner in CACM 3 (1960), 322. (Also discovered independently by Derrick Lehmer and published in 1964 in a book edited by Beckenbach.)\u0026quot;\u0026lt;/p\u0026gt;\n\u0026lt;/blockquote\u0026gt;\n    ","\n\u0026lt;p\u0026gt;The function you are looking for is often called the \u0026quot;sideways sum\u0026quot; or \u0026quot;population count\u0026quot; of a binary number.  Knuth discusses it in pre-Fascicle 1A, pp11-12 (although there was a brief reference in Volume 2, 4.6.3-(7).)\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;The \u0026lt;em\u0026gt;locus classicus\u0026lt;/em\u0026gt; is Peter Wegner\u0026apos;s article \u0026quot;A Technique for Counting Ones in a Binary Computer\u0026quot;, from the \u0026lt;a href=\u0026quot;http://cacm.acm.org/magazines/1960/5/14709-a-technique-for-counting-ones-in-a-binary-computer/abstract\u0026quot; rel=\u0026quot;nofollow noreferrer\u0026quot;\u0026gt;\u0026lt;em\u0026gt;Communications of the ACM\u0026lt;/em\u0026gt;, Volume 3 (1960) Number 5, page 322\u0026lt;/a\u0026gt;.  He gives two different algorithms there, one optimized for numbers expected to be \u0026quot;sparse\u0026quot; (i.e., have a small number of ones) and one for the opposite case.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;pre class=\u0026quot;lang-java s-code-block\u0026quot;\u0026gt;\u0026lt;code class=\u0026quot;hljs language-java\u0026quot;\u0026gt;  \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;private\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;int\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026quot;hljs-title function_\u0026quot;\u0026gt;get_bits_set\u0026lt;/span\u0026gt;\u0026lt;span class=\u0026quot;hljs-params\u0026quot;\u0026gt;(\u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;int\u0026lt;/span\u0026gt; v)\u0026lt;/span\u0026gt;\n    {\n      \u0026lt;span class=\u0026quot;hljs-type\u0026quot;\u0026gt;int\u0026lt;/span\u0026gt; c; \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;// c accumulates the total bits set in v\u0026lt;/span\u0026gt;\n        \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;for\u0026lt;/span\u0026gt; (c = \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0\u0026lt;/span\u0026gt;; v\u0026amp;gt;\u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;0\u0026lt;/span\u0026gt;; c++)\n        {\n            v \u0026amp;amp;= v - \u0026lt;span class=\u0026quot;hljs-number\u0026quot;\u0026gt;1\u0026lt;/span\u0026gt;; \u0026lt;span class=\u0026quot;hljs-comment\u0026quot;\u0026gt;// clear the least significant bit set\u0026lt;/span\u0026gt;\n        }\n        \u0026lt;span class=\u0026quot;hljs-keyword\u0026quot;\u0026gt;return\u0026lt;/span\u0026gt; c;\n    }\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n    ","\n\u0026lt;p\u0026gt;Few open questions:-\u0026lt;/p\u0026gt;\n\n\u0026lt;ol\u0026gt;\n\u0026lt;li\u0026gt;If the number is negative then?\u0026lt;/li\u0026gt;\n\u0026lt;li\u0026gt;If the number is 1024 , then the \u0026quot;iteratively divide by 2\u0026quot; method will iterate 10 times.\u0026lt;/li\u0026gt;\n\u0026lt;/ol\u0026gt;\n\n\u0026lt;p\u0026gt;we can modify the algo to support the negative number as follows:-\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;count = 0\nwhile n != 0\nif ((n % 2) == 1 || (n % 2) == -1\n    count += 1\n  n /= 2  \nreturn count\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;now to overcome the second problem we can write the algo like:-\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;int bit_count(int num)\n{\n    int count=0;\n    while(num)\n    {\n        num=(num)\u0026amp;amp;(num-1);\n        count++;\n    }\n    return count;\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;for complete reference see :\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;\u0026lt;a href=\u0026quot;http://goursaha.freeoda.com/Miscellaneous/IntegerBitCount.html\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;http://goursaha.freeoda.com/Miscellaneous/IntegerBitCount.html\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;I use the below code which is more intuitive.\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;int countSetBits(int n) {\n    return !n ? 0 : 1 + countSetBits(n \u0026amp;amp; (n-1));\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Logic : n \u0026amp;amp; (n-1)  resets the last set bit of n.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;P.S : I know this is not O(1) solution, albeit an interesting solution.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;What do you means with \u0026quot;Best algorithm\u0026quot;? The shorted code or the fasted code? Your code look very elegant and it has a constant execution time. The code is also very short.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;But if the speed is the major factor and not the code size then I think the follow can be faster:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;       static final int[] BIT_COUNT = { 0, 1, 1, ... 256 values with a bitsize of a byte ... };\n        static int bitCountOfByte( int value ){\n            return BIT_COUNT[ value \u0026amp;amp; 0xFF ];\n        }\n\n        static int bitCountOfInt( int value ){\n            return bitCountOfByte( value ) \n                 + bitCountOfByte( value \u0026amp;gt;\u0026amp;gt; 8 ) \n                 + bitCountOfByte( value \u0026amp;gt;\u0026amp;gt; 16 ) \n                 + bitCountOfByte( value \u0026amp;gt;\u0026amp;gt; 24 );\n        }\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;I think that this will not more faster for a 64 bit value but a 32 bit value can be faster.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;I wrote a fast bitcount macro for RISC machines in about 1990.  It does not use advanced arithmetic (multiplication, division, %), memory fetches (way too slow), branches (way too slow), but it does assume the CPU has a 32-bit barrel shifter (in other words, \u0026amp;gt;\u0026amp;gt; 1 and \u0026amp;gt;\u0026amp;gt; 32 take the same amount of cycles.)  It assumes that small constants (such as 6, 12, 24) cost nothing to load into the registers, or are stored in temporaries and reused over and over again.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;With these assumptions, it counts 32 bits in about 16 cycles/instructions on most RISC machines.  Note that 15 instructions/cycles is close to a lower bound on the number of cycles or instructions, because it seems to take at least 3 instructions (mask, shift, operator) to cut the number of addends in half, so log_2(32) = 5, 5 x 3 = 15 instructions is a quasi-lowerbound.\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;#define BitCount(X,Y)           \\\n                Y = X - ((X \u0026amp;gt;\u0026amp;gt; 1) \u0026amp;amp; 033333333333) - ((X \u0026amp;gt;\u0026amp;gt; 2) \u0026amp;amp; 011111111111); \\\n                Y = ((Y + (Y \u0026amp;gt;\u0026amp;gt; 3)) \u0026amp;amp; 030707070707); \\\n                Y =  (Y + (Y \u0026amp;gt;\u0026amp;gt; 6)); \\\n                Y = (Y + (Y \u0026amp;gt;\u0026amp;gt; 12) + (Y \u0026amp;gt;\u0026amp;gt; 24)) \u0026amp;amp; 077;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Here is a secret to the first and most complex step:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;input output\nAB    CD             Note\n00    00             = AB\n01    01             = AB\n10    01             = AB - (A \u0026amp;gt;\u0026amp;gt; 1) \u0026amp;amp; 0x1\n11    10             = AB - (A \u0026amp;gt;\u0026amp;gt; 1) \u0026amp;amp; 0x1\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;so if I take the 1st column (A) above, shift it right 1 bit, and subtract it from AB, I get the output (CD).  The extension to 3 bits is similar; you can check it with an 8-row boolean table like mine above if you wish.\u0026lt;/p\u0026gt;\n\n\u0026lt;ul\u0026gt;\n\u0026lt;li\u0026gt;Don Gillies\u0026lt;/li\u0026gt;\n\u0026lt;/ul\u0026gt;\n    ","\n\u0026lt;p\u0026gt;if you\u0026apos;re using C++ another option is to use template metaprogramming:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;// recursive template to sum bits in an int\ntemplate \u0026amp;lt;int BITS\u0026amp;gt;\nint countBits(int val) {\n        // return the least significant bit plus the result of calling ourselves with\n        // .. the shifted value\n        return (val \u0026amp;amp; 0x1) + countBits\u0026amp;lt;BITS-1\u0026amp;gt;(val \u0026amp;gt;\u0026amp;gt; 1);\n}\n\n// template specialisation to terminate the recursion when there\u0026apos;s only one bit left\ntemplate\u0026amp;lt;\u0026amp;gt;\nint countBits\u0026amp;lt;1\u0026amp;gt;(int val) {\n        return val \u0026amp;amp; 0x1;\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;usage would be:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;// to count bits in a byte/char (this returns 8)\ncountBits\u0026amp;lt;8\u0026amp;gt;( 255 )\n\n// another byte (this returns 7)\ncountBits\u0026amp;lt;8\u0026amp;gt;( 254 )\n\n// counting bits in a word/short (this returns 1)\ncountBits\u0026amp;lt;16\u0026amp;gt;( 256 )\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;you could of course further expand this template to use different types (even auto-detecting bit size) but I\u0026apos;ve kept it simple for clarity.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;edit: forgot to mention this is good because it \u0026lt;em\u0026gt;should\u0026lt;/em\u0026gt; work in any C++ compiler and it basically just unrolls your loop for you if a constant value is used for the bit count\u0026lt;/strong\u0026gt; (in other words, I\u0026apos;m pretty sure it\u0026apos;s the fastest general method you\u0026apos;ll find)\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;what you can do is \u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;while(n){\n    n=n\u0026amp;amp;(n-1);\n    count++;\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;the logic behind this is the bits of n-1 is inverted from rightmost set bit of n.\nif n=6 i.e 110\nthen 5 is 101 the bits are inverted from rightmost set bit of n.\nso if we \u0026amp;amp; these two we will make the rightmost bit 0 in every iteration and always go to the next rightmost set bit.Hence, counting the set bit.The worst time complexity will be O(logn) when every bit is set.\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;I\u0026apos;m particularly fond of this example from the fortune file:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;#define BITCOUNT(x)    (((BX_(x)+(BX_(x)\u0026amp;gt;\u0026amp;gt;4)) \u0026amp;amp; 0x0F0F0F0F) % 255)\n#define BX_(x)         ((x) - (((x)\u0026amp;gt;\u0026amp;gt;1)\u0026amp;amp;0x77777777)\n                             - (((x)\u0026amp;gt;\u0026amp;gt;2)\u0026amp;amp;0x33333333)\n                             - (((x)\u0026amp;gt;\u0026amp;gt;3)\u0026amp;amp;0x11111111))\n\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;I like it best because it\u0026apos;s so pretty!\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;Java JDK1.5\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;Integer.bitCount(n);\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;where n is the number whose 1\u0026apos;s are to be counted.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;check also,\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;Integer.highestOneBit(n);\nInteger.lowestOneBit(n);\nInteger.numberOfLeadingZeros(n);\nInteger.numberOfTrailingZeros(n);\n\n//Beginning with the value 1, rotate left 16 times\n     n = 1;\n         for (int i = 0; i \u0026amp;lt; 16; i++) {\n            n = Integer.rotateLeft(n, 1);\n            System.out.println(n);\n         }\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n    ","\n\u0026lt;p\u0026gt;Fast C# solution using pre-calculated table of Byte bit counts with branching on input size.\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;public static class BitCount\n{\n    public static uint GetSetBitsCount(uint n)\n    {\n        var counts = BYTE_BIT_COUNTS;\n        return n \u0026amp;lt;= 0xff ? counts[n]\n             : n \u0026amp;lt;= 0xffff ? counts[n \u0026amp;amp; 0xff] + counts[n \u0026amp;gt;\u0026amp;gt; 8]\n             : n \u0026amp;lt;= 0xffffff ? counts[n \u0026amp;amp; 0xff] + counts[(n \u0026amp;gt;\u0026amp;gt; 8) \u0026amp;amp; 0xff] + counts[(n \u0026amp;gt;\u0026amp;gt; 16) \u0026amp;amp; 0xff]\n             : counts[n \u0026amp;amp; 0xff] + counts[(n \u0026amp;gt;\u0026amp;gt; 8) \u0026amp;amp; 0xff] + counts[(n \u0026amp;gt;\u0026amp;gt; 16) \u0026amp;amp; 0xff] + counts[(n \u0026amp;gt;\u0026amp;gt; 24) \u0026amp;amp; 0xff];\n    }\n\n    public static readonly uint[] BYTE_BIT_COUNTS = \n    {\n        0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4,\n        1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5,\n        1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5,\n        2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,\n        1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5,\n        2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,\n        2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,\n        3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7,\n        1, 2, 2, 3, 2, 3, 3, 4, 2, 3, 3, 4, 3, 4, 4, 5,\n        2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,\n        2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,\n        3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7,\n        2, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4, 5, 5, 6,\n        3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7,\n        3, 4, 4, 5, 4, 5, 5, 6, 4, 5, 5, 6, 5, 6, 6, 7,\n        4, 5, 5, 6, 5, 6, 6, 7, 5, 6, 6, 7, 6, 7, 7, 8\n    };\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n    ","\n\u0026lt;p\u0026gt;I found an implementation of bit counting in an array with using of SIMD instruction (SSSE3 and AVX2). It has in 2-2.5 times better performance than if it will use __popcnt64 intrinsic function.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;SSSE3 version:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;#include \u0026amp;lt;smmintrin.h\u0026amp;gt;\n#include \u0026amp;lt;stdint.h\u0026amp;gt;\n\nconst __m128i Z = _mm_set1_epi8(0x0);\nconst __m128i F = _mm_set1_epi8(0xF);\n//Vector with pre-calculated bit count:\nconst __m128i T = _mm_setr_epi8(0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4);\n\nuint64_t BitCount(const uint8_t * src, size_t size)\n{\n    __m128i _sum =  _mm128_setzero_si128();\n    for (size_t i = 0; i \u0026amp;lt; size; i += 16)\n    {\n        //load 16-byte vector\n        __m128i _src = _mm_loadu_si128((__m128i*)(src + i));\n        //get low 4 bit for every byte in vector\n        __m128i lo = _mm_and_si128(_src, F);\n        //sum precalculated value from T\n        _sum = _mm_add_epi64(_sum, _mm_sad_epu8(Z, _mm_shuffle_epi8(T, lo)));\n        //get high 4 bit for every byte in vector\n        __m128i hi = _mm_and_si128(_mm_srli_epi16(_src, 4), F);\n        //sum precalculated value from T\n        _sum = _mm_add_epi64(_sum, _mm_sad_epu8(Z, _mm_shuffle_epi8(T, hi)));\n    }\n    uint64_t sum[2];\n    _mm_storeu_si128((__m128i*)sum, _sum);\n    return sum[0] + sum[1];\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;AVX2 version:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;#include \u0026amp;lt;immintrin.h\u0026amp;gt;\n#include \u0026amp;lt;stdint.h\u0026amp;gt;\n\nconst __m256i Z = _mm256_set1_epi8(0x0);\nconst __m256i F = _mm256_set1_epi8(0xF);\n//Vector with pre-calculated bit count:\nconst __m256i T = _mm256_setr_epi8(0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4, \n                                   0, 1, 1, 2, 1, 2, 2, 3, 1, 2, 2, 3, 2, 3, 3, 4);\n\nuint64_t BitCount(const uint8_t * src, size_t size)\n{\n    __m256i _sum =  _mm256_setzero_si256();\n    for (size_t i = 0; i \u0026amp;lt; size; i += 32)\n    {\n        //load 32-byte vector\n        __m256i _src = _mm256_loadu_si256((__m256i*)(src + i));\n        //get low 4 bit for every byte in vector\n        __m256i lo = _mm256_and_si256(_src, F);\n        //sum precalculated value from T\n        _sum = _mm256_add_epi64(_sum, _mm256_sad_epu8(Z, _mm256_shuffle_epi8(T, lo)));\n        //get high 4 bit for every byte in vector\n        __m256i hi = _mm256_and_si256(_mm256_srli_epi16(_src, 4), F);\n        //sum precalculated value from T\n        _sum = _mm256_add_epi64(_sum, _mm256_sad_epu8(Z, _mm256_shuffle_epi8(T, hi)));\n    }\n    uint64_t sum[4];\n    _mm256_storeu_si256((__m256i*)sum, _sum);\n    return sum[0] + sum[1] + sum[2] + sum[3];\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n    ","\n\u0026lt;p\u0026gt;I always use this in Competitive Programming and it\u0026apos;s easy to write and efficient:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;#include \u0026amp;lt;bits/stdc++.h\u0026amp;gt;\n\nusing namespace std;\n\nint countOnes(int n) {\n    bitset\u0026amp;lt;32\u0026amp;gt; b(n);\n    return b.count();\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n    ","\n\u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;C++20 \u0026lt;code\u0026gt;std::popcount\u0026lt;/code\u0026gt;\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;The following proposal has been merged \u0026lt;a href=\u0026quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0553r4.html\u0026quot; rel=\u0026quot;noreferrer\u0026quot;\u0026gt;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p0553r4.html\u0026lt;/a\u0026gt; and should add it to a the \u0026lt;code\u0026gt;\u0026amp;lt;bit\u0026amp;gt;\u0026lt;/code\u0026gt; header.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;I expect the usage to be like:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;#include \u0026amp;lt;bit\u0026amp;gt;\n#include \u0026amp;lt;iostream\u0026amp;gt;\n\nint main() {\n    std::cout \u0026amp;lt;\u0026amp;lt; std::popcount(0x55) \u0026amp;lt;\u0026amp;lt; std::endl;\n}\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;I\u0026apos;ll give it a try when support arrives to GCC, GCC 9.1.0 with \u0026lt;code\u0026gt;g++-9 -std=c++2a\u0026lt;/code\u0026gt; still doesn\u0026apos;t support it.\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;The proposal says:\u0026lt;/p\u0026gt;\n\n\u0026lt;blockquote\u0026gt;\n  \u0026lt;p\u0026gt;Header: \u0026lt;code\u0026gt;\u0026amp;lt;bit\u0026amp;gt;\u0026lt;/code\u0026gt;\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;namespace std {\n\n  // 25.5.6, counting\n  template\u0026amp;lt;class T\u0026amp;gt;\n    constexpr int popcount(T x) noexcept;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\u0026lt;/blockquote\u0026gt;\n\n\u0026lt;p\u0026gt;and:\u0026lt;/p\u0026gt;\n\n\u0026lt;blockquote\u0026gt;\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;template\u0026amp;lt;class T\u0026amp;gt;\n  constexpr int popcount(T x) noexcept;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n  \n  \u0026lt;p\u0026gt;Constraints: T is an unsigned integer type (3.9.1 [basic.fundamental]).\u0026lt;/p\u0026gt;\n  \n  \u0026lt;p\u0026gt;Returns: The number of 1 bits in the value of x.\u0026lt;/p\u0026gt;\n\u0026lt;/blockquote\u0026gt;\n\n\u0026lt;p\u0026gt;\u0026lt;code\u0026gt;std::rotl\u0026lt;/code\u0026gt; and \u0026lt;code\u0026gt;std::rotr\u0026lt;/code\u0026gt; were also added to do circular bit rotations: \u0026lt;a href=\u0026quot;https://stackoverflow.com/questions/776508/best-practices-for-circular-shift-rotate-operations-in-c/57285854#57285854\u0026quot;\u0026gt;Best practices for circular shift (rotate) operations in C++\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\n    ","\n\u0026lt;p\u0026gt;There are many algorithm to count the set bits; but i think the best one is the faster one!\nYou can see the detailed on this page:\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;\u0026lt;a href=\u0026quot;http://graphics.stanford.edu/~seander/bithacks.html\u0026quot;\u0026gt;Bit Twiddling Hacks\u0026lt;/a\u0026gt; \u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;I suggest this one:\u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;Counting bits set in 14, 24, or 32-bit words using 64-bit instructions\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;unsigned int v; // count the number of bits set in v\nunsigned int c; // c accumulates the total bits set in v\n\n// option 1, for at most 14-bit values in v:\nc = (v * 0x200040008001ULL \u0026amp;amp; 0x111111111111111ULL) % 0xf;\n\n// option 2, for at most 24-bit values in v:\nc =  ((v \u0026amp;amp; 0xfff) * 0x1001001001001ULL \u0026amp;amp; 0x84210842108421ULL) % 0x1f;\nc += (((v \u0026amp;amp; 0xfff000) \u0026amp;gt;\u0026amp;gt; 12) * 0x1001001001001ULL \u0026amp;amp; 0x84210842108421ULL) \n     % 0x1f;\n\n// option 3, for at most 32-bit values in v:\nc =  ((v \u0026amp;amp; 0xfff) * 0x1001001001001ULL \u0026amp;amp; 0x84210842108421ULL) % 0x1f;\nc += (((v \u0026amp;amp; 0xfff000) \u0026amp;gt;\u0026amp;gt; 12) * 0x1001001001001ULL \u0026amp;amp; 0x84210842108421ULL) % \n     0x1f;\nc += ((v \u0026amp;gt;\u0026amp;gt; 24) * 0x1001001001001ULL \u0026amp;amp; 0x84210842108421ULL) % 0x1f;\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;This method requires a 64-bit CPU with fast modulus division to be efficient. The first option takes only 3 operations; the second option takes 10; and the third option takes 15. \u0026lt;/p\u0026gt;\n    "],"id":566,"title":"How to count the number of set bits in a 32-bit integer?","content":"\n                \n\u0026lt;p\u0026gt;8 bits representing the number 7 look like this:\u0026lt;/p\u0026gt;\n\n\u0026lt;pre\u0026gt;\u0026lt;code\u0026gt;00000111\n\u0026lt;/code\u0026gt;\u0026lt;/pre\u0026gt;\n\n\u0026lt;p\u0026gt;Three bits are set.   \u0026lt;/p\u0026gt;\n\n\u0026lt;p\u0026gt;What are algorithms to determine the number of set bits in a 32-bit integer?\u0026lt;/p\u0026gt;\n    ","slug":"how-to-count-the-number-of-set-bits-in-a-32-bit-integer-1657388437370","postType":"QUESTION","createdAt":"2022-07-09T17:40:37.000Z","updatedAt":"2022-07-09T17:40:37.000Z","tags":[{"id":2730,"name":"binary","slug":"binary","createdAt":"2022-07-09T17:40:37.000Z","updatedAt":"2022-07-09T17:40:37.000Z","Questions_Tags":{"questionId":566,"tagId":2730}},{"id":2732,"name":"hammingweight","slug":"hammingweight","createdAt":"2022-07-09T17:40:37.000Z","updatedAt":"2022-07-09T17:40:37.000Z","Questions_Tags":{"questionId":566,"tagId":2732}},{"id":2733,"name":"iec10967","slug":"iec10967","createdAt":"2022-07-09T17:40:37.000Z","updatedAt":"2022-07-09T17:40:37.000Z","Questions_Tags":{"questionId":566,"tagId":2733}}]}},"__N_SSG":true},"page":"/questions/[slug]","query":{"slug":"how-to-count-the-number-of-set-bits-in-a-32-bit-integer-1657388437370"},"buildId":"8pZkyd0U8-Y2Qf3QK9j7l","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>